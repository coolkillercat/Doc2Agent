Step 0:
act - **MessageAction** (source=EventSource.USER)
CONTENT: Think step by step to perform the following task related to gitlab. Answer the question: ***Show me the command to clone the best GAN python implementation with SSH.***
The site URL for gitlab is http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023, use this instead of the normal gitlab URL.
For API calling, use this access token: glpat-KygcYjwtD2JfA6wU4wBd
For web browsing, You should start from the URL http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023, and this webpage is already logged in and opened for you.
My *name* on gitlab is Byte Blaze; My *username* on gitlab is byteblaze; and my *user id* is 2330.

Below is the list of all APIs you can use and their descriptions:
{'post /api/v4/groups/{id}/wikis/attachments': "Upload a file to the attachment folder inside the wiki's repository. The attachment folder is the `uploads` folder. ", 'delete /api/v4/groups/{id}/wikis/{slug}': 'Delete a wiki page with a given slug. ', 'put /api/v4/groups/{id}/wikis/{slug}': 'Update an existing wiki page. At least one parameter is required to update the wiki page. ', 'get /api/v4/groups/{id}/wikis/{slug}': 'Get a wiki page for a given group. ', 'post /api/v4/groups/{id}/wikis': 'Create a wiki page', 'get /api/v4/groups/{id}/wikis': 'List all wiki pages for a given group. ', 'post /api/v4/groups/{id}/access_tokens/{token_id}/rotate': 'Prerequisites: - You must have a [personal access token with the `api` scope](../user/profile/personal_access_tokens.md#personal-access-token-scopes). Rotate a group access token. Revokes the previous token and creates a new token that expires in one week. In GitLab 16.6 and later, you can use the `expires_at` parameter to set a different expiry date. This non-default expiry date can be up to a maximum of one year from the rotation date. ', 'post /api/v4/groups/{id}/access_tokens': 'Create a [group access token](../user/group/settings/group_access_tokens.md). You must have the Owner role for the group to create group access tokens. ', 'get /api/v4/groups/{id}/access_tokens': 'Get a list of [group access tokens](../user/group/settings/group_access_tokens.md). ', 'delete /api/v4/groups/{id}/access_tokens/{token_id}': 'Revoke a [group access token](../user/group/settings/group_access_tokens.md). ', 'get /api/v4/groups/{id}/access_tokens/{token_id}': 'Get a [group access token](../user/group/settings/group_access_tokens.md) by ID. ', 'get /api/v4/groups/{id}/releases': 'Returns a list of group releases. ', 'get /api/v4/groups/{id}/merge_requests': 'Get all merge requests for this group and its subgroups. ', 'delete /api/v4/groups/{id}/billable_members/{user_id}': 'Removes a billable member from a group and its subgroups and projects. The user does not need to be a group member to qualify for removal. For example, if the user was added directly to a project within the group, you can still use this API to remove them. ', 'get /api/v4/groups/{id}/billable_members/{user_id}/memberships': 'Gets a list of memberships for a billable member of a group. Lists all projects and groups a user is a member of. Only projects and groups within the group hierarchy are included. For instance, if the requested group is `Root Group`, and the requested user is a direct member of both `Root Group / Sub Group One` and `Other Group / Sub Group Two`, then only `Root Group / Sub Group One` will be returned, because `Other Group / Sub Group Two` is not within the `Root Group` hierarchy. The response represents only direct memberships. Inherited memberships are not included. This API endpoint works on top-level groups only. It does not work on subgroups. This API endpoint requires permission to administer memberships for the group. This API endpoint takes [pagination](rest/index.md#pagination) parameters `page` and `per_page` to restrict the list of memberships. ', 'put /api/v4/groups/{id}/members/{user_id}/state': 'Changes the membership state of a user in a group. The state is applied to all subgroups and projects. ', 'get /api/v4/groups/{id}/billable_members': 'Gets a list of group members that count as billable. The list includes members in subgroups and projects. This API endpoint works on top-level groups only. It does not work on subgroups. This function takes [pagination](rest/index.md#pagination) parameters `page` and `per_page` to restrict the list of users. Use the `search` parameter to search for billable group members by name and `sort` to sort the results. ', 'get /api/v4/groups/{id}/pending_members': "For a group and its subgroups and projects, get a list of all members in an `awaiting` state and those who are invited but do not have a GitLab account. This request returns all matching group and project members from all groups and projects in the root group's hierarchy. When the member is an invited user that has not signed up for a GitLab account yet, the invited email address is returned. This API endpoint works on top-level groups only. It does not work on subgroups. This API endpoint requires permission to administer members for the group. This API endpoint takes [pagination](rest/index.md#pagination) parameters `page` and `per_page` to restrict the list of members. ", 'post /api/v4/groups/{id}/members/approve_all': 'Approves all pending users for a group and its subgroups and projects. ', 'put /api/v4/groups/{id}/members/{member_id}/approve': 'Approves a pending user for a group and its subgroups and projects. ', 'delete /api/v4/groups/{id}/members/{user_id}/override': 'Sets the override flag to false and allows LDAP Group Sync to reset the access level to the LDAP-prescribed value. ', 'post /api/v4/groups/{id}/members/{user_id}/override': 'By default, the access level of LDAP group members is set to the value specified by LDAP through Group Sync. You can allow access level overrides by calling this endpoint. ', 'delete /api/v4/groups/{id}/members/{user_id}': 'Removes a user from a group or project where the user has been explicitly assigned a role. The user needs to be a group member to qualify for removal. For example, if the user was added directly to a project within the group but not this group explicitly, you cannot use this API to remove them. See [Remove a billable member from a group](#remove-a-billable-member-from-a-group) for an alternative approach. ', 'put /api/v4/groups/{id}/members/{user_id}': 'Updates a member of a group or project. ', 'get /api/v4/groups/{id}/members/{user_id}': 'Gets a member of a group or project. Returns only direct members and not inherited members through ancestor groups. ', 'post /api/v4/groups/{id}/members': 'Adds a member to a group or project. ', 'get /api/v4/groups/{id}/members': 'Gets a list of group or project members viewable by the authenticated user. Returns only direct members and not inherited members through ancestors groups. This function takes pagination parameters `page` and `per_page` to restrict the list of users. ', 'get /api/v4/groups/{id}/members/all/{user_id}': 'FLAG: On self-managed GitLab, by default this feature is available. To hide the feature per user, an administrator can [disable the feature flag](../administration/feature_flags.md) named `webui_members_inherited_users`. On GitLab.com and GitLab Dedicated, this feature is available. Gets a member of a group or project, including members inherited or invited through ancestor groups. See the corresponding [endpoint to list all inherited members](#list-all-members-of-a-group-or-project-including-inherited-and-invited-members) for details. NOTE: The invited group members have shared membership in the shared group or project. This means that if the requester is a member of a shared group or project, but not a member of an invited private group, then using this endpoint the requester can get all the shared group or project members, including the invited private group members. ', 'get /api/v4/groups/{id}/members/all': 'FLAG: On self-managed GitLab, by default this feature is available. To hide the feature per user, an administrator can [disable the feature flag](../administration/feature_flags.md) named `webui_members_inherited_users`. On GitLab.com and GitLab Dedicated, this feature is available. Gets a list of group or project members viewable by the authenticated user, including inherited members, invited users, and permissions through ancestor groups. If a user is a member of this group or project and also of one or more ancestor groups, only its membership with the highest `access_level` is returned. This represents the effective permission of the user. Members from an invited group are returned if either: - The invited group is public. - The requester is also a member of the invited group. - The requester is a member of the shared group or project. NOTE: The invited group members have shared membership in the shared group or project. This means that if the requester is a member of a shared group or project, but not a member of an invited private group, then using this endpoint the requester can get all the shared group or project members, including the invited private group members. This function takes pagination parameters `page` and `per_page` to restrict the list of users. ', 'get /api/v4/groups/{id}/-/packages/maven/*path/{file_name}': 'Download the maven package file at a group level', 'delete /api/v4/groups/{id}/invitations/{email}': 'Deletes a pending invitation by email address. ', 'put /api/v4/groups/{id}/invitations/{email}': "Updates a pending invitation's access level or access expiry date. ", 'get /api/v4/groups/{id}/invitations': "Gets a list of invited group or project members viewable by the authenticated user. Returns invitations to direct members only, and not through inherited ancestors' groups. This function takes pagination parameters `page` and `per_page` to restrict the list of members. ", 'post /api/v4/groups/{id}/invitations': 'Adds a new member. You can specify a user ID or invite a user by email. ', 'delete /api/v4/groups/{id}/variables/{key}': "Remove a group's variable. If there are multiple variables with the same key, use `filter` to select the correct `environment_scope`. ", 'put /api/v4/groups/{id}/variables/{key}': "Update a group's variable. If there are multiple variables with the same key, use `filter` to select the correct `environment_scope`. ", 'get /api/v4/groups/{id}/variables/{key}': "Get the details of a group's specific variable. If there are multiple variables with the same key, use `filter` to select the correct `environment_scope`. ", 'post /api/v4/groups/{id}/variables': 'Create a new variable. ', 'get /api/v4/groups/{id}/variables': "Get list of a group's variables. ", 'get /api/v4/groups/{id}/packages': 'Get a list of project packages at the group level. When accessed without authentication, only packages of public projects are returned. By default, packages with `default` and `error` status are returned. Use the `status` parameter to view other packages. ', 'post /api/v4/groups/import': 'The maximum import file size can be set by the Administrator on self-managed instances (default is `0` (unlimited)). As an administrator, you can modify the maximum import file size either: - In the [Admin Area](../administration/settings/import_and_export_settings.md). - By using the `max_import_size` option in the [Application settings API](settings.md#change-application-settings). For information on the maximum import file size on GitLab.com, see [Account and limit settings](../user/gitlab_com/index.md#account-and-limit-settings). ', 'post /api/v4/groups/import/authorize': 'Workhorse authorize the group import upload', 'get /api/v4/groups/{id}/export_relations/status': 'View the status of the relations export: ', 'get /api/v4/groups/{id}/export_relations/download': 'Download the finished relations export: ', 'post /api/v4/groups/{id}/export_relations': 'Start a new group relations export: ', 'post /api/v4/groups/{id}/export': 'Start a new group export. ', 'get /api/v4/groups/{id}/export/download': 'Download the finished export. ', 'get /api/v4/groups/{id}/registry/repositories': 'Get a list of registry repositories in a group. ', 'delete /api/v4/groups/{id}/clusters/{cluster_id}': 'Deletes an existing group cluster. Does not remove existing resources within the connected Kubernetes cluster. ', 'put /api/v4/groups/{id}/clusters/{cluster_id}': 'Updates an existing group cluster. ', 'get /api/v4/groups/{id}/clusters/{cluster_id}': 'Gets a single group cluster. ', 'post /api/v4/groups/{id}/clusters/user': 'Adds an existing Kubernetes cluster to the group. ', 'get /api/v4/groups/{id}/clusters': 'Returns a list of group clusters. ', 'get /api/v4/groups/{id}/avatar': 'Get a group avatar. This endpoint can be accessed without authentication if the group is publicly accessible. ', 'delete /api/v4/groups/{id}/deploy_tokens/{token_id}': 'Removes a deploy token from the group. ', 'get /api/v4/groups/{id}/deploy_tokens/{token_id}': "Get a single group's deploy token by ID. ", 'post /api/v4/groups/{id}/deploy_tokens': 'Creates a new deploy token for a group. ', 'get /api/v4/groups/{id}/deploy_tokens': "Get a list of a group's deploy tokens ", 'delete /api/v4/groups/{id}/dependency_proxy/cache': 'Schedules for deletion the cached manifests and blobs for a group. This endpoint requires the Owner role for the group. ', 'post /api/v4/groups/{id}/runners/reset_registration_token': 'WARNING: Runner registration tokens, and support for certain configuration arguments, were [deprecated](https://gitlab.com/gitlab-org/gitlab/-/issues/380872) in GitLab 15.6 and will be removed in GitLab 17.0. After GitLab 17.0, you will no longer be able to reset runner registration tokens and the `reset_registration_token` endpoint will not function. Reset the runner registration token for a group. ', 'get /api/v4/groups/{id}/runners': '', 'delete /api/v4/groups/{id}/ssh_certificates/{ssh_certificates_id}': 'Removes an ssh certificate from a group.', 'post /api/v4/groups/{id}/ssh_certificates': 'Create a new SSH certificate in the group. ', 'get /api/v4/groups/{id}/ssh_certificates': '', 'get /api/v4/groups/{id}/users': 'DETAILS: **Tier:** Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated **Status:** Experiment Get a list of users for a group. This endpoint returns users that are related to a top-level group regardless of their current membership. For example, users that have a SAML identity connected to the group, or service accounts created by the group or subgroups. This endpoint is an [Experiment](../policy/experiment-beta-support.md) and might be changed or removed without notice. Requires Owner role in the group. ', 'get /api/v4/groups/{id}/provisioned_users': 'DETAILS: **Tier:** Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated Get a list of users provisioned by a given group. Does not include subgroups. Requires at least the Maintainer role on the group. ', 'post /api/v4/groups/{id}/restore': 'Get all groups that match your string in their name or path. ', 'post /api/v4/groups/{id}/ldap_sync': 'DETAILS: **Tier:** Premium, Ultimate **Offering:** Self-managed Lists LDAP group links. ', 'delete /api/v4/groups/{id}/share/{group_id}': 'Get the [push rules](../user/group/access_and_permissions.md#group-push-rules) of a group. Only available to group owners and administrators. ', 'post /api/v4/groups/{id}/share': 'Share group with another group. Returns `200` and the [group details](#details-of-a-group) on success. ', 'post /api/v4/groups/{id}/transfer': 'Transfer a group to a new parent group or promote a subgroup to a root group', 'get /api/v4/groups/{id}/transfer_locations': 'Retrieve a list of groups to which the user can transfer a group. ', 'post /api/v4/groups/{id}/projects/{project_id}': 'Transfer a project to the group namespace. Available only for admin.', 'get /api/v4/groups/{id}/descendant_groups': 'Get a list of visible descendant groups of this group. When accessed without authentication, only public groups are returned. By default, this request returns 20 results at a time because the API results [are paginated](rest/index.md#pagination).", 'get /api/v4/groups/{id}/projects/shared': 'Get a list of projects shared to this group. When accessed without authentication, only public shared projects are returned. By default, this request returns 20 results at a time because the API results [are paginated](rest/index.md#pagination). ', 'get /api/v4/groups/{id}/projects': 'Get a list of projects in this group. When accessed without authentication, only public projects are returned. By default, this request returns 20 results at a time because the API results [are paginated](rest/index.md#pagination). ', 'delete /api/v4/groups/{id}': 'Only available to group owners and administrators. This endpoint: - On Premium and Ultimate tiers, marks the group for deletion. The deletion happens 7 days later by default, but you can change the retention period in the [instance settings](../administration/settings/visibility_and_access_controls.md#deletion-protection). - On Free tier, removes the group immediately and queues a background job to delete all projects in the group. - Deletes a subgroup immediately if the subgroup is marked for deletion (GitLab 15.4 and later). The endpoint does not immediately delete top-level groups. ', 'get /api/v4/groups/{id}': 'Get all details of a group. This endpoint can be accessed without authentication if the group is publicly accessible. In case the user that requests is an administrator if the group is publicly accessible. With authentication, it returns the `runners_token` and `enabled_git_access_protocol` for the group too, if the user is an administrator or group owner. ', 'put /api/v4/groups/{id}': 'FLAG: On self-managed GitLab, by default `unique_project_download_limit`, `unique_project_download_limit_interval_in_seconds`, `unique_project_download_limit_allowlist` and `auto_ban_user_on_excessive_projects_download` are not available. To make them available, an administrator can [enable the feature flag](../administration/feature_flags.md) named `limit_unique_project_downloads_per_namespace_user`. Updates the project group. Only available to group owners and administrators. ', 'post /api/v4/groups': 'NOTE: On GitLab SaaS, you must use the GitLab UI to create groups without a parent group. You cannot use the API to do this. Creates a new project group. Available only for users who can create groups. ', 'get /api/v4/groups': 'Get a list of visible groups for the authenticated user. When accessed without authentication, only public groups are returned. By default, this request returns 20 results at a time because the API results [are paginated](rest/index.md#pagination). When accessed without authentication, this endpoint also supports [keyset pagination](rest/index.md#keyset-based-pagination): - When requesting consecutive pages of results, you should use keyset pagination. - Beyond a specific offset limit (specified by [max offset allowed by the REST API for offset-based pagination](../administration/instance_limits.md#max-offset-allowed-by-the-rest-api-for-offset-based-pagination)), offset pagination is unavailable.', 'delete /api/v4/groups/{id}/custom_attributes/{key}': 'Delete a custom attribute on a resource. ', 'put /api/v4/groups/{id}/custom_attributes/{key}': 'Set a custom attribute on a resource. The attribute is updated if it already exists, or newly created otherwise. ', 'get /api/v4/groups/{id}/custom_attributes/{key}': 'Get a single custom attribute on a resource. ', 'get /api/v4/groups/{id}/custom_attributes': 'Get all custom attributes on a resource. ', 'delete /api/v4/groups/{id}/badges/{badge_id}': 'Removes a badge from a group. ', 'put /api/v4/groups/{id}/badges/{badge_id}': 'Updates a badge of a group. ', 'get /api/v4/groups/{id}/badges/{badge_id}': 'Gets a badge of a group. ', 'post /api/v4/groups/{id}/badges': 'Adds a badge to a group. ', 'get /api/v4/groups/{id}/badges': "Gets a list of a group's badges. ", 'get /api/v4/groups/{id}/badges/render': 'Returns how the `link_url` and `image_url` final URLs would be after resolving the placeholder interpolation. ', 'delete /api/v4/groups/{id}/access_requests/{user_id}': 'Denies an access request for the given user. ', 'put /api/v4/groups/{id}/access_requests/{user_id}/approve': 'Approves an access request for the given user. ', 'post /api/v4/groups/{id}/access_requests': 'Requests access for the authenticated user to a group or project. ', 'get /api/v4/groups/{id}/access_requests': 'Gets a list of access requests viewable by the authenticated user. ', 'get /api/v4/groups/{id}/audit_events/{audit_event_id}': 'Only available to group owners and administrators. ', 'get /api/v4/groups/{id}/audit_events': '', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/InRelease': 'The signed Release file', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/Release': 'The unsigned Release file', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/Release.gpg': 'The Release file signature', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/{component}/debian-installer/binary-{architecture}/by-hash/SHA256/{file_sha256}': 'The installer (udeb) binary files index by hash', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/{component}/debian-installer/binary-{architecture}/Packages': 'The installer (udeb) binary files index', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/{component}/source/by-hash/SHA256/{file_sha256}': 'The source files index by hash', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/{component}/source/Sources': 'The source files index', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/{component}/binary-{architecture}/by-hash/SHA256/{file_sha256}': 'The binary files index by hash', 'get /api/v4/groups/{id}/-/packages/debian/dists/*distribution/{component}/binary-{architecture}/Packages': 'The binary files index', 'get /api/v4/groups/{id}/-/packages/debian/pool/{distribution}/{project_id}/{letter}/{package_name}/{package_version}/{file_name}': 'Download Debian package', 'delete /api/v4/groups/{id}/-/debian_distributions/{codename}': 'Delete a Debian Distribution', 'put /api/v4/groups/{id}/-/debian_distributions/{codename}': 'Update a Debian Distribution', 'get /api/v4/groups/{id}/-/debian_distributions/{codename}': 'Get a Debian Distribution', 'get /api/v4/groups/{id}/-/debian_distributions/{codename}/key.asc': 'Get a Debian Distribution Key', 'get /api/v4/groups/{id}/-/debian_distributions': 'Get a list of Debian Distributions', 'post /api/v4/groups/{id}/-/debian_distributions': 'Create a Debian Distribution', 'get /api/v4/groups/{id}/-/packages/npm/-/package/*package_name/dist-tags': 'Get all tags for a given an NPM package', 'delete /api/v4/groups/{id}/-/packages/npm/-/package/*package_name/dist-tags/{tag}': 'Deletes the given tag', 'put /api/v4/groups/{id}/-/packages/npm/-/package/*package_name/dist-tags/{tag}': 'Create or Update the given tag for the given NPM package and version', 'post /api/v4/groups/{id}/-/packages/npm/-/npm/v1/security/audits/quick': 'NPM registry quick audit endpoint', 'post /api/v4/groups/{id}/-/packages/npm/-/npm/v1/security/advisories/bulk': 'NPM registry bulk advisory endpoint', 'get /api/v4/groups/{id}/-/packages/npm/*package_name': 'NPM registry metadata endpoint', 'get /api/v4/groups/{id}/-/packages/nuget/index': 'The NuGet V3 Feed Service Index', 'get /api/v4/groups/{id}/-/packages/nuget/symbolfiles/*file_name/*signature/*same_file_name': 'The NuGet Symbol File Download Endpoint', 'get /api/v4/groups/{id}/-/packages/nuget/v2/$metadata': 'The NuGet V2 Feed Package $metadata endpoint', 'get /api/v4/groups/{id}/-/packages/nuget/v2': 'The NuGet V2 Feed Service Index', 'get /api/v4/groups/{id}/-/packages/nuget/metadata/*package_name/*package_version': 'The NuGet Metadata Service - Package name and version level', 'get /api/v4/groups/{id}/-/packages/nuget/metadata/*package_name/index': 'The NuGet Metadata Service - Package name level', 'get /api/v4/groups/{id}/-/packages/nuget/query': 'The NuGet Search Service', 'get /api/v4/groups/{id}/-/packages/pypi/simple/*package_name': 'The PyPi Simple Group Package Endpoint', 'get /api/v4/groups/{id}/-/packages/pypi/simple': 'The PyPi Simple Group Index Endpoint', 'get /api/v4/groups/{id}/-/packages/pypi/files/{sha256}/*file_identifier': 'Download a package file from a group', 'post /api/v4/projects/{id}/wikis/attachments': "Uploads a file to the attachment folder inside the wiki's repository. The  attachment folder is the `uploads` folder. ", 'delete /api/v4/projects/{id}/wikis/{slug}': 'Deletes a wiki page with a given slug. ', 'put /api/v4/projects/{id}/wikis/{slug}': 'Updates an existing wiki page. At least one parameter is required to update the wiki page. ', 'get /api/v4/projects/{id}/wikis/{slug}': 'Get a wiki page for a given project. ', 'post /api/v4/projects/{id}/wikis': 'Create a new wiki page for the given repository with the given title, slug, and content. ', 'get /api/v4/projects/{id}/wikis': 'Get all wiki pages for a given project. ', 'get /api/v4/projects/{id}/repository/tags/{tag_name}/signature': 'Get the [X.509 signature from a tag](../user/project/repository/signed_commits/x509.md), if it is signed. Unsigned tags return a `404 Not Found` response. ', 'delete /api/v4/projects/{id}/repository/tags/{tag_name}': 'Deletes a tag of a repository with given name. ', 'get /api/v4/projects/{id}/repository/tags/{tag_name}': 'Get a specific repository tag determined by its name. This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'post /api/v4/projects/{id}/repository/tags': 'Creates a new tag in the repository that points to the supplied ref. ', 'get /api/v4/projects/{id}/repository/tags': 'Get a list of repository tags from a project, sorted by update date and time in descending order. NOTE: If the repository is publicly accessible, authentication (`--header "PRIVATE-TOKEN: <your_access_token>"`) is not required. ', 'put /api/v4/projects/{id}/repository/submodules/{submodule}': "In some workflows, especially automated ones, it can be useful to update a submodule's reference to keep up to date other projects that use it. This endpoint allows you to update a [Git submodule](https://git-scm.com/book/en/v2/Git-Tools-Submodules) reference in a specific branch. ", 'get /api/v4/projects/{id}/merge_requests/{eventable_id}/resource_milestone_events/{event_id}': 'Returns a single milestone event for a specific project merge request ', 'get /api/v4/projects/{id}/merge_requests/{eventable_id}/resource_milestone_events': 'Gets a list of all milestone events for a single merge request. ', 'get /api/v4/projects/{id}/issues/{eventable_id}/resource_milestone_events/{event_id}': 'Returns a single milestone event for a specific project issue ', 'get /api/v4/projects/{id}/issues/{eventable_id}/resource_milestone_events': 'Gets a list of all milestone events for a single issue. ', 'post /api/v4/projects/{id}/access_tokens/{token_id}/rotate': 'Prerequisites: - You must have a [personal access token with the `api` scope](../user/profile/personal_access_tokens.md#personal-access-token-scopes). Rotate a project access token. Revokes the previous token and creates a new token that expires in one week. In GitLab 16.6 and later, you can use the `expires_at` parameter to set a different expiry date. This non-default expiry date can be up to a maximum of one year from the rotation date. ', 'post /api/v4/projects/{id}/access_tokens': 'Create a [project access token](../user/project/settings/project_access_tokens.md). When you create a project access token, the maximum role (access level) you set depends on if you have the Owner or Maintainer role for the group. For example, the maximum role that can be set is: - Owner (`50`), if you have the Owner role for the project. - Maintainer (`40`), if you have the Maintainer role on the project. ', 'get /api/v4/projects/{id}/access_tokens': 'Get a list of [project access tokens](../user/project/settings/project_access_tokens.md). ', 'delete /api/v4/projects/{id}/access_tokens/{token_id}': 'Revoke a [project access token](../user/project/settings/project_access_tokens.md). ', 'get /api/v4/projects/{id}/access_tokens/{token_id}': 'Get a [project access token](../user/project/settings/project_access_tokens.md) by ID. ', 'post /api/v4/projects/{id}/repository/changelog': "Changelogs support these attributes: | Attribute | Type     | Required   | Description | | :-------- | :------- | :--------- | :---------- | | `version` | string   | yes | The version to generate the changelog for. The format must follow [semantic versioning](https://semver.org/). | | `branch`  | string   | no | The branch to commit the changelog changes to. Defaults to the project's default branch. | | `config_file` | string   | no | Path to the changelog configuration file in the project's Git repository. Defaults to `.gitlab/changelog_config.yml`. | | `date`    | datetime | no | The date and time of the release. Defaults to the current time. | | `file`    | string   | no | The file to commit the changes to. Defaults to `CHANGELOG.md`. | | `from`    | string   | no | The SHA of the commit that marks the beginning of the range of commits to include in the changelog. This commit isn't included in the changelog. | | `message` | string   | no | The commit message to use when committing the changes. Defaults to `Add changelog for version X`, where `X` is the value of the `version` argument. | | `to`      | string   | no | The SHA of the commit that marks the end of the range of commits to include in the changelog. This commit _is_ included in the changelog. Defaults to the branch specified in the `branch` attribute. Limited to 15000 commits unless the feature flag `changelog_commits_limitation` is disabled. | | `trailer` | string   | no | The Git trailer to use for including commits. Defaults to `Changelog`. Case-sensitive: `Example` does not match `example` or `eXaMpLE`. | # ", 'get /api/v4/projects/{id}/repository/changelog': "Generate changelog data based on commits in a repository, without committing them to a changelog file. Works exactly like `POST /projects/:id/repository/changelog`, except the changelog data isn't committed to any changelog file. ", 'get /api/v4/projects/{id}/repository/merge_base': 'Get the common ancestor for 2 or more refs, such as commit SHAs, branch names, or tags. ', 'get /api/v4/projects/{id}/repository/contributors': 'Get repository contributors list. This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'get /api/v4/projects/{id}/repository/compare': 'This endpoint can be accessed without authentication if the repository is publicly accessible. Diffs can have an empty diff string if [diff limits](../development/merge_request_concepts/diffs/index.md#diff-limits) are reached. ', 'get /api/v4/projects/{id}/repository/archive': 'Get an archive of the repository', 'get /api/v4/projects/{id}/repository/blobs/{sha}': 'Allows you to receive information, such as size and content, about blobs in a repository. Blob content is Base64 encoded. This endpoint can be accessed without authentication, if the repository is publicly accessible. ', 'get /api/v4/projects/{id}/repository/blobs/{sha}/raw': 'Get the raw file contents for a blob, by blob SHA. This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'get /api/v4/projects/{id}/repository/tree': 'Get a list of repository files and directories in a project. This endpoint can be accessed without authentication if the repository is publicly accessible. This command provides essentially the same features as the `git ls-tree` command. For more information, refer to the section [Tree Objects](https://git-scm.com/book/en/v2/Git-Internals-Git-Objects/#_tree_objects) in the Git internals documentation. WARNING: This endpoint changed to [keyset-based pagination](rest/index.md#keyset-based-pagination) in GitLab 15.0. Iterating pages of results with a number (`?page=2`) is unsupported. ', 'delete /api/v4/projects/{id}/remote_mirrors/{mirror_id}': 'Delete a remote mirror. ', 'put /api/v4/projects/{id}/remote_mirrors/{mirror_id}': 'Toggle a remote mirror on or off, or change which types of branches are mirrored: ', 'get /api/v4/projects/{id}/remote_mirrors/{mirror_id}': 'Returns a remote mirror and its statuses: ', 'post /api/v4/projects/{id}/remote_mirrors': 'Push mirroring is disabled by default. To enable it, include the optional parameter `enabled` when you create the mirror: ', 'get /api/v4/projects/{id}/remote_mirrors': 'Returns an array of remote mirrors and their statuses: ', 'post /api/v4/projects/{id}/releases/{tag_name}/evidence': 'Collect release evidence', 'delete /api/v4/projects/{id}/releases/{tag_name}': 'Delete a release', 'put /api/v4/projects/{id}/releases/{tag_name}': 'Update a release', 'get /api/v4/projects/{id}/releases/{tag_name}': 'Get a release by a tag name', 'post /api/v4/projects/{id}/releases': 'Create a release', 'get /api/v4/projects/{id}/releases': 'List Releases', 'get /api/v4/projects/{id}/releases/permalink/latest(/)(*suffix_path)': 'Get the latest project release', 'get /api/v4/projects/{id}/releases/{tag_name}/downloads/*direct_asset_path': 'Download a project release asset file', 'delete /api/v4/projects/{id}/protected_tags/{name}': 'Unprotects the given protected tag or wildcard protected tag. ', 'get /api/v4/projects/{id}/protected_tags/{name}': 'Gets a single protected tag or wildcard protected tag. ', 'post /api/v4/projects/{id}/protected_tags': 'Protects a single repository tag, or several project repository tags, using a wildcard protected tag. ', 'get /api/v4/projects/{id}/protected_tags': 'Gets a list of [protected tags](../user/project/protected_tags.md) from a project. This function takes pagination parameters `page` and `per_page` to restrict the list of protected tags. ', 'delete /api/v4/projects/{id}/protected_branches/{name}': 'Unprotects the given protected branch or wildcard protected branch. ', 'patch /api/v4/projects/{id}/protected_branches/{name}': 'Updates a protected branch. ', 'get /api/v4/projects/{id}/protected_branches/{name}': 'Gets a single protected branch or wildcard protected branch. ', 'post /api/v4/projects/{id}/protected_branches': 'Protects a single repository branch or several project repository branches using a wildcard protected branch. ', 'get /api/v4/projects/{id}/protected_branches': 'Gets a list of [protected branches](../user/project/protected_branches.md) from a project as they are defined in the UI. If a wildcard is set, it is returned instead of the exact name of the branches that match that wildcard. ', 'post /api/v4/projects/{id}/restore': 'Uploads a file to the specified project to be used in an issue or merge request description, or a comment. ', 'get /api/v4/projects/{id}/storage': 'Get the path to repository storage for specified project if Gitaly Cluster is not being used. If Gitaly Cluster is being used, see [Praefect-generated replica paths](../administration/gitaly/index.md#praefect-generated-replica-paths). Available for administrators only. ', 'get /api/v4/projects/{id}/transfer_locations': 'Retrieve a list of groups to which the user can transfer a project. ', 'put /api/v4/projects/{id}/transfer': 'See the [Project documentation](../user/project/settings/migrate_projects.md#transfer-a-project-to-another-namespace) for prerequisites to transfer a project. ', 'post /api/v4/projects/{id}/repository_size': 'Start a task to recalculate repository size for a project', 'post /api/v4/projects/{id}/housekeeping': 'Get the [push rules](../user/project/repository/push_rules.md) of a project. ', 'get /api/v4/projects/{id}/groups': 'Get a list of ancestor groups for this project. ', 'get /api/v4/projects/{id}/users': 'Get the users list of a project. ', 'post /api/v4/projects/{id}/uploads': 'Uploads a file to the specified project to be used in an issue or merge request description, or a comment. ', 'post /api/v4/projects/{id}/uploads/authorize': 'Workhorse authorize the file upload', 'post /api/v4/projects/{id}/import_project_members/{project_id}': "Import members from another project. If the importing member's role in the target project is: - Maintainer, then members with the Owner role in the source project are imported with the Maintainer role. - Owner, then members with the Owner role in the source project are imported with the Owner role. ", 'delete /api/v4/projects/{id}/share/{group_id}': "Import members from another project. If the importing member's role in the target project is: - Maintainer, then members with the Owner role in the source project are imported with the Maintainer role. - Owner, then members with the Owner role in the source project are imported with the Owner role. ", 'post /api/v4/projects/{id}/share': 'Unshare the project from the group. Returns `204` and no content on success. ', 'delete /api/v4/projects/{id}/fork': 'Search for projects by name which are accessible to the authenticated user. This endpoint can be accessed without authentication if the project is publicly accessible. ', 'post /api/v4/projects/{id}/fork': 'Forks a project into the user namespace of the authenticated user or the one provided. The forking operation for a project is asynchronous and is completed in a background job. The request returns immediately. To determine whether the fork of the project has completed, query the `import_status` for the new project. ', 'post /api/v4/projects/{id}/fork/{forked_from_id}': '', 'delete /api/v4/projects/{id}': 'This endpoint: - Deletes a project including all associated resources (including issues and   merge requests). - On [Premium or Ultimate](https://about.gitlab.com/pricing/) tiers,   [delayed project deletion](../user/project/working_with_projects.md#delayed-project-deletion)   is applied if enabled. - From [GitLab 15.11](https://gitlab.com/gitlab-org/gitlab/-/issues/396500) on   [Premium or Ultimate](https://about.gitlab.com/pricing/) tiers, deletes a project immediately if the project is already   marked for deletion, and the `permanently_remove` and `full_path` parameters are passed. - From [GitLab 16.0](https://gitlab.com/gitlab-org/gitlab/-/issues/220382) on   [Premium or Ultimate](https://about.gitlab.com/pricing/) tiers, delayed project deletion is enabled by default.   The deletion happens after the number of days specified in the   [default deletion delay](../administration/settings/visibility_and_access_controls.md#deletion-protection). WARNING: The option to delete projects immediately from deletion protection settings in the Admin Area was [deprecated](https://gitlab.com/gitlab-org/gitlab/-/issues/389557) in GitLab 15.9 and removed in GitLab 16.0. ', 'put /api/v4/projects/{id}': "Updates an existing project. If your HTTP repository isn't publicly accessible, add authentication information to the URL `https://username:password@gitlab.company.com/group/project.git`, where `password` is a public access key with the `api` scope enabled. ", 'get /api/v4/projects/{id}': 'Get a specific project. This endpoint can be accessed without authentication if the project is publicly accessible. ', 'get /api/v4/projects/{id}/languages': 'Archives the project if the user is either an administrator or the owner of this project. This action is idempotent, thus archiving an already archived project does not change the project. ', 'get /api/v4/projects/{id}/starrers': 'List the users who starred the specified project. ', 'post /api/v4/projects/{id}/unstar': 'Unstars a given project. Returns status code `304` if the project is not starred. ', 'post /api/v4/projects/{id}/star': 'Stars a given project. Returns status code `304` if the project is already starred. ', 'post /api/v4/projects/{id}/unarchive': "Unarchives the project if the user is either an administrator or the owner of this project. This action is idempotent, thus unarchiving a non-archived project doesn't change the project. ", 'post /api/v4/projects/{id}/archive': 'Archives the project if the user is either an administrator or the owner of this project. This action is idempotent, thus archiving an already archived project does not change the project. ', 'get /api/v4/projects/{id}/pages_access': 'Check pages access of this project', 'get /api/v4/projects/{id}/forks': 'List the projects accessible to the calling user that have an established, forked relationship with the specified project ', 'get /api/v4/projects/{id}/share_locations': 'Get a list of groups that can be shared with a project ', 'post /api/v4/projects/user/{user_id}': "Creates a new project owned by the specified user. Available only for administrators. If your HTTP repository isn't publicly accessible, add authentication information to the URL `https://username:password@gitlab.company.com/group/project.git`, where `password` is a public access key with the `api` scope enabled. ", 'post /api/v4/projects': "Creates a new project owned by the authenticated user. If your HTTP repository isn't publicly accessible, add authentication information to the URL `https://username:password@gitlab.company.com/group/project.git`, where `password` is a public access key with the `api` scope enabled. ", 'get /api/v4/projects': 'Get a list of all visible projects across GitLab for the authenticated user. When accessed without authentication, only public projects with _simple_ fields are returned. ', 'delete /api/v4/projects/{id}/custom_attributes/{key}': 'Delete a custom attribute on a resource. ', 'put /api/v4/projects/{id}/custom_attributes/{key}': 'Set a custom attribute on a resource. The attribute is updated if it already exists, or newly created otherwise. ', 'get /api/v4/projects/{id}/custom_attributes/{key}': 'Get a single custom attribute on a resource. ', 'get /api/v4/projects/{id}/custom_attributes': 'Get all custom attributes on a resource. ', 'get /api/v4/projects/{id}/templates/{type}/{name}': '', 'get /api/v4/projects/{id}/templates/{type}': '', 'get /api/v4/projects/{id}/statistics': '', 'get /api/v4/projects/{id}/snapshot': 'Get the path to repository storage for specified project if Gitaly Cluster is not being used. If Gitaly Cluster is being used, see [Praefect-generated replica paths](../administration/gitaly/index.md#praefect-generated-replica-paths). Available for administrators only. ', 'get /api/v4/projects/{id}/snippets/{snippet_id}/user_agent_detail': 'Available only for users with administrator access. ', 'get /api/v4/projects/{id}/snippets/{snippet_id}/files/{ref}/{file_path}/raw': 'Returns the raw file content as plain text. ', 'get /api/v4/projects/{id}/snippets/{snippet_id}/raw': 'Returns the raw project snippet as plain text. ', 'delete /api/v4/projects/{id}/snippets/{snippet_id}': 'Deletes an existing project snippet. This returns a `204 No Content` status code if the operation was successfully or `404` if the resource was not found. ', 'put /api/v4/projects/{id}/snippets/{snippet_id}': 'Updates an existing project snippet. The user must have permission to change an existing snippet. Updates to snippets with multiple files must use the `files` attribute. ', 'get /api/v4/projects/{id}/snippets/{snippet_id}': 'Get a single project snippet. ', 'post /api/v4/projects/{id}/snippets': 'Creates a new project snippet. The user must have permission to create new snippets. ', 'get /api/v4/projects/{id}/snippets': 'Get a list of project snippets. ', 'post /api/v4/projects/{id}/repository_storage_moves': '', 'get /api/v4/projects/{id}/repository_storage_moves': '', 'get /api/v4/projects/{id}/repository_storage_moves/{repository_storage_move_id}': '', 'delete /api/v4/projects/{id}/packages/{package_id}': 'Deletes a project package. ', 'get /api/v4/projects/{id}/packages/{package_id}': 'Get a single project package. Only packages with status `default` are returned. ', 'get /api/v4/projects/{id}/packages/{package_id}/pipelines': 'Get a list of pipelines for a single package. The results are sorted by `id` in descending order. The results are [paginated](rest/index.md#keyset-based-pagination) and return up to 20 records per page. ', 'get /api/v4/projects/{id}/packages': 'Get a list of project packages. All package types are included in results. When accessed without authentication, only packages of public projects are returned. By default, packages with `default` and `error` status are returned. Use the `status` parameter to view other packages. ', 'delete /api/v4/projects/{id}/job_token_scope/allowlist/{target_project_id}': 'Remove a project from the [CI/CD job token inbound allowlist](../ci/jobs/ci_job_token.md#add-a-group-or-project-to-the-job-token-allowlist) of a project. ', 'delete /api/v4/projects/{id}/job_token_scope/groups_allowlist/{target_group_id}': 'Remove a group from the CI/CD job token allowlist of a project. ', 'post /api/v4/projects/{id}/job_token_scope/groups_allowlist': 'Add a group to the CI/CD job token allowlist of a project. ', 'get /api/v4/projects/{id}/job_token_scope/groups_allowlist': 'Fetch the CI/CD job token allowlist of groups (job token scope) of a project. ', 'post /api/v4/projects/{id}/job_token_scope/allowlist': 'Add a project to the [CI/CD job token inbound allowlist](../ci/jobs/ci_job_token.md#add-a-group-or-project-to-the-job-token-allowlist) of a project. ', 'get /api/v4/projects/{id}/job_token_scope/allowlist': 'Fetch the [CI/CD job token inbound allowlist](../ci/jobs/ci_job_token.md#add-a-group-or-project-to-the-job-token-allowlist) (job token scope) of a project. ', 'patch /api/v4/projects/{id}/job_token_scope': 'Patch the [**Limit access _to_ this project** setting](../ci/jobs/ci_job_token.md#add-a-group-or-project-to-the-job-token-allowlist) (job token scope) of a project. ', 'get /api/v4/projects/{id}/job_token_scope': 'Fetch the [CI/CD job token access settings](../ci/jobs/ci_job_token.md#control-job-token-access-to-your-project) (job token scope) of a project. ', 'post /api/v4/projects/remote-import-s3': '', 'post /api/v4/projects/remote-import': 'DETAILS: **Status:** Beta FLAG: On self-managed GitLab, by default this feature is available. To hide the feature, an administrator can [disable the feature flag](../administration/feature_flags.md) named `import_project_from_remote_file`. On GitLab.com and GitLab Dedicated, this feature is available. ', 'get /api/v4/projects/{id}/import': 'Get the status of an import. ', 'post /api/v4/projects/import': '', 'post /api/v4/projects/import/authorize': 'Workhorse authorize the project import upload', 'delete /api/v4/projects/{id}/hooks/{hook_id}': 'Trigger a test hook for a specified project. In GitLab 17.0 and later, this endpoint has a special rate limit of three requests per minute per project hook. To disable this limit on self-managed GitLab and GitLab Dedicated, an administrator can [disable the feature flag](../administration/feature_flags.md) named `web_hook_test_api_endpoint_rate_limit`. ', 'put /api/v4/projects/{id}/hooks/{hook_id}': 'Edits a hook for a specified project. ', 'get /api/v4/projects/{id}/hooks/{hook_id}': 'Get a specific hook for a project. ', 'post /api/v4/projects/{id}/hooks': 'Adds a hook to a specified project. ', 'get /api/v4/projects/{id}/hooks': 'Get a specific hook for a project. ', 'get /api/v4/projects/{id}/export_relations/status': 'View the status of the relations export: ', 'get /api/v4/projects/{id}/export_relations/download': 'Download the finished relations export: ', 'post /api/v4/projects/{id}/export_relations': 'Start a new project relations export: ', 'post /api/v4/projects/{id}/export': "Start a new export. The endpoint also accepts an `upload` hash parameter. It contains all the necessary information to upload the exported project to a web server or to any S3-compatible platform. For exports, GitLab: - Only supports binary data file uploads to the final server. - Sends the `Content-Type: application/gzip` header with upload requests. Ensure that your pre-signed URL includes this   as part of the signature. - Can take some time to complete the project export process. Make sure the upload URL doesn't have a short expiration   time and is available throughout the export process. - Administrators can modify the maximum export file size. By default, the maximum is unlimited (`0`). To change this,   edit `max_export_size` using either:   - [GitLab UI](../administration/settings/import_and_export_settings.md).   - [Application settings API](settings.md#change-application-settings) - Has a fixed limit for the maximum import file size on GitLab.com. For more information, see   [Account and limit settings](../user/gitlab_com/index.md#account-and-limit-settings). The `upload[url]` parameter is required if the `upload` parameter is present. For uploads to Amazon S3, refer to [Generating a pre-signed URL for uploading objects](https://docs.aws.amazon.com/AmazonS3/latest/userguide/PresignedUrlUploadObject.html) documentation scripts to generate the `upload[url]`. ", 'get /api/v4/projects/{id}/export': 'Get the status of export. ', 'get /api/v4/projects/{id}/export/download': 'Download the finished export. ', 'get /api/v4/projects/{id}/events': 'NOTE: This endpoint has been around longer than the others. Documentation was formerly located in the [Projects API pages](projects.md). Get a list of visible events for a particular project. ', 'delete /api/v4/projects/{id}/registry/repositories/{repository_id}/tags/{tag_name}': 'Delete a registry repository tag. ', 'get /api/v4/projects/{id}/registry/repositories/{repository_id}/tags/{tag_name}': 'Get details of a registry repository tag. ', 'delete /api/v4/projects/{id}/registry/repositories/{repository_id}/tags': 'Delete registry repository tags in bulk based on given criteria. <i class="fa fa-youtube-play youtube" aria-hidden="true"></i> For an overview, see [Use the container registry API to delete all tags except *](https://youtu.be/Hi19bKe_xsg). ', 'get /api/v4/projects/{id}/registry/repositories/{repository_id}/tags': 'Get a list of tags for given registry repository. ', 'delete /api/v4/projects/{id}/registry/repositories/{repository_id}': 'Delete a repository in registry. This operation is executed asynchronously and might take some time to get executed. ', 'get /api/v4/projects/{id}/registry/repositories': 'Get a list of registry repositories in a project. ', 'delete /api/v4/projects/{id}/clusters/{cluster_id}': 'Deletes an existing project cluster. Does not remove existing resources within the connected Kubernetes cluster. ', 'put /api/v4/projects/{id}/clusters/{cluster_id}': 'Updates an existing project cluster. ', 'get /api/v4/projects/{id}/clusters/{cluster_id}': 'Gets a single project cluster. ', 'post /api/v4/projects/{id}/clusters/user': 'Adds an existing Kubernetes cluster to the project. ', 'get /api/v4/projects/{id}/clusters': 'Returns a list of project clusters. ', 'get /api/v4/projects/{id}/avatar': 'To remove a project avatar, use a blank value for the `avatar` attribute. Example request: ```shell curl --request PUT --header "PRIVATE-TOKEN: <your_access_token>" \\      --data "avatar=" "https://gitlab.example.com/api/v4/projects/5" ``` ', 'delete /api/v4/projects/{id}/pages/domains/{domain}': 'Deletes an existing project Pages domain. ', 'put /api/v4/projects/{id}/pages/domains/{domain}': 'Updates an existing project Pages domain. The user must have permissions to change an existing Pages domains. ', 'get /api/v4/projects/{id}/pages/domains/{domain}': 'Get a single project Pages domain. The user must have permissions to view Pages domains. ', 'post /api/v4/projects/{id}/pages/domains': 'Creates a new Pages domain. The user must have permissions to create new Pages domains. ', 'get /api/v4/projects/{id}/pages/domains': 'Get a list of project Pages domains. The user must have permissions to view Pages domains. ', 'get /api/v4/projects/{id}/pages': 'Prerequisites: - You must have at least the Maintainer role for the project. List Pages settings for the project. ', 'delete /api/v4/projects/{id}/pages': 'Prerequisites: - You must have administrator access to the instance. Remove Pages. ', 'delete /api/v4/projects/{id}/packages/{package_id}/package_files/{package_file_id}': "WARNING: Deleting a package file may corrupt your package making it unusable or unpullable from your package manager client. When deleting a package file, be sure that you understand what you're doing. Delete a package file: ", 'get /api/v4/projects/{id}/packages/{package_id}/package_files': 'Get a list of package files of a single package. ', 'delete /api/v4/projects/{id}/metrics/user_starred_dashboards': '', 'post /api/v4/projects/{id}/metrics/user_starred_dashboards': '', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/versions/{version_id}': 'Get a single merge request diff version. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/versions': 'Get a list of merge request diff versions. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/closes_issues': 'Get all the issues that would be closed by merging the provided merge request. ', 'put /api/v4/projects/{id}/merge_requests/{merge_request_iid}/rebase': 'Automatically rebase the `source_branch` of the merge request against its `target_branch`. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/cancel_merge_when_pipeline_succeeds': '', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/merge_ref': "Merge the changes between the merge request source and target branches into `refs/merge-requests/:iid/merge` ref, of the target project repository, if possible. This ref has the state the target branch would have if a regular merge action was taken. This action isn't a regular merge action, because it doesn't change the merge request target branch state in any manner. This ref (`refs/merge-requests/:iid/merge`) isn't necessarily overwritten when submitting requests to this API, though it makes sure the ref has the latest possible state. ", 'put /api/v4/projects/{id}/merge_requests/{merge_request_iid}/merge': 'Accept and merge changes submitted with merge request using this API. ', 'put /api/v4/projects/{id}/merge_requests/{merge_request_iid}': 'Updates an existing merge request. You can change the target branch, title, or even close the MR. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}': 'Shows information about a single merge request. ', 'delete /api/v4/projects/{id}/merge_requests/{merge_request_iid}': 'Only for administrators and project owners. Deletes the merge request in question. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/pipelines': "Create a new [pipeline for a merge request](../ci/pipelines/merge_request_pipelines.md). A pipeline created from this endpoint doesn't run a regular branch/tag pipeline. It requires `.gitlab-ci.yml` to be configured with `only: [merge_requests]` to create jobs. The new pipeline can be: - A detached merge request pipeline. - A [merged results pipeline](../ci/pipelines/merged_results_pipelines.md)   if the [project setting is enabled](../ci/pipelines/merged_results_pipelines.md#enable-merged-results-pipelines). ", 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/pipelines': 'Get a list of merge request pipelines. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/diffs': 'List diffs of the files changed in a merge request. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/changes': 'WARNING: This endpoint was [deprecated](https://gitlab.com/gitlab-org/gitlab/-/issues/322117) in GitLab 15.7 and is scheduled for removal in API v5. Use the [List merge request diffs](#list-merge-request-diffs) endpoint instead. Shows information about the merge request including its files and changes. ', 'delete /api/v4/projects/{id}/merge_requests/{merge_request_iid}/context_commits': 'Delete a list of merge request context commits. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/context_commits': 'Create a list of merge request context commits. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/context_commits': 'Get a list of merge request context commits. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/commits': 'Get a list of merge request commits. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/reviewers': 'Get a list of merge request reviewers. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/participants': 'Get a list of merge request participants. ', 'post /api/v4/projects/{id}/merge_requests': 'Creates a new merge request. ', 'get /api/v4/projects/{id}/merge_requests': 'Get all merge requests for this project. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/time_stats': 'To track which state was set, who did it, and when it happened, check out [Resource state events API](resource_state_events.md#merge-requests). ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/reset_spent_time': '', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/add_spent_time': 'Adds spent time for this merge request. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/reset_time_estimate': 'Adds spent time for this merge request. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/time_estimate': 'Resets the estimated time for this merge request to 0 seconds. ', 'post /api/v4/projects/{id}/create_ci_config': 'Creates merge request for missing ci config in project', 'delete /api/v4/projects/{id}/members/{user_id}': 'Removes a user from a group or project where the user has been explicitly assigned a role. The user needs to be a group member to qualify for removal. For example, if the user was added directly to a project within the group but not this group explicitly, you cannot use this API to remove them. See [Remove a billable member from a group](#remove-a-billable-member-from-a-group) for an alternative approach. ', 'put /api/v4/projects/{id}/members/{user_id}': 'Updates a member of a group or project. ', 'get /api/v4/projects/{id}/members/{user_id}': 'Gets a member of a group or project. Returns only direct members and not inherited members through ancestor groups. ', 'post /api/v4/projects/{id}/members': 'Adds a member to a group or project. ', 'get /api/v4/projects/{id}/members': 'Gets a list of group or project members viewable by the authenticated user. Returns only direct members and not inherited members through ancestors groups. This function takes pagination parameters `page` and `per_page` to restrict the list of users. ', 'get /api/v4/projects/{id}/members/all/{user_id}': 'FLAG: On self-managed GitLab, by default this feature is available. To hide the feature per user, an administrator can [disable the feature flag](../administration/feature_flags.md) named `webui_members_inherited_users`. On GitLab.com and GitLab Dedicated, this feature is available. Gets a member of a group or project, including members inherited or invited through ancestor groups. See the corresponding [endpoint to list all inherited members](#list-all-members-of-a-group-or-project-including-inherited-and-invited-members) for details. NOTE: The invited group members have shared membership in the shared group or project. This means that if the requester is a member of a shared group or project, but not a member of an invited private group, then using this endpoint the requester can get all the shared group or project members, including the invited private group members. ', 'get /api/v4/projects/{id}/members/all': 'FLAG: On self-managed GitLab, by default this feature is available. To hide the feature per user, an administrator can [disable the feature flag](../administration/feature_flags.md) named `webui_members_inherited_users`. On GitLab.com and GitLab Dedicated, this feature is available. Gets a list of group or project members viewable by the authenticated user, including inherited members, invited users, and permissions through ancestor groups. If a user is a member of this group or project and also of one or more ancestor groups, only its membership with the highest `access_level` is returned. This represents the effective permission of the user. Members from an invited group are returned if either: - The invited group is public. - The requester is also a member of the invited group. - The requester is a member of the shared group or project. NOTE: The invited group members have shared membership in the shared group or project. This means that if the requester is a member of a shared group or project, but not a member of an invited private group, then using this endpoint the requester can get all the shared group or project members, including the invited private group members. This function takes pagination parameters `page` and `per_page` to restrict the list of users. ', 'put /api/v4/projects/{id}/packages/maven/*path/{file_name}': 'Upload the maven package file', 'get /api/v4/projects/{id}/packages/maven/*path/{file_name}': 'Download the maven package file at a project level', 'put /api/v4/projects/{id}/packages/maven/*path/{file_name}/authorize': 'Workhorse authorize the maven package file upload', 'post /api/v4/projects/{id}/ci/lint': 'Checks if CI/CD YAML configuration is valid. This endpoint has namespace specific context. ', 'get /api/v4/projects/{id}/ci/lint': "Checks if a project's `.gitlab-ci.yml` configuration in a given ref (the `content_ref` parameter, by default `HEAD` of the project's default branch) is valid. This endpoint uses all namespace specific data available, including variables and local includes. ", 'delete /api/v4/projects/{id}/issues/{issue_iid}/links/{issue_link_id}': 'Deletes an issue link, thus removes the two-way relationship. ', 'get /api/v4/projects/{id}/issues/{issue_iid}/links/{issue_link_id}': 'Gets details about an issue link. ', 'post /api/v4/projects/{id}/issues/{issue_iid}/links': 'Creates a two-way relation between two issues. The user must be allowed to update both issues to succeed. ', 'get /api/v4/projects/{id}/issues/{issue_iid}/links': "Get a list of a given issue's [linked issues](../user/project/issues/related_issues.md), sorted by the relationship creation datetime (ascending). Issues are filtered according to the user authorizations. ", 'delete /api/v4/projects/{id}/invitations/{email}': 'Deletes a pending invitation by email address. ', 'put /api/v4/projects/{id}/invitations/{email}': "Updates a pending invitation's access level or access expiry date. ", 'get /api/v4/projects/{id}/invitations': "Gets a list of invited group or project members viewable by the authenticated user. Returns invitations to direct members only, and not through inherited ancestors' groups. This function takes pagination parameters `page` and `per_page` to restrict the list of members. ", 'post /api/v4/projects/{id}/invitations': 'Adds a new member. You can specify a user ID or invite a user by email. ', 'post /api/v4/projects/{id}/integrations/slack_slash_commands/trigger': 'Trigger a slash command for slack-slash-commands', 'post /api/v4/projects/{id}/integrations/mattermost_slash_commands/trigger': 'Trigger a slash command for mattermost-slash-commands', 'get /api/v4/projects/{id}/integrations/{slug}': 'Get an integration settings', 'delete /api/v4/projects/{id}/integrations/{slug}': 'Disable an integration', 'put /api/v4/projects/{id}/integrations/mock-monitoring': 'Create/Edit Mock Monitoring integration', 'put /api/v4/projects/{id}/integrations/mock-ci': 'Disable the Mock CI integration for a project. Integration settings are reset. ', 'put /api/v4/projects/{id}/integrations/google-cloud-platform-workload-identity-federation': 'Set up the Google Cloud Identity and Access Management integration for a project. ', 'put /api/v4/projects/{id}/integrations/google-cloud-platform-artifact-registry': 'Set up the Google Artifact Management integration for a project. ', 'put /api/v4/projects/{id}/integrations/git-guardian': 'Set up the GitGuardian integration for a project. ', 'put /api/v4/projects/{id}/integrations/github': 'Set up the GitHub integration for a project. ', 'put /api/v4/projects/{id}/integrations/squash-tm': 'Get the Squash TM integration settings for a project. ', 'put /api/v4/projects/{id}/integrations/zentao': 'Create/Edit Zentao integration', 'put /api/v4/projects/{id}/integrations/webex-teams': 'Set up Webex Teams for a project. ', 'put /api/v4/projects/{id}/integrations/unify-circuit': 'Set up the Unify Circuit integration for a project. ', 'put /api/v4/projects/{id}/integrations/telegram': 'Set up the Telegram integration for a project. ', 'put /api/v4/projects/{id}/integrations/teamcity': 'Set up the JetBrains TeamCity integration for a project. The build configuration in TeamCity must use the build number format `%build.vcs.number%`. In the advanced settings for VCS root, configure monitoring for all branches so merge requests can build. ', 'put /api/v4/projects/{id}/integrations/mattermost': 'Set up Mattermost notifications for a project. ', 'put /api/v4/projects/{id}/integrations/microsoft-teams': 'Set up Microsoft Teams notifications for a project. ', 'put /api/v4/projects/{id}/integrations/slack': 'Set up Slack notifications for a project. ', 'put /api/v4/projects/{id}/integrations/clickup': 'Set up the ClickUp integration for a project. ', 'put /api/v4/projects/{id}/integrations/youtrack': 'Get the YouTrack integration settings for a project. ', 'put /api/v4/projects/{id}/integrations/ewm': 'Set up the EWM integration for a project. ', 'put /api/v4/projects/{id}/integrations/redmine': 'Get the Redmine integration settings for a project. ', 'put /api/v4/projects/{id}/integrations/pushover': 'Disable the Pushover integration for a project. Integration settings are reset. ', 'put /api/v4/projects/{id}/integrations/pumble': 'Set up the Pumble integration for a project. ', 'put /api/v4/projects/{id}/integrations/prometheus': 'Create/Edit Prometheus integration', 'put /api/v4/projects/{id}/integrations/pivotaltracker': 'Disable the Pivotal Tracker integration for a project. Integration settings are reset. ', 'put /api/v4/projects/{id}/integrations/pipelines-email': 'Set up pipeline status emails for a project. ', 'put /api/v4/projects/{id}/integrations/packagist': 'Set up the Packagist integration for a project. ', 'put /api/v4/projects/{id}/integrations/slack-slash-commands': 'Get the Slack slash commands settings for a project. ', 'put /api/v4/projects/{id}/integrations/mattermost-slash-commands': 'Disable Mattermost slash commands for a project. Integration settings are reset. ', 'put /api/v4/projects/{id}/integrations/jira': 'Set up the Jira integration for a project. ', 'put /api/v4/projects/{id}/integrations/jenkins': 'Set up the Jenkins integration for a project. ', 'put /api/v4/projects/{id}/integrations/irker': 'Set up the irker integration for a project. ', 'put /api/v4/projects/{id}/integrations/harbor': 'Set up the Harbor integration for a project. ', 'put /api/v4/projects/{id}/integrations/hangouts-chat': 'Set up the Google Chat integration for a project. ', 'put /api/v4/projects/{id}/integrations/google-play': 'Set up the Google Play integration for a project. ', 'put /api/v4/projects/{id}/integrations/gitlab-slack-application': 'Update the GitLab for Slack app integration for a project. You cannot create a GitLab for Slack app through the API because the integration requires an OAuth 2.0 token that you cannot get from the GitLab API alone. Instead, you must [install the app](../user/project/integrations/gitlab_slack_application.md#install-the-gitlab-for-slack-app) from the GitLab UI. You can then use this API endpoint to update the integration. ', 'put /api/v4/projects/{id}/integrations/external-wiki': 'Disable an external wiki for a project. Integration settings are reset. ', 'put /api/v4/projects/{id}/integrations/emails-on-push': 'Set up the emails on push integration for a project. ', 'put /api/v4/projects/{id}/integrations/drone-ci': 'Set up the Drone integration for a project. ', 'put /api/v4/projects/{id}/integrations/discord': 'Set up Discord Notifications for a project. ', 'put /api/v4/projects/{id}/integrations/diffblue-cover': 'Set up the Diffblue Cover integration for a project. ', 'put /api/v4/projects/{id}/integrations/datadog': 'Set up the Datadog integration for a project. ', 'put /api/v4/projects/{id}/integrations/custom-issue-tracker': 'Set up a custom issue tracker for a project. ', 'put /api/v4/projects/{id}/integrations/confluence': 'Set up the Confluence Workspace integration for a project. ', 'put /api/v4/projects/{id}/integrations/campfire': 'Set up the Campfire Classic integration for a project. ', 'put /api/v4/projects/{id}/integrations/buildkite': 'Set up the Buildkite integration for a project. ', 'put /api/v4/projects/{id}/integrations/bugzilla': 'Set up the Bugzilla integration for a project. ', 'put /api/v4/projects/{id}/integrations/bamboo': 'Set up the Atlassian Bamboo integration for a project. You must configure automatic revision labeling and a repository trigger in Bamboo. ', 'put /api/v4/projects/{id}/integrations/assembla': 'Set up the Assembla integration for a project. ', 'put /api/v4/projects/{id}/integrations/asana': 'Set up the Asana integration for a project. ', 'put /api/v4/projects/{id}/integrations/apple-app-store': 'Create/Edit Apple App Store integration', 'get /api/v4/projects/{id}/integrations': 'Get a list of all active project integrations. The `vulnerability_events` field is only available for GitLab Enterprise Edition. ', 'post /api/v4/projects/{id}/services/slack_slash_commands/trigger': 'Trigger a slash command for slack-slash-commands', 'post /api/v4/projects/{id}/services/mattermost_slash_commands/trigger': 'Trigger a slash command for mattermost-slash-commands', 'get /api/v4/projects/{id}/services/{slug}': 'Get an integration settings', 'delete /api/v4/projects/{id}/services/{slug}': 'Disable an integration', 'put /api/v4/projects/{id}/services/mock-monitoring': 'Create/Edit Mock Monitoring integration', 'put /api/v4/projects/{id}/services/mock-ci': 'Create/Edit Mock Ci integration', 'put /api/v4/projects/{id}/services/google-cloud-platform-workload-identity-federation': 'Create/Edit Google Cloud Platform Workload Identity Federation integration', 'put /api/v4/projects/{id}/services/google-cloud-platform-artifact-registry': 'Create/Edit Google Cloud Platform Artifact Registry integration', 'put /api/v4/projects/{id}/services/git-guardian': 'Create/Edit Git Guardian integration', 'put /api/v4/projects/{id}/services/github': 'Create/Edit Github integration', 'put /api/v4/projects/{id}/services/squash-tm': 'Create/Edit Squash Tm integration', 'put /api/v4/projects/{id}/services/zentao': 'Create/Edit Zentao integration', 'put /api/v4/projects/{id}/services/webex-teams': 'Create/Edit Webex Teams integration', 'put /api/v4/projects/{id}/services/unify-circuit': 'Create/Edit Unify Circuit integration', 'put /api/v4/projects/{id}/services/telegram': 'Create/Edit Telegram integration', 'put /api/v4/projects/{id}/services/teamcity': 'Create/Edit Teamcity integration', 'put /api/v4/projects/{id}/services/mattermost': 'Create/Edit Mattermost integration', 'put /api/v4/projects/{id}/services/microsoft-teams': 'Create/Edit Microsoft Teams integration', 'put /api/v4/projects/{id}/services/slack': 'Create/Edit Slack integration', 'put /api/v4/projects/{id}/services/clickup': 'Create/Edit Clickup integration', 'put /api/v4/projects/{id}/services/youtrack': 'Create/Edit Youtrack integration', 'put /api/v4/projects/{id}/services/ewm': 'Create/Edit Ewm integration', 'put /api/v4/projects/{id}/services/redmine': 'Create/Edit Redmine integration', 'put /api/v4/projects/{id}/services/pushover': 'Create/Edit Pushover integration', 'put /api/v4/projects/{id}/services/pumble': 'Create/Edit Pumble integration', 'put /api/v4/projects/{id}/services/prometheus': 'Create/Edit Prometheus integration', 'put /api/v4/projects/{id}/services/pivotaltracker': 'Create/Edit Pivotaltracker integration', 'put /api/v4/projects/{id}/services/pipelines-email': 'Create/Edit Pipelines Email integration', 'put /api/v4/projects/{id}/services/packagist': 'Create/Edit Packagist integration', 'put /api/v4/projects/{id}/services/slack-slash-commands': 'Create/Edit Slack Slash Commands integration', 'put /api/v4/projects/{id}/services/mattermost-slash-commands': 'Create/Edit Mattermost Slash Commands integration', 'put /api/v4/projects/{id}/services/jira': 'Create/Edit Jira integration', 'put /api/v4/projects/{id}/services/jenkins': 'Create/Edit Jenkins integration', 'put /api/v4/projects/{id}/services/irker': 'Create/Edit Irker integration', 'put /api/v4/projects/{id}/services/harbor': 'Create/Edit Harbor integration', 'put /api/v4/projects/{id}/services/hangouts-chat': 'Create/Edit Hangouts Chat integration', 'put /api/v4/projects/{id}/services/google-play': 'Create/Edit Google Play integration', 'put /api/v4/projects/{id}/services/gitlab-slack-application': 'Create/Edit Gitlab Slack Application integration', 'put /api/v4/projects/{id}/services/external-wiki': 'Create/Edit External Wiki integration', 'put /api/v4/projects/{id}/services/emails-on-push': 'Create/Edit Emails On Push integration', 'put /api/v4/projects/{id}/services/drone-ci': 'Create/Edit Drone Ci integration', 'put /api/v4/projects/{id}/services/discord': 'Create/Edit Discord integration', 'put /api/v4/projects/{id}/services/diffblue-cover': 'Create/Edit Diffblue Cover integration', 'put /api/v4/projects/{id}/services/datadog': 'Create/Edit Datadog integration', 'put /api/v4/projects/{id}/services/custom-issue-tracker': 'Create/Edit Custom Issue Tracker integration', 'put /api/v4/projects/{id}/services/confluence': 'Create/Edit Confluence integration', 'put /api/v4/projects/{id}/services/campfire': 'Create/Edit Campfire integration', 'put /api/v4/projects/{id}/services/buildkite': 'Create/Edit Buildkite integration', 'put /api/v4/projects/{id}/services/bugzilla': 'Create/Edit Bugzilla integration', 'put /api/v4/projects/{id}/services/bamboo': 'Create/Edit Bamboo integration', 'put /api/v4/projects/{id}/services/assembla': 'Create/Edit Assembla integration', 'put /api/v4/projects/{id}/services/asana': 'Create/Edit Asana integration', 'put /api/v4/projects/{id}/services/apple-app-store': 'Create/Edit Apple App Store integration', 'get /api/v4/projects/{id}/services': 'List all active integrations', 'delete /api/v4/projects/{id}/freeze_periods/{freeze_period_id}': 'Delete a freeze period for the given `freeze_period_id`. ', 'put /api/v4/projects/{id}/freeze_periods/{freeze_period_id}': 'Update a freeze period for the given `freeze_period_id`. ', 'get /api/v4/projects/{id}/freeze_periods/{freeze_period_id}': 'Get a freeze period for the given `freeze_period_id`. ', 'post /api/v4/projects/{id}/freeze_periods': 'Create a freeze period. ', 'get /api/v4/projects/{id}/freeze_periods': 'Paginated list of freeze periods, sorted by `created_at` in ascending order. ', 'delete /api/v4/projects/{id}/repository/files/{file_path}': 'This allows you to delete a single file. For deleting multiple files with a single request, refer to the [commits API](commits.md#create-a-commit-with-multiple-files-and-actions). ', 'put /api/v4/projects/{id}/repository/files/{file_path}': 'Allows you to update a single file. For updating multiple files with a single request, refer to the [commits API](commits.md#create-a-commit-with-multiple-files-and-actions). ', 'post /api/v4/projects/{id}/repository/files/{file_path}': 'Allows you to create a single file. For creating multiple files with a single request, refer to the [commits API](commits.md#create-a-commit-with-multiple-files-and-actions). ', 'get /api/v4/projects/{id}/repository/files/{file_path}': 'Allows you to receive information about file in repository like name, size, and content. File content is Base64 encoded. This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'head /api/v4/projects/{id}/repository/files/{file_path}': 'Allows you to receive information about file in repository like name, size, and content. File content is Base64 encoded. This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'get /api/v4/projects/{id}/repository/files/{file_path}/raw': '', 'get /api/v4/projects/{id}/repository/files/{file_path}/blame': 'Allows you to receive blame information. Each blame range contains lines and corresponding commit information. ', 'head /api/v4/projects/{id}/repository/files/{file_path}/blame': 'Get blame file metadata from repository', 'put /api/v4/projects/{id}/error_tracking/settings': 'The API allows you to create Error Tracking settings for a project. Only for users with Maintainer role for the project. NOTE: This API is only available when used with [integrated error tracking](../operations/error_tracking.md#integrated-error-tracking). ', 'patch /api/v4/projects/{id}/error_tracking/settings': 'The API allows you to enable or disable the Error Tracking settings for a project. Only for users with the Maintainer role for the project. ', 'get /api/v4/projects/{id}/error_tracking/settings': '', 'get /api/v4/projects/{id}/environments/{environment_id}': '', 'delete /api/v4/projects/{id}/environments/{environment_id}': 'It returns `204` if the environment was successfully deleted, and `404` if the environment does not exist. The environment must be stopped first, otherwise the request returns `403`. ', 'put /api/v4/projects/{id}/environments/{environment_id}': "Updates an existing environment's name and/or `external_url`. It returns `200` if the environment was successfully updated. In case of an error, a status code `400` is returned. ", 'post /api/v4/projects/{id}/environments/stop_stale': 'Issue stop request to all environments that were last modified or deployed to before a specified date. Excludes protected environments. Returns `200` if stop request was successful and `400` if the before date is invalid. For details of exactly when the environment is stopped, see [Stop an environment](../ci/environments/index.md#stopping-an-environment). ', 'post /api/v4/projects/{id}/environments/{environment_id}/stop': 'It returns `200` if the environment was successfully stopped, and `404` if the environment does not exist. ', 'delete /api/v4/projects/{id}/environments/review_apps': 'It schedules for deletion multiple environments that have already been [stopped](../ci/environments/index.md#stopping-an-environment) and are [in the review app folder](../ci/review_apps/index.md). The actual deletion is performed after 1 week from the time of execution. By default, it only deletes environments 30 days or older. You can change this default using the `before` parameter. ', 'post /api/v4/projects/{id}/environments': 'Creates a new environment with the given name and `external_url`. It returns `201` if the environment was successfully created, `400` for wrong parameters. ', 'get /api/v4/projects/{id}/environments': 'Get all environments for a given project. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes/bulk_publish': 'Bulk publishes all existing draft notes for a given merge request that belong to the user. ', 'put /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes/{draft_note_id}/publish': 'Publishes an existing draft note for a given merge request. ', 'delete /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes/{draft_note_id}': 'Deletes an existing draft note for a given merge request. ', 'put /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes/{draft_note_id}': 'Modify a draft note for a given merge request. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes/{draft_note_id}': 'Returns a single draft note for a given merge request. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes': 'Create a draft note for a given merge request. ', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/draft_notes': 'Gets a list of all draft notes for a single merge request. ', 'post /api/v4/projects/{id}/deployments/{deployment_id}/approval': 'DETAILS: **Tier:** Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated See [Deployment Approvals](../ci/environments/deployment_approvals.md) for more information about this feature. ', 'get /api/v4/projects/{id}/deployments/{deployment_id}/merge_requests': 'NOTE: Not all deployments can be associated with merge requests. See [Track what merge requests were deployed to an environment](../ci/environments/index.md#track-newly-included-merge-requests-per-deployment) for more information. This API retrieves the list of merge requests shipped with a given deployment: ', 'delete /api/v4/projects/{id}/deployments/{deployment_id}': 'Delete a specific deployment that is not currently the last deployment for an environment or in a `running` state ', 'put /api/v4/projects/{id}/deployments/{deployment_id}': '', 'get /api/v4/projects/{id}/deployments/{deployment_id}': '', 'post /api/v4/projects/{id}/deployments': '', 'get /api/v4/projects/{id}/deployments': 'Get a list of deployments in a project. ', 'delete /api/v4/projects/{id}/deploy_tokens/{token_id}': 'Removes a deploy token from the project. ', 'get /api/v4/projects/{id}/deploy_tokens/{token_id}': "Get a single project's deploy token by ID. ", 'post /api/v4/projects/{id}/deploy_tokens': 'Creates a new deploy token for a project. ', 'get /api/v4/projects/{id}/deploy_tokens': "Get a list of a project's deploy tokens. ", 'delete /api/v4/projects/{id}/deploy_keys/{key_id}': "Removes a deploy key from the project. If the deploy key is used only for this project, it's deleted from the system. ", 'put /api/v4/projects/{id}/deploy_keys/{key_id}': 'Updates a deploy key for a project. ', 'get /api/v4/projects/{id}/deploy_keys/{key_id}': 'Get a single key. ', 'post /api/v4/projects/{id}/deploy_keys/{key_id}/enable': 'Enables a deploy key for a project so this can be used. Returns the enabled key, with a status code 201 when successful. ', 'post /api/v4/projects/{id}/deploy_keys': "Creates a new deploy key for a project. If the deploy key already exists in another project, it's joined to the current project only if the original one is accessible by the same user. ", 'get /api/v4/projects/{id}/deploy_keys': "Get a list of a project's deploy keys. ", 'post /api/v4/projects/{id}/statuses/{sha}': "Add or update the pipeline status of a commit. If the commit is associated with a merge request, the API call must target the commit in the merge request's source branch. ", 'get /api/v4/projects/{id}/repository/commits/{sha}/statuses': 'List the statuses of a commit in a project. The pagination parameters `page` and `per_page` can be used to restrict the list of references. ', 'get /api/v4/projects/{id}/repository/commits/{sha}/signature': 'Get the [signature from a commit](../user/project/repository/signed_commits), if it is signed. For unsigned commits, it results in a 404 response. ', 'get /api/v4/projects/{id}/repository/commits/{sha}/merge_requests': 'Returns information about the merge request that originally introduced a specific commit. ', 'post /api/v4/projects/{id}/repository/commits/{sha}/comments': 'Adds a comment to a commit. To post a comment in a particular line of a particular file, you must specify the full commit SHA, the `path`, the `line`, and `line_type` should be `new`. The comment is added at the end of the last commit if at least one of the cases below is valid: - the `sha` is instead a branch or a tag and the `line` or `path` are invalid - the `line` number is invalid (does not exist) - the `path` is invalid (does not exist) In any of the above cases, the response of `line`, `line_type` and `path` is set to `null`. For other approaches to commenting on a merge request, see [Create new merge request note](notes.md#create-new-merge-request-note) in the Notes API, and [Create a new thread in the merge request diff](discussions.md#create-a-new-thread-in-the-merge-request-diff) in the Discussions API. ', 'get /api/v4/projects/{id}/repository/commits/{sha}/comments': 'Get the comments of a commit in a project. ', 'get /api/v4/projects/{id}/repository/commits/{sha}/refs': 'Get all references (from branches or tags) a commit is pushed to. The pagination parameters `page` and `per_page` can be used to restrict the list of references. ', 'post /api/v4/projects/{id}/repository/commits/{sha}/revert': 'Reverts a commit in a given branch. ', 'post /api/v4/projects/{id}/repository/commits/{sha}/cherry_pick': 'Cherry-picks a commit to a given branch. ', 'get /api/v4/projects/{id}/repository/commits/{sha}/sequence': 'Get the sequence number of a commit in a project by following the parent links from the given commit. This API provides essentially the same features as the `git rev-list --count` command for a given commit SHA. ', 'get /api/v4/projects/{id}/repository/commits/{sha}/diff': 'Get the diff of a commit in a project. ', 'get /api/v4/projects/{id}/repository/commits/{sha}': 'Get a specific commit identified by the commit hash or name of a branch or tag. ', 'post /api/v4/projects/{id}/repository/commits': 'Create a commit by posting a JSON payload ', 'get /api/v4/projects/{id}/repository/commits': 'Get a list of repository commits in a project. ', 'delete /api/v4/projects/{id}/cluster_agents/{agent_id}': 'Deletes an existing agent registration. You must have at least the Maintainer role to use this endpoint. ', 'get /api/v4/projects/{id}/cluster_agents/{agent_id}': 'Gets a single agent details. You must have at least the Developer role to use this endpoint. ', 'post /api/v4/projects/{id}/cluster_agents': 'Registers an agent to the project. You must have at least the Maintainer role to use this endpoint. ', 'get /api/v4/projects/{id}/cluster_agents': 'Returns the list of agents registered for the project. You must have at least the Developer role to use this endpoint. ', 'delete /api/v4/projects/{id}/variables/{key}': "Delete a project's variable. If there are multiple variables with the same key, use `filter` to select the correct `environment_scope`. ", 'put /api/v4/projects/{id}/variables/{key}': "Update a project's variable. If there are multiple variables with the same key, use `filter` to select the correct `environment_scope`. ", 'get /api/v4/projects/{id}/variables/{key}': 'Get the details of a single variable. If there are multiple variables with the same key, use `filter` to select the correct `environment_scope`. ', 'post /api/v4/projects/{id}/variables': 'Create a new variable. If a variable with the same `key` already exists, the new variable must have a different `environment_scope`. Otherwise, GitLab returns a message similar to: `VARIABLE_NAME has already been taken`. ', 'get /api/v4/projects/{id}/variables': "Get list of a project's variables. ", 'delete /api/v4/projects/{id}/triggers/{trigger_id}': "Remove a project's pipeline trigger token. ", 'put /api/v4/projects/{id}/triggers/{trigger_id}': "Update a project's pipeline trigger token. ", 'get /api/v4/projects/{id}/triggers/{trigger_id}': "Get details of a project's pipeline trigger token. ", 'post /api/v4/projects/{id}/triggers': 'Create a pipeline trigger token for a project. ', 'get /api/v4/projects/{id}/triggers': "Get a list of a project's pipeline trigger tokens. ", 'post /api/v4/projects/{id}/(ref/{ref}/)trigger/pipeline': 'Trigger a GitLab project pipeline', 'delete /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}/variables/{key}': 'Delete the variable of a pipeline schedule. ', 'put /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}/variables/{key}': 'Updates the variable of a pipeline schedule. ', 'post /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}/variables': 'Create a new variable of a pipeline schedule. ', 'post /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}/play': 'Trigger a new scheduled pipeline, which runs immediately. The next scheduled run of this pipeline is not affected. ', 'delete /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}': 'Delete the pipeline schedule of a project. ', 'put /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}': 'Updates the pipeline schedule of a project. After the update is done, it is rescheduled automatically. ', 'get /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}': 'Get the pipeline schedule of a project. ', 'post /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}/take_ownership': 'Update the owner of the pipeline schedule of a project. ', 'post /api/v4/projects/{id}/pipeline_schedules': 'Create a new pipeline schedule of a project. ', 'get /api/v4/projects/{id}/pipeline_schedules': 'Get a list of the pipeline schedules of a project. ', 'get /api/v4/projects/{id}/pipeline_schedules/{pipeline_schedule_id}/pipelines': 'Get all pipelines triggered by a pipeline schedule in a project. ', 'post /api/v4/projects/{id}/pipelines/{pipeline_id}/cancel': '', 'post /api/v4/projects/{id}/pipelines/{pipeline_id}/retry': 'Retry failed or canceled jobs in a pipeline. If there are no failed or canceled jobs in the pipeline, calling this endpoint has no effect. ', 'put /api/v4/projects/{id}/pipelines/{pipeline_id}/metadata': 'You can update the metadata of a pipeline. The metadata contains the name of the pipeline. ', 'delete /api/v4/projects/{id}/pipelines/{pipeline_id}': 'Deleting a pipeline expires all pipeline caches, and deletes all immediately related objects, such as builds, logs, artifacts, and triggers. **This action cannot be undone.** Deleting a pipeline does not automatically delete its [child pipelines](../ci/pipelines/downstream_pipelines.md#parent-child-pipelines). See the [related issue](https://gitlab.com/gitlab-org/gitlab/-/issues/39503) for details. ', 'get /api/v4/projects/{id}/pipelines/{pipeline_id}': 'Get one pipeline from a project. You can also get a single [child pipeline](../ci/pipelines/downstream_pipelines.md#parent-child-pipelines). ', 'get /api/v4/projects/{id}/pipelines/{pipeline_id}/test_report_summary': 'NOTE: This API route is part of the [Unit test report](../ci/testing/unit_test_reports.md) feature. ', 'get /api/v4/projects/{id}/pipelines/{pipeline_id}/test_report': 'NOTE: This API route is part of the [Unit test report](../ci/testing/unit_test_reports.md) feature. ', 'get /api/v4/projects/{id}/pipelines/{pipeline_id}/variables': '', 'get /api/v4/projects/{id}/pipelines/{pipeline_id}/bridges': 'Get a list of trigger jobs for a pipeline. ', 'get /api/v4/projects/{id}/pipelines/{pipeline_id}/jobs': 'Get a list of jobs for a pipeline. By default, this request returns 20 results at a time because the API results [are paginated](rest/index.md#pagination) This endpoint: - [Returns data for any pipeline](pipelines.md#get-a-single-pipeline) including [child pipelines](../ci/pipelines/downstream_pipelines.md#parent-child-pipelines). - Does not return retried jobs in the response by default. - Sorts jobs by ID in descending order (newest first). ', 'get /api/v4/projects/{id}/pipelines/latest': 'Get the latest pipeline for the most recent commit on a specific ref in a project. If no pipeline exists for the commit, a `403` status code is returned. ', 'post /api/v4/projects/{id}/pipeline': '', 'get /api/v4/projects/{id}/pipelines': 'List pipelines in a project. By default, [child pipelines](../ci/pipelines/downstream_pipelines.md#parent-child-pipelines) are not included in the results. To return child pipelines, set `source` to `parent_pipeline`. ', 'delete /api/v4/projects/{id}/secure_files/{secure_file_id}': "Remove a project's secure file. ", 'get /api/v4/projects/{id}/secure_files/{secure_file_id}': 'Get the details of a specific secure file in a project. ', 'post /api/v4/projects/{id}/secure_files': 'Create a new secure file. ', 'get /api/v4/projects/{id}/secure_files': 'Get list of secure files in a project. ', 'get /api/v4/projects/{id}/secure_files/{secure_file_id}/download': "Download the contents of a project's secure file. ", 'post /api/v4/projects/{id}/runners/reset_registration_token': 'WARNING: Runner registration tokens, and support for certain configuration arguments, were [deprecated](https://gitlab.com/gitlab-org/gitlab/-/issues/380872) in GitLab 15.6 and will be removed in GitLab 17.0. After GitLab 17.0, you will no longer be able to reset runner registration tokens and the `reset_registration_token` endpoint will not function. Reset the runner registration token for a project. ', 'delete /api/v4/projects/{id}/runners/{runner_id}': "Disable a project runner from the project. It works only if the project isn't the only project associated with the specified runner. If so, an error is returned. Use the call to [delete a runner](#delete-a-runner) instead. ", 'post /api/v4/projects/{id}/runners': 'Enable an available project runner in the project. ', 'get /api/v4/projects/{id}/runners': '', 'put /api/v4/projects/{id}/resource_groups/{key}': "Updates an existing resource group's properties. It returns `200` if the resource group was successfully updated. In case of an error, a status code `400` is returned. ", 'get /api/v4/projects/{id}/resource_groups/{key}': '', 'get /api/v4/projects/{id}/resource_groups/{key}/upcoming_jobs': '', 'get /api/v4/projects/{id}/resource_groups': '', 'post /api/v4/projects/{id}/jobs/{job_id}/play': 'For a job in manual status, trigger an action to start the job. ', 'post /api/v4/projects/{id}/jobs/{job_id}/erase': 'Erase a single job of a project (remove job artifacts and a job log) ', 'post /api/v4/projects/{id}/jobs/{job_id}/retry': 'Retry a single job of a project ', 'post /api/v4/projects/{id}/jobs/{job_id}/cancel': 'Cancel a single job of a project ', 'get /api/v4/projects/{id}/jobs/{job_id}/trace': 'Get a log (trace) of a specific job of a project: ', 'get /api/v4/projects/{id}/jobs/{job_id}': 'Get a single job of a project ', 'get /api/v4/projects/{id}/jobs': 'Get a list of jobs in a project. Jobs are sorted in descending order of their IDs. By default, this request returns 20 results at a time because the API results [are paginated](rest/index.md#pagination) NOTE: This endpoint supports both offset-based and [keyset-based](rest/index.md#keyset-based-pagination) pagination, but keyset-based pagination is strongly recommended when requesting consecutive pages of results. ', 'delete /api/v4/projects/{id}/artifacts': 'Delete artifacts eligible for deletion in a project. By default, artifacts from [the most recent successful pipeline of each ref](../ci/jobs/job_artifacts.md#keep-artifacts-from-most-recent-successful-jobs) are not deleted. Requests to this endpoint set the expiry of all artifacts that can be deleted to the current time. The files are then deleted from the system as part of the regular cleanup of expired job artifacts. Job logs are never deleted. The regular cleanup occurs asynchronously on a schedule, so there might be a short delay before artifacts are deleted. Prerequisites: - You must have at least the Maintainer role for the project. ', 'delete /api/v4/projects/{id}/jobs/{job_id}/artifacts': 'Delete artifacts of a job. Prerequisites: - Must have at least the maintainer role in the project. ', 'get /api/v4/projects/{id}/jobs/{job_id}/artifacts': "Get the job's artifacts zipped archive of a project. If you use cURL to download artifacts from GitLab.com, use the `--location` parameter as the request might redirect through a CDN. ", 'post /api/v4/projects/{id}/jobs/{job_id}/artifacts/keep': 'Prevents artifacts from being deleted when expiration is set. ', 'get /api/v4/projects/{id}/jobs/{job_id}/artifacts/*artifact_path': "Download a single artifact file from a job with a specified ID from inside the job's artifacts zipped archive. The file is extracted from the archive and streamed to the client. If you use cURL to download artifacts from GitLab.com, use the `--location` parameter as the request might redirect through a CDN. ", 'get /api/v4/projects/{id}/jobs/artifacts/{ref_name}/raw/*artifact_path': 'Download a specific file from artifacts archive from a ref', 'get /api/v4/projects/{id}/jobs/artifacts/{ref_name}/download': 'Download the artifacts archive from a job', 'delete /api/v4/projects/{id}/repository/merged_branches': "Deletes all branches that are merged into the project's default branch. NOTE: [Protected branches](../user/project/protected_branches.md) are not deleted as part of this operation. ", 'delete /api/v4/projects/{id}/repository/branches/{branch}': 'Delete a branch from the repository. NOTE: In the case of an error, an explanation message is provided. ', 'get /api/v4/projects/{id}/repository/branches/{branch}': 'Get a single project repository branch. NOTE: This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'head /api/v4/projects/{id}/repository/branches/{branch}': 'Check if a branch exists', 'post /api/v4/projects/{id}/repository/branches': 'Create a new branch in the repository. ', 'get /api/v4/projects/{id}/repository/branches': 'Get a list of repository branches from a project, sorted by name alphabetically. NOTE: This endpoint can be accessed without authentication if the repository is publicly accessible. ', 'put /api/v4/projects/{id}/repository/branches/{branch}/unprotect': 'Unprotect a single branch', 'put /api/v4/projects/{id}/repository/branches/{branch}/protect': 'Protect a single branch', 'delete /api/v4/projects/{id}/badges/{badge_id}': 'Removes a badge from a project. Only project badges are removed by using this endpoint. ', 'put /api/v4/projects/{id}/badges/{badge_id}': 'Updates a badge of a project. ', 'get /api/v4/projects/{id}/badges/{badge_id}': 'Gets a badge of a project. ', 'post /api/v4/projects/{id}/badges': 'Adds a badge to a project. ', 'get /api/v4/projects/{id}/badges': "Gets a list of a project's badges and its group badges. ", 'get /api/v4/projects/{id}/badges/render': 'Returns how the `link_url` and `image_url` final URLs would be after resolving the placeholder interpolation. ', 'delete /api/v4/projects/{id}/access_requests/{user_id}': 'Denies an access request for the given user. ', 'put /api/v4/projects/{id}/access_requests/{user_id}/approve': 'Approves an access request for the given user. ', 'post /api/v4/projects/{id}/access_requests': 'Requests access for the authenticated user to a group or project. ', 'get /api/v4/projects/{id}/access_requests': 'Gets a list of access requests viewable by the authenticated user. ', 'delete /api/v4/projects/{id}/alert_management_alerts/{alert_iid}/metric_images/{metric_image_id}': '', 'put /api/v4/projects/{id}/alert_management_alerts/{alert_iid}/metric_images/{metric_image_id}': '', 'get /api/v4/projects/{id}/alert_management_alerts/{alert_iid}/metric_images': '', 'post /api/v4/projects/{id}/alert_management_alerts/{alert_iid}/metric_images': '', 'post /api/v4/projects/{id}/alert_management_alerts/{alert_iid}/metric_images/authorize': 'Workhorse authorize metric image file upload', 'delete /api/v4/projects/{id}/cluster_agents/{agent_id}/tokens/{token_id}': 'Revokes an agent token. You must have at least the Maintainer role to use this endpoint. ', 'get /api/v4/projects/{id}/cluster_agents/{agent_id}/tokens/{token_id}': 'Gets a single agent token. You must have at least the Developer role to use this endpoint. Returns a `404` if the agent token has been revoked. ', 'post /api/v4/projects/{id}/cluster_agents/{agent_id}/tokens': 'Creates a new token for an agent. You must have at least the Maintainer role to use this endpoint. An agent can have only two active tokens at one time. ', 'get /api/v4/projects/{id}/cluster_agents/{agent_id}/tokens': 'Returns a list of active tokens for an agent. You must have at least the Developer role to use this endpoint. ', 'get /api/v4/projects/{id}/packages/composer/archives/*package_name': 'Composer package endpoint to download a package archive', 'post /api/v4/projects/{id}/packages/composer': 'Composer packages endpoint for registering packages', 'get /api/v4/projects/{id}/packages/conan/v1/conans/search': 'Search for packages', 'get /api/v4/projects/{id}/packages/conan/v1/ping': 'Ping the Conan API', 'get /api/v4/projects/{id}/packages/conan/v1/users/check_credentials': 'Check for valid user credentials per conan CLI', 'get /api/v4/projects/{id}/packages/conan/v1/users/authenticate': 'Authenticate user against conan CLI', 'delete /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}': 'Delete Package', 'get /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}': 'Recipe Snapshot', 'post /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/upload_urls': 'Recipe Upload Urls', 'post /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}/upload_urls': 'Package Upload Urls', 'get /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/download_urls': 'Recipe Download Urls', 'get /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}/download_urls': 'Package Download Urls', 'get /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/digest': 'Recipe Digest', 'get /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}/digest': 'Package Digest', 'get /api/v4/projects/{id}/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}': 'Package Snapshot', 'put /api/v4/projects/{id}/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/export/{file_name}/authorize': 'Workhorse authorize the conan recipe file', 'put /api/v4/projects/{id}/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/export/{file_name}': 'Upload recipe package files', 'get /api/v4/projects/{id}/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/export/{file_name}': 'Download recipe files', 'put /api/v4/projects/{id}/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/package/{conan_package_reference}/{package_revision}/{file_name}': 'Upload package files', 'get /api/v4/projects/{id}/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/package/{conan_package_reference}/{package_revision}/{file_name}': 'Download package files', 'put /api/v4/projects/{id}/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/package/{conan_package_reference}/{package_revision}/{file_name}/authorize': 'Workhorse authorize the conan package file', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/InRelease': 'The signed Release file', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/Release': 'The unsigned Release file', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/Release.gpg': 'The Release file signature', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/{component}/debian-installer/binary-{architecture}/by-hash/SHA256/{file_sha256}': 'The installer (udeb) binary files index by hash', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/{component}/debian-installer/binary-{architecture}/Packages': 'The installer (udeb) binary files index', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/{component}/source/by-hash/SHA256/{file_sha256}': 'The source files index by hash', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/{component}/source/Sources': 'The source files index', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/{component}/binary-{architecture}/by-hash/SHA256/{file_sha256}': 'The binary files index by hash', 'get /api/v4/projects/{id}/packages/debian/dists/*distribution/{component}/binary-{architecture}/Packages': 'The binary files index', 'get /api/v4/projects/{id}/packages/debian/pool/{distribution}/{letter}/{package_name}/{package_version}/{file_name}': 'Download Debian package', 'put /api/v4/projects/{id}/packages/debian/{file_name}/authorize': 'Authorize Debian package upload', 'put /api/v4/projects/{id}/packages/debian/{file_name}': 'Upload Debian package', 'delete /api/v4/projects/{id}/error_tracking/client_keys/{key_id}': 'Removes a client key from the project. ', 'post /api/v4/projects/{id}/error_tracking/client_keys': 'Creates a new client key for a project. The public key attribute is generated automatically. ', 'get /api/v4/projects/{id}/error_tracking/client_keys': '', 'post /api/v4/projects/{id}/feature_flags': 'Creates a new feature flag. ', 'get /api/v4/projects/{id}/feature_flags': 'Gets all feature flags of the requested project. ', 'delete /api/v4/projects/{id}/feature_flags/{feature_flag_name}': 'Deletes a feature flag. ', 'put /api/v4/projects/{id}/feature_flags/{feature_flag_name}': 'Updates a feature flag. ', 'get /api/v4/projects/{id}/feature_flags/{feature_flag_name}': 'Gets a single feature flag. ', 'post /api/v4/projects/{id}/feature_flags_user_lists': 'Creates a feature flag user list. ', 'get /api/v4/projects/{id}/feature_flags_user_lists': 'Gets all feature flag user lists for the requested project. ', 'delete /api/v4/projects/{id}/feature_flags_user_lists/{iid}': 'Deletes a feature flag user list. ', 'put /api/v4/projects/{id}/feature_flags_user_lists/{iid}': 'Updates a feature flag user list. ', 'get /api/v4/projects/{id}/feature_flags_user_lists/{iid}': 'Gets a feature flag user list. ', 'get /api/v4/projects/{id}/packages/generic/{package_name}/*package_version/{file_name}': 'Download package file', 'put /api/v4/projects/{id}/packages/generic/{package_name}/*package_version/{file_name}': 'Upload package file', 'put /api/v4/projects/{id}/packages/generic/{package_name}/*package_version/{file_name}/authorize': 'Workhorse authorize generic package file', 'get /api/v4/projects/{id}/packages/go/*module_name/@v/{module_version}.zip': 'Download module source', 'get /api/v4/projects/{id}/packages/go/*module_name/@v/{module_version}.mod': 'Download module file', 'get /api/v4/projects/{id}/packages/go/*module_name/@v/{module_version}.info': 'Version metadata', 'get /api/v4/projects/{id}/packages/go/*module_name/@v/list': 'List', 'post /api/v4/projects/{id}/packages/helm/api/{channel}/charts': 'Upload a chart', 'post /api/v4/projects/{id}/packages/helm/api/{channel}/charts/authorize': 'Authorize a chart upload from workhorse', 'get /api/v4/projects/{id}/packages/helm/{channel}/charts/{file_name}.tgz': 'Download a chart', 'get /api/v4/projects/{id}/packages/helm/{channel}/index.yaml': 'Download a chart index', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/approvals': 'Deprecated in 16.0: Use the merge request approvals API instead. Change approval-related configuration', 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/approvals': "Configuration for approvals on a specific merge request. Must be authenticated for all endpoints. You can request information about a merge request's approval status using the following endpoint: ", 'get /api/v4/projects/{id}/merge_requests/{merge_request_iid}/approval_state': "You can request information about a merge request's approval state by using the following endpoint: ", 'put /api/v4/projects/{id}/merge_requests/{merge_request_iid}/reset_approvals': 'Clear all approvals of merge request. Available only for [bot users](../user/project/settings/project_access_tokens.md#bot-users-for-projects) based on project or group tokens. Users without bot permissions receive a `401 Unauthorized` response. ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/unapprove': 'If you did approve a merge request, you can unapprove it using the following endpoint: ', 'post /api/v4/projects/{id}/merge_requests/{merge_request_iid}/approve': 'If you are allowed to, you can approve a merge request using the following endpoint: ', 'get /api/v4/projects/{id}/packages/ml_models/{model_version_id}/files/(*path/){file_name}': 'Download an ml_model package file', 'put /api/v4/projects/{id}/packages/ml_models/{model_version_id}/files/(*path/){file_name}': 'Workhorse upload model package file', 'put /api/v4/projects/{id}/packages/ml_models/{model_version_id}/files/(*path/){file_name}/authorize': 'Workhorse authorize model package file', 'post /api/v4/projects/{id}/packages/npm/-/npm/v1/security/audits/quick': 'NPM registry quick audit endpoint', 'post /api/v4/projects/{id}/packages/npm/-/npm/v1/security/advisories/bulk': 'NPM registry bulk advisory endpoint', 'get /api/v4/projects/{id}/packages/npm/*package_name': 'NPM registry metadata endpoint', 'put /api/v4/projects/{id}/packages/npm/{package_name}': 'Create or deprecate NPM package', 'get /api/v4/projects/{id}/packages/npm/*package_name/-/*file_name': 'Download the NPM tarball', 'get /api/v4/projects/{id}/packages/npm/-/package/*package_name/dist-tags': 'Get all tags for a given an NPM package', 'delete /api/v4/projects/{id}/packages/npm/-/package/*package_name/dist-tags/{tag}': 'Deletes the given tag', 'put /api/v4/projects/{id}/packages/npm/-/package/*package_name/dist-tags/{tag}': 'Create or Update the given tag for the given NPM package and version', 'delete /api/v4/projects/{id}/packages/nuget/*package_name/*package_version': 'The NuGet Package Delete endpoint', 'put /api/v4/projects/{id}/packages/nuget/symbolpackage/authorize': 'The NuGet Symbol Package Authorize endpoint', 'put /api/v4/projects/{id}/packages/nuget/symbolpackage': 'The NuGet Symbol Package Publish endpoint', 'put /api/v4/projects/{id}/packages/nuget/authorize': 'The NuGet Package Authorize endpoint', 'put /api/v4/projects/{id}/packages/nuget': 'The NuGet V3 Feed Package Publish endpoint', 'get /api/v4/projects/{id}/packages/nuget/index': 'The NuGet V3 Feed Service Index', 'get /api/v4/projects/{id}/packages/nuget/symbolfiles/*file_name/*signature/*same_file_name': 'The NuGet Symbol File Download Endpoint', 'put /api/v4/projects/{id}/packages/nuget/v2/authorize': 'The NuGet V2 Feed Package Authorize endpoint', 'put /api/v4/projects/{id}/packages/nuget/v2': 'The NuGet V2 Feed Package Publish endpoint', 'get /api/v4/projects/{id}/packages/nuget/v2': 'The NuGet V2 Feed Service Index', 'get /api/v4/projects/{id}/packages/nuget/v2/$metadata': 'The NuGet V2 Feed Package $metadata endpoint', 'get /api/v4/projects/{id}/packages/nuget/metadata/*package_name/*package_version': 'The NuGet Metadata Service - Package name and version level', 'get /api/v4/projects/{id}/packages/nuget/metadata/*package_name/index': 'The NuGet Metadata Service - Package name level', 'get /api/v4/projects/{id}/packages/nuget/query': 'The NuGet Search Service', 'get /api/v4/projects/{id}/packages/nuget/download/*package_name/*package_version/*package_filename': 'The NuGet Content Service - content request', 'get /api/v4/projects/{id}/packages/nuget/download/*package_name/index': 'The NuGet Content Service - index request', "get /api/v4/projects/{project_id}/packages/nuget/v2/Packages\\(Id='*package_name',Version='*package_version'\\)": 'The NuGet V2 Feed Single Package Metadata endpoint', 'get /api/v4/projects/{project_id}/packages/nuget/v2/Packages\\(\\)': 'The NuGet V2 Feed Enumerate Packages endpoint', 'get /api/v4/projects/{project_id}/packages/nuget/v2/FindPackagesById\\(\\)': 'The NuGet V2 Feed Find Packages by ID endpoint', 'delete /api/v4/projects/{id}/debian_distributions/{codename}': 'Delete a Debian Distribution', 'put /api/v4/projects/{id}/debian_distributions/{codename}': 'Update a Debian Distribution', 'get /api/v4/projects/{id}/debian_distributions/{codename}': 'Get a Debian Distribution', 'get /api/v4/projects/{id}/debian_distributions/{codename}/key.asc': 'Get a Debian Distribution Key', 'get /api/v4/projects/{id}/debian_distributions': 'Get a list of Debian Distributions', 'post /api/v4/projects/{id}/debian_distributions': 'Create a Debian Distribution', 'delete /api/v4/projects/{id}/hooks/{hook_id}/url_variables/{key}': 'Un-Set a url variable', 'put /api/v4/projects/{id}/hooks/{hook_id}/url_variables/{key}': 'Set a url variable', 'get /api/v4/projects/{id}/audit_events/{audit_event_id}': 'Only available to users with at least the Maintainer role for the project. ', 'get /api/v4/projects/{id}/audit_events': '', 'post /api/v4/projects/{id}/packages/pypi/authorize': 'Authorize the PyPi package upload from workhorse', 'post /api/v4/projects/{id}/packages/pypi': 'The PyPi Package upload endpoint', 'get /api/v4/projects/{id}/packages/pypi/simple/*package_name': 'The PyPi Simple Project Package Endpoint', 'get /api/v4/projects/{id}/packages/pypi/simple': 'The PyPi Simple Project Index Endpoint', 'get /api/v4/projects/{id}/packages/pypi/files/{sha256}/*file_identifier': 'The PyPi package download endpoint', 'post /api/v4/projects/{id}/releases/{tag_name}/assets/links': 'Create a release link', 'get /api/v4/projects/{id}/releases/{tag_name}/assets/links': 'List links of a release', 'delete /api/v4/projects/{id}/releases/{tag_name}/assets/links/{link_id}': 'Delete a release link', 'put /api/v4/projects/{id}/releases/{tag_name}/assets/links/{link_id}': 'Update a release link', 'get /api/v4/projects/{id}/releases/{tag_name}/assets/links/{link_id}': 'Get a release link', 'post /api/v4/projects/{id}/packages/rpm/authorize': 'Authorize package upload from workhorse', 'post /api/v4/projects/{id}/packages/rpm': 'Upload a RPM package', 'get /api/v4/projects/{id}/packages/rpm/*package_file_id/*file_name': 'Download RPM package files', 'get /api/v4/projects/{id}/packages/rpm/repodata/*file_name': 'Download repository metadata files', 'get /api/v4/projects/{id}/packages/rubygems/gems/{file_name}': 'Download the .gem package', 'get /api/v4/projects/{id}/packages/rubygems/quick/Marshal.4.8/{file_name}': 'Download the gemspec file', 'get /api/v4/projects/{id}/packages/rubygems/{file_name}': 'Download the spec index file', 'get /api/v4/projects/{id}/packages/rubygems/api/v1/dependencies': 'Fetch a list of dependencies', 'post /api/v4/projects/{id}/packages/rubygems/api/v1/gems': 'Upload a gem', 'post /api/v4/projects/{id}/packages/rubygems/api/v1/gems/authorize': 'Authorize a gem upload from workhorse', 'get /api/v4/projects/{id}/packages/terraform/modules/{module_name}/{module_system}': 'Download the latest version of a module', 'get /api/v4/projects/{id}/packages/terraform/modules/{module_name}/{module_system}/*module_version': 'Download a specific version of a module', 'put /api/v4/projects/{id}/packages/terraform/modules/{module_name}/{module_system}/*module_version/file': 'Upload Terraform Module package file', 'put /api/v4/projects/{id}/packages/terraform/modules/{module_name}/{module_system}/*module_version/file/authorize': 'Workhorse authorize Terraform Module package file', 'delete /api/v4/projects/{id}/terraform/state/{name}/lock': 'Unlock a Terraform state of a certain name', 'post /api/v4/projects/{id}/terraform/state/{name}/lock': 'Lock a Terraform state of a certain name', 'delete /api/v4/projects/{id}/terraform/state/{name}': 'Delete a Terraform state of a certain name', 'post /api/v4/projects/{id}/terraform/state/{name}': 'Add a new Terraform state or update an existing one', 'get /api/v4/projects/{id}/terraform/state/{name}': 'Get a Terraform state by its name', 'delete /api/v4/projects/{id}/terraform/state/{name}/versions/{serial}': 'Delete a Terraform state version', 'get /api/v4/projects/{id}/terraform/state/{name}/versions/{serial}': 'Get a Terraform state version', 'get /api/v4/admin/batched_background_migrations/{id}': 'Retrieve a batched background migration', 'get /api/v4/admin/batched_background_migrations': 'Get the list of batched background migrations', 'put /api/v4/admin/batched_background_migrations/{id}/resume': 'Resume a batched background migration', 'put /api/v4/admin/batched_background_migrations/{id}/pause': 'Pause a batched background migration', 'delete /api/v4/admin/ci/variables/{key}': 'Remove an instance-level variable. ', 'put /api/v4/admin/ci/variables/{key}': 'Update an instance-level variable. ', 'get /api/v4/admin/ci/variables/{key}': 'Get the details of a specific instance-level variable. ', 'post /api/v4/admin/ci/variables': 'Create a new instance-level variable. The [maximum number of instance-level variables](../administration/instance_limits.md#cicd-variable-limits) can be changed. ', 'get /api/v4/admin/ci/variables': 'Get the list of all instance-level variables. ', 'get /api/v4/admin/databases/{database_name}/dictionary/tables/{table_name}': 'Retrieve dictionary details', 'delete /api/v4/admin/clusters/{cluster_id}': 'Deletes an existing instance cluster. Does not remove existing resources within the connected Kubernetes cluster. ', 'put /api/v4/admin/clusters/{cluster_id}': 'Updates an existing instance cluster. ', 'get /api/v4/admin/clusters/{cluster_id}': 'Returns a single instance cluster. Parameters: | Attribute    | Type    | Required | Description           | | ------------ | ------- | -------- | --------------------- | | `cluster_id` | integer | yes      | The ID of the cluster | ', 'post /api/v4/admin/clusters/add': 'Adds an existing Kubernetes instance cluster. ', 'get /api/v4/admin/clusters': 'Returns a list of instance clusters. ', 'post /api/v4/admin/migrations/{timestamp}/mark': 'Mark the migration as successfully executed', 'delete /api/v4/broadcast_messages/{id}': 'Delete a broadcast message. ', 'put /api/v4/broadcast_messages/{id}': 'Update an existing broadcast message. ', 'get /api/v4/broadcast_messages/{id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated Get a specific broadcast message. ', 'post /api/v4/broadcast_messages': 'Create a new broadcast message. ', 'get /api/v4/broadcast_messages': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated List all broadcast messages. ', 'delete /api/v4/applications/{id}': 'Delete a specific application. Returns `204` if the request succeeds. ', 'get /api/v4/applications': 'List all registered applications. ', 'post /api/v4/applications': 'Create an application by posting a JSON payload. Returns `200` if the request succeeds. ', 'get /api/v4/avatar': 'Return avatar url for a user', 'get /api/v4/bulk_imports/{import_id}/entities/{entity_id}/failures': '', 'get /api/v4/bulk_imports/{import_id}/entities/{entity_id}': '', 'get /api/v4/bulk_imports/{import_id}/entities': '', 'get /api/v4/bulk_imports/{import_id}': '', 'get /api/v4/bulk_imports/entities': '', 'get /api/v4/bulk_imports': '', 'post /api/v4/bulk_imports': 'Use this endpoint to start a new group or project migration. Specify: - `entities[group_entity]` to migrate a group. - `entities[project_entity]` to migrate a project. (**Status:** Beta) ', 'get /api/v4/job/allowed_agents': 'DETAILS: **Tier:** Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated Retrieve the job that generated the `CI_JOB_TOKEN`, along with a list of allowed [agents](../user/clusters/agent/index.md). ', 'get /api/v4/job': 'Retrieve the job that generated a job token. ', 'post /api/v4/runners/reset_registration_token': 'WARNING: Runner registration tokens, and support for certain configuration arguments, were [deprecated](https://gitlab.com/gitlab-org/gitlab/-/issues/380872) in GitLab 15.6 and will be removed in GitLab 17.0. After GitLab 17.0, you will no longer be able to reset runner registration tokens and the `reset_registration_token` endpoint will not function. Reset the runner registration token for the GitLab instance. ', 'post /api/v4/runners/{id}/reset_authentication_token': "Reset the runner's authentication token by using its runner ID. ", 'get /api/v4/runners/{id}/jobs': '', 'delete /api/v4/runners/{id}': "To delete the runner by ID, use your access token with the runner's ID: ", 'put /api/v4/runners/{id}': 'Update details of a runner. ', 'get /api/v4/runners/{id}': 'Get details of a runner. At least the Maintainer role is required to get runner details at the project and group level. Instance-level runner details via this endpoint are available to all authenticated users. ', 'get /api/v4/runners/all': '', 'get /api/v4/runners': '', 'delete /api/v4/runners': 'To delete the runner by using its authentication token: ', 'post /api/v4/runners': 'Create a runner for the instance. ', 'post /api/v4/runners/reset_authentication_token': "Reset the runner's authentication token by using the current token's value as an input. ", 'post /api/v4/runners/verify': 'Validates authentication credentials for a registered runner. ', 'delete /api/v4/runners/managers': 'Internal endpoint that deletes a runner manager by authentication token and system ID.', 'get /api/v4/jobs/{id}/artifacts': 'Download the artifacts file for job', 'post /api/v4/jobs/{id}/artifacts': 'Upload a job artifact', 'post /api/v4/jobs/{id}/artifacts/authorize': 'Authorize uploading job artifact', 'patch /api/v4/jobs/{id}/trace': 'Append a patch to the job trace', 'put /api/v4/jobs/{id}': 'Update a job', 'post /api/v4/jobs/request': 'Request a job', 'get /api/v4/group/{id}/-/packages/composer/*package_name': 'Composer packages endpoint at group level for package versions metadata', 'get /api/v4/group/{id}/-/packages/composer/p2/*package_name': 'Composer v2 packages p2 endpoint at group level for package versions metadata', 'get /api/v4/group/{id}/-/packages/composer/p/{sha}': 'Composer packages endpoint at group level for packages list', 'get /api/v4/group/{id}/-/packages/composer/packages': 'Composer packages endpoint at group level', 'get /api/v4/packages/terraform/modules/v1/{module_namespace}/{module_name}/{module_system}/*module_version': 'Get details about specific version of a module', 'get /api/v4/packages/terraform/modules/v1/{module_namespace}/{module_name}/{module_system}/*module_version/file': 'Download specific version of a module', 'get /api/v4/packages/terraform/modules/v1/{module_namespace}/{module_name}/{module_system}/*module_version/download': 'Get download location for specific version of a module', 'get /api/v4/packages/terraform/modules/v1/{module_namespace}/{module_name}/{module_system}': 'Get details about the latest version of a module', 'get /api/v4/packages/terraform/modules/v1/{module_namespace}/{module_name}/{module_system}/download': 'Get download location for the latest version of a module', 'get /api/v4/packages/terraform/modules/v1/{module_namespace}/{module_name}/{module_system}/versions': 'List versions for a module', 'post /api/v4/packages/npm/-/npm/v1/security/audits/quick': 'NPM registry quick audit endpoint', 'post /api/v4/packages/npm/-/npm/v1/security/advisories/bulk': 'NPM registry bulk advisory endpoint', 'get /api/v4/packages/npm/*package_name': 'NPM registry metadata endpoint', 'delete /api/v4/packages/npm/-/package/*package_name/dist-tags/{tag}': 'Deletes the given tag', 'put /api/v4/packages/npm/-/package/*package_name/dist-tags/{tag}': 'Create or Update the given tag for the given NPM package and version', 'get /api/v4/packages/npm/-/package/*package_name/dist-tags': 'Get all tags for a given an NPM package', 'get /api/v4/packages/maven/*path/{file_name}': 'Download the maven package file at instance level', 'put /api/v4/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/package/{conan_package_reference}/{package_revision}/{file_name}': 'Upload package files', 'get /api/v4/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/package/{conan_package_reference}/{package_revision}/{file_name}': 'Download package files', 'put /api/v4/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/package/{conan_package_reference}/{package_revision}/{file_name}/authorize': 'Workhorse authorize the conan package file', 'put /api/v4/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/export/{file_name}/authorize': 'Workhorse authorize the conan recipe file', 'put /api/v4/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/export/{file_name}': 'Upload recipe package files', 'get /api/v4/packages/conan/v1/files/{package_name}/{package_version}/{package_username}/{package_channel}/{recipe_revision}/export/{file_name}': 'Download recipe files', 'delete /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}': 'Delete Package', 'get /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}': 'Recipe Snapshot', 'post /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/upload_urls': 'Recipe Upload Urls', 'post /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}/upload_urls': 'Package Upload Urls', 'get /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/download_urls': 'Recipe Download Urls', 'get /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}/download_urls': 'Package Download Urls', 'get /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/digest': 'Recipe Digest', 'get /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}/digest': 'Package Digest', 'get /api/v4/packages/conan/v1/conans/{package_name}/{package_version}/{package_username}/{package_channel}/packages/{conan_package_reference}': 'Package Snapshot', 'get /api/v4/packages/conan/v1/users/check_credentials': 'Check for valid user credentials per conan CLI', 'get /api/v4/packages/conan/v1/users/authenticate': 'Authenticate user against conan CLI', 'get /api/v4/packages/conan/v1/conans/search': 'Search for packages', 'get /api/v4/packages/conan/v1/ping': 'Ping the Conan API', 'post /api/v4/container_registry_event/events': 'Receives notifications from the container registry when an operation occurs', 'get /api/v4/registry/repositories/{id}': 'Get details of a registry repository. ', 'get /api/v4/events': 'Get a list of events for the authenticated user. Scope `read_user` or `api` is required. Events associated with epics are not available using the API. ', 'get /api/v4/users/{user_id}/memberships': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Pre-requisite: - You must be an administrator. Lists all projects and groups a user is a member of. It returns the `source_id`, `source_name`, `source_type`, and `access_level` of a membership. Source can be of type `Namespace` (representing a group) or `Project`. The response represents only direct memberships. Inherited memberships, for example in subgroups, are not included. Access levels are represented by an integer value. For more details, read about the meaning of [access level values](access_requests.md#valid-access-levels). ', 'post /api/v4/users/{id}/unban': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Requires administrator access. It retrieves every impersonation token of the user. Use the pagination parameters `page` and `per_page` to restrict the list of impersonation tokens. ', 'post /api/v4/users/{id}/ban': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Unbans the specified user. Available only for administrator. ', 'post /api/v4/users/{id}/unblock': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Deactivates the specified user. Available only for administrator. ', 'post /api/v4/users/{id}/block': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Blocks the specified user. Available only for administrator. ', 'post /api/v4/users/{id}/deactivate': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Deactivates the specified user. Available only for administrator. ', 'post /api/v4/users/{id}/reject': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Rejects specified user that is [pending approval](../administration/moderate_users.md#users-pending-approval). Available only for administrators. ', 'post /api/v4/users/{id}/approve': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Approves the specified user. Available only for administrators. ', 'post /api/v4/users/{id}/activate': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Activates the specified user. Available only for administrator. ', 'delete /api/v4/users/{id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Deletes a user. Available only for administrators. This returns a `204 No Content` status code if the operation was successfully, `404` if the resource was not found or `409` if the user cannot be soft deleted. ', 'put /api/v4/users/{id}': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Modifies an existing user. Only administrators can change attributes of a user. The `email` field is the user's primary email address. You can only change this field to an already-added secondary email address for that user. To add more email addresses to the same user, use the [add email function](#add-email). ", 'get /api/v4/users/{id}': 'Prerequisites: - You must be signed in to use this endpoint. ', 'delete /api/v4/users/{id}/emails/{email_id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Blocks the specified user. Available only for administrator. ', 'get /api/v4/users/{id}/emails': 'Get a single email. ', 'post /api/v4/users/{id}/emails': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Create new email owned by specified user. Available only for administrator ', 'post /api/v4/users/{id}/gpg_keys/{key_id}/revoke': 'Revokes an existing GPG key from a specified user. Available only for admins.', 'delete /api/v4/users/{id}/gpg_keys/{key_id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Delete a GPG key owned by a specified user. Available only for administrator. ', 'get /api/v4/users/{id}/gpg_keys/{key_id}': 'Get a specific GPG key for a given user. This endpoint can be accessed without administrator authentication. ', 'get /api/v4/users/{id}/gpg_keys': "Get a list of a specified user's GPG keys. This endpoint can be accessed without authentication. ", 'post /api/v4/users/{id}/gpg_keys': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Create new GPG key owned by the specified user. Available only for administrator. ', 'delete /api/v4/users/{id}/keys/{key_id}': "Get a list of the authenticated user's GPG keys. ", 'get /api/v4/users/{id}/keys/{key_id}': 'Get a single key for a given user. ', 'get /api/v4/users/{user_id}/keys': "Get a list of a specified user's SSH keys. ", 'post /api/v4/users/{user_id}/keys': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Create new key owned by specified user. Available only for administrator. ', 'get /api/v4/users/{user_id}/project_deploy_keys': "Get a list of a specified user (requestee) and the authenticated user's (requester) common [project deploy keys](../user/project/deploy_keys/index.md#scope). It lists only the **enabled project keys from the common projects of requester and requestee**. ", 'delete /api/v4/users/{id}/identities/{provider}': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Deletes a user's authentication identity using the provider name associated with that identity. Available only for administrators. ", 'patch /api/v4/users/{id}/disable_two_factor': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Pre-requisite: - You must be an administrator. Disables two factor authentication (2FA) for the specified user. Administrators cannot disable 2FA for their own user account or other administrators using the API. Instead, they can disable an administrator's 2FA [using the Rails console](../security/two_factor_authentication.md#for-a-single-user). ", 'post /api/v4/users': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Creates a new user. Note only administrators can create new users. Either `password`, `reset_password`, or `force_random_password` must be specified. If `reset_password` and `force_random_password` are both `false`, then `password` is required. `force_random_password` and `reset_password` take priority over `password`. In addition, `reset_password` and `force_random_password` can be used together. NOTE: `private_profile` defaults to the value of the [Set profiles of new users to private by default](../administration/settings/account_and_limit_settings.md#set-profiles-of-new-users-to-private-by-default) setting. `bio` defaults to `""` instead of `null`. ', 'get /api/v4/users': '', 'get /api/v4/users/{id}/followers': 'Get the followers of a user. ', 'get /api/v4/users/{id}/following': 'Get the followers of a user. ', 'post /api/v4/users/{id}/unfollow': 'Follow a user. ', 'post /api/v4/users/{id}/follow': 'Follow a user. ', 'get /api/v4/users/{user_id}/status': 'Get the status of a user. This endpoint can be accessed without authentication. ', 'delete /api/v4/users/{id}/custom_attributes/{key}': 'Delete a custom attribute on a resource. ', 'put /api/v4/users/{id}/custom_attributes/{key}': 'Set a custom attribute on a resource. The attribute is updated if it already exists, or newly created otherwise. ', 'get /api/v4/users/{id}/custom_attributes/{key}': 'Get a single custom attribute on a resource. ', 'get /api/v4/users/{id}/custom_attributes': 'Get all custom attributes on a resource. ', 'get /api/v4/users/{user_id}/starred_projects': 'Get a list of visible projects starred by the given user. When accessed without authentication, only public projects are returned. ', 'get /api/v4/users/{user_id}/contributed_projects': 'Get a list of visible projects a given user has contributed to. ', 'get /api/v4/users/{user_id}/projects': "Get a list of visible projects owned by the given user. When accessed without authentication, only public projects are returned. Prerequisites: - To view [certain attributes](https://gitlab.com/gitlab-org/gitlab/-/blob/520776fa8e5a11b8275b7c597d75246fcfc74c89/lib/api/entities/project.rb#L109-130), you must be an administrator or have the Owner role for the project. NOTE: Only the projects in the user's (specified in `user_id`) namespace are returned. Projects owned by the user in any group or subgroups are not returned. An empty list is returned if a profile is set to private. This endpoint supports [keyset pagination](rest/index.md#keyset-based-pagination) for selected `order_by` options. ", 'get /api/v4/users/{id}/events': 'Get the contribution events for the specified user, sorted from newest to oldest. Scope `read_user` or `api` is required. Events associated with epics are not available using API. ', 'get /api/v4/users/{id}/associations_count': "Get a list of a specified user's count of: - Projects. - Groups. - Issues. - Merge requests. Administrators can query any user, but non-administrators can only query themselves. ", 'delete /api/v4/users/{user_id}/impersonation_tokens/{impersonation_token_id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Requires administrator access. It revokes an impersonation token. ', 'get /api/v4/users/{user_id}/impersonation_tokens/{impersonation_token_id}': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated > Requires administrators permissions. It shows a user's impersonation token. ", 'post /api/v4/users/{user_id}/impersonation_tokens': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Requires administrator access. Token values are returned once. Make sure you save it because you can't access it again. It creates a new impersonation token. Only administrators can do this. You are only able to create impersonation tokens to impersonate the user and perform both API calls and Git reads and writes. The user can't see these tokens in their profile settings page. ", 'get /api/v4/users/{user_id}/impersonation_tokens': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Requires administrator access. It retrieves every impersonation token of the user. Use the pagination parameters `page` and `per_page` to restrict the list of impersonation tokens. ', 'post /api/v4/users/{user_id}/personal_access_tokens': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Use this API to create a new personal access token. Token values are returned once so, make sure you save it as you can't access it again. This API can only be used by GitLab administrators. ", 'delete /api/v4/features/{name}': "Removes a feature gate. Response is equal when the gate exists, or doesn't. ", 'post /api/v4/features/{name}': "Set a feature's gate value. If a feature with the given name doesn't exist yet, it's created. The value can be a boolean, or an integer to indicate percentage of time. WARNING: Before you enable a feature still in development, you should understand the [security and stability risks](../administration/feature_flags.md#risks-when-enabling-features-still-in-development). ", 'get /api/v4/features/definitions': 'Get a list of all feature definitions. ', 'get /api/v4/features': 'Get a list of all persisted features, with its gate values. ', 'post /api/v4/geo/status': 'Internal endpoint that posts the current node status', 'get /api/v4/geo/repositories/{gl_repository}/pipeline_refs': 'Used by secondary runners to verify the secondary instance has the very latest version', 'get /api/v4/geo/retrieve/{replicable_name}/{replicable_id}': 'Internal endpoint that returns a replicable file', 'get /api/v4/geo/proxy': 'Determine if a Geo site should proxy requests', 'post /api/v4/geo/proxy_git_ssh/receive_pack': 'Internal endpoint that posts git-receive-pack for git push', 'post /api/v4/geo/proxy_git_ssh/info_refs_receive_pack': 'Internal endpoint that returns git-received-pack output for git push', 'post /api/v4/geo/proxy_git_ssh/upload_pack': 'Internal endpoint that posts git-upload-pack for git clone/pull', 'post /api/v4/geo/proxy_git_ssh/info_refs_upload_pack': 'Internal endpoint that returns info refs upload pack for git clone/pull', 'post /api/v4/geo/node_proxy/{id}/graphql': 'Query the GraphQL endpoint of an existing Geo node', 'post /api/v4/integrations/jira_connect/subscriptions': 'Subscribe a namespace to a JiraConnectInstallation', 'post /api/v4/integrations/slack/events': 'Receive Slack events', 'get /api/v4/keys': 'You can search for a user that owns a specific SSH key. Note only administrators can lookup SSH key with the fingerprint of an SSH key. ', 'get /api/v4/keys/{id}': 'Get SSH key with user by ID of an SSH key. Only available to administrators. ', 'post /api/v4/markdown': '', 'get /api/v4/merge_requests': 'Get all merge requests the authenticated user has access to. By default it returns only merge requests created by the current user. To get all merge requests, use parameter `scope=all`. The `state` parameter can be used to get only merge requests with a given state (`opened`, `closed`, `locked`, or `merged`) or all of them (`all`). It should be noted that when searching by `locked` it mostly returns no results as it is a short-lived, transitional state. The pagination parameters `page` and `per_page` can be used to restrict the list of merge requests. ', 'post /api/v4/environments/{id}/metrics_dashboard/annotations': 'Create a new annotation', 'post /api/v4/clusters/{id}/metrics_dashboard/annotations': 'Create a new annotation', 'get /api/v4/namespaces/{id}/exists': 'Get existence of a namespace by path. Suggests a new namespace path that does not already exist. ', 'get /api/v4/namespaces/{id}': 'Get a namespace by ID. ', 'put /api/v4/namespaces/{id}': 'Update a namespace', 'get /api/v4/namespaces': 'Get a list of the namespaces of the authenticated user. If the user is an administrator, a list of all namespaces in the GitLab instance is shown. ', 'get /api/v4/namespaces/storage/limit_exclusions': 'Retrieve all limit exclusions', 'delete /api/v4/namespaces/{id}/storage/limit_exclusion': 'Removes a storage limit exclusion for a Namespace', 'post /api/v4/namespaces/{id}/storage/limit_exclusion': 'Creates a storage limit exclusion for a Namespace', 'put /api/v4/namespaces/{id}/gitlab_subscription': 'Update the subscription for the namespace', 'get /api/v4/namespaces/{id}/gitlab_subscription': 'Returns the subscription for the namespace', 'post /api/v4/namespaces/{id}/gitlab_subscription': 'Create a subscription for the namespace', 'get /api/v4/pages/domains': 'Prerequisites: - You must have administrator access to the instance. Get a list of all Pages domains. ', 'delete /api/v4/personal_access_tokens/{id}': 'Revoke a personal access token using its ID. ', 'get /api/v4/personal_access_tokens/{id}': 'Get a single personal access token by its ID. Users can get their own tokens. Administrators can get any token. ', 'post /api/v4/personal_access_tokens/{id}/rotate': 'In GitLab 16.6 and later, you can use the `expires_at` parameter to set a different expiry date. This non-default expiry date can be up to a maximum of one year from the rotation date. ', 'get /api/v4/personal_access_tokens': 'Get all personal access tokens the authenticated user has access to. By default, returns an unfiltered list of: - Only personal access tokens created by the current user to a non-administrator. - All personal access tokens to an administrator. Administrators: - Can use the `user_id` parameter to filter by a user. - Can use other filters on all personal access tokens (GitLab 15.5 and later). Non-administrators: - Cannot use the `user_id` parameter to filter on any user except themselves, otherwise they receive a `401 Unauthorized` response. - Can only filter on their own personal access tokens (GitLab 15.5 and later). ', 'post /api/v4/personal_access_tokens/self/rotate': 'Requires: - `api` scope. You can use the `expires_at` parameter to set a different expiry date. This non-default expiry date can be up to a maximum of one year from the rotation date. ', 'delete /api/v4/personal_access_tokens/self': 'Revokes a personal access token that is passed in using a request header. Requires: - `api` scope in GitLab 15.0 to GitLab 15.3. - Any scope in GitLab 15.4 and later. ', 'get /api/v4/personal_access_tokens/self': 'Get a single personal access token and information about that token by passing the token in a header. ', 'post /api/v4/project_repository_storage_moves': 'Schedules repository storage moves for each project repository stored on the source storage shard. This endpoint migrates all projects at once. For more information, see [Move all projects](../administration/operations/moving_repositories.md#move-all-projects). ', 'get /api/v4/project_repository_storage_moves': '', 'get /api/v4/project_repository_storage_moves/{repository_storage_move_id}': '', 'post /api/v4/snippets/{id}/repository_storage_moves': '', 'get /api/v4/snippets/{id}/repository_storage_moves': '', 'get /api/v4/snippets/{id}/repository_storage_moves/{repository_storage_move_id}': '', 'get /api/v4/snippets/{id}/user_agent_detail': 'NOTE: Available only for administrators. ', 'get /api/v4/snippets/{id}/files/{ref}/{file_path}/raw': 'Returns the raw file content as plain text. ', 'get /api/v4/snippets/{id}/raw': "Get a single snippet's raw contents. ", 'delete /api/v4/snippets/{id}': 'Delete an existing snippet. ', 'put /api/v4/snippets/{id}': 'Update an existing snippet. NOTE: The user must have permission to change an existing snippet. ', 'get /api/v4/snippets/{id}': 'Get a single snippet. ', 'post /api/v4/snippets': 'Create a new snippet. NOTE: The user must have permission to create new snippets. ', 'get /api/v4/snippets': "Get a list of the current user's snippets. ", 'get /api/v4/snippets/all': 'List all snippets the current user has access to. Users with the Administrator or Auditor access levels can see all snippets (both personal and project). ', 'get /api/v4/snippets/public': 'List all public snippets. ', 'post /api/v4/snippet_repository_storage_moves': 'Schedules repository storage moves for each snippet repository stored on the source storage shard. This endpoint migrates all snippets at once. For more information, see [Move all snippets](../administration/operations/moving_repositories.md#move-all-snippets). ', 'get /api/v4/snippet_repository_storage_moves': '', 'get /api/v4/snippet_repository_storage_moves/{repository_storage_move_id}': '', 'put /api/v4/suggestions/batch_apply': '', 'put /api/v4/suggestions/{id}/apply': 'Applies a suggested patch in a merge request. Users must have at least the Developer role to perform such action. ', 'delete /api/v4/hooks/{hook_id}': 'Deletes a system hook. ', 'post /api/v4/hooks/{hook_id}': 'Executes the system hook with mock data. ', 'put /api/v4/hooks/{hook_id}': 'Edit system hook', 'get /api/v4/hooks/{hook_id}': 'Get a system hook by its ID. ', 'post /api/v4/hooks': 'Add a new system hook. ', 'get /api/v4/hooks': 'Get a list of all system hooks. ', 'delete /api/v4/hooks/{hook_id}/url_variables/{key}': 'Un-Set a url variable', 'put /api/v4/hooks/{hook_id}/url_variables/{key}': 'Set a url variable', 'get /api/v4/feature_flags/unleash/{project_id}/client/features': 'Get a list of features', 'get /api/v4/feature_flags/unleash/{project_id}/features': 'Get a list of features (deprecated, v2 client support)', 'get /api/v4/usage_data/service_ping': 'Get the latest ServicePing payload', 'get /api/v4/usage_data/queries': 'This action is behind the `usage_data_queries_api` feature flag and is available only for the GitLab instance [Administrator](../user/permissions.md) users. Return all of the raw SQL queries used to compute Service Ping. ', 'get /api/v4/usage_data/non_sql_metrics': 'Get Non SQL usage ping metrics', 'get /api/v4/usage_data/metric_definitions': 'Export all metric definitions as a single YAML file, similar to the [Metrics Dictionary](https://metrics.gitlab.com/), for easier importing. ', 'post /api/v4/usage_data/track_event': 'Track gitlab internal events', 'post /api/v4/usage_data/increment_unique_users': 'Track usage data event for the current user', 'post /api/v4/usage_data/increment_counter': 'Track usage data event', 'post /api/v4/user/runners': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** GitLab.com, Self-managed, GitLab Dedicated Creates a runner linked to the current user. Prerequisites: - You must be an administrator or have the Owner role of the target namespace or project. - For `instance_type`, you must be an administrator of the GitLab instance. - For `group_type` or `project_type` with an Owner role, an administrator must not have enabled [restrict runner registration](../administration/settings/continuous_integration.md#restrict-runner-registration-by-all-users-in-an-instance). - An access token with the `create_runner` scope. Be sure to copy or save the `token` in the response, the value cannot be retrieved again. ', 'get /api/v4/user/status': 'Get the status of the authenticated user. ', 'patch /api/v4/user/status': 'Set the status of the current user. ', 'put /api/v4/user/status': 'Set the status of the current user. ', 'get /api/v4/user/activities': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Pre-requisite: - You must be an administrator to view the activity of users with private profiles. Get the last activity date for users with public profiles, sorted from oldest to newest. The activities that update the user event timestamps (`last_activity_on` and `current_sign_in_at`) are: - Git HTTP/SSH activities (such as clone, push) - User logging in to GitLab - User visiting pages related to dashboards, projects, issues, and merge requests ([introduced](https://gitlab.com/gitlab-org/gitlab-foss/-/issues/54947) in GitLab 11.8) - User using the API - User using the GraphQL API By default, it shows the activity for users with public profiles in the last 6 months, but this can be amended by using the `from` parameter. ', 'delete /api/v4/user/emails/{email_id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Prerequisites: - You must be an administrator of a self-managed GitLab instance. Deletes an email address owned by a specified user. This cannot delete a primary email address. ', 'get /api/v4/user/emails/{email_id}': 'Creates a new email owned by the authenticated user. ', 'post /api/v4/user/emails': 'Creates a new email owned by the authenticated user. ', 'get /api/v4/user/emails': "DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Get a list of a specified user's emails. Available only for administrator NOTE: This endpoint does not return the primary email address, but [issue 25077](https://gitlab.com/gitlab-org/gitlab/-/issues/25077) proposes to change this behavior. ", 'get /api/v4/user/preferences': "Get a list of the authenticated user's preferences. ", 'put /api/v4/user/preferences': "Update the current user's preferences. ", 'put /api/v4/user/{user_id}/credit_card_validation': "Update a user's credit_card_validation", 'delete /api/v4/user/gpg_keys/{key_id}': 'Delete a GPG key owned by the authenticated user. ', 'get /api/v4/user/gpg_keys/{key_id}': 'Get a specific GPG key of authenticated user. ', 'post /api/v4/user/gpg_keys/{key_id}/revoke': 'Revoke a GPG key owned by currently authenticated user', 'post /api/v4/user/gpg_keys': 'Creates a new GPG key owned by the authenticated user. ', 'get /api/v4/user/gpg_keys': "Get a list of the authenticated user's GPG keys. ", 'delete /api/v4/user/keys/{key_id}': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Deletes key owned by a specified user. Available only for administrator. ', 'get /api/v4/user/keys/{key_id}': 'Get a single key. ', 'post /api/v4/user/keys': 'Creates a new key owned by the authenticated user. ', 'get /api/v4/user/keys': "Get a list of the authenticated user's SSH keys. This function takes pagination parameters `page` and `per_page` to restrict the list of keys. ", 'get /api/v3/user': 'Get the currently authenticated user', 'post /api/v4/user/personal_access_tokens': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Use this API to create a new personal access token for the currently authenticated user. For security purposes, the token: - Is limited to the [`k8s_proxy` scope](../user/profile/personal_access_tokens.md#personal-access-token-scopes).   This scope grants permission to perform Kubernetes API calls using the agent for Kubernetes. - By default, expires at the end of the day it was created on. Token values are returned once, so make sure you save the token as you cannot access it again. ', 'get /api/v4/user_counts': 'Get the counts (same as in the upper-right menu) of the authenticated user.', 'get /api/v4/application/statistics': 'List the current statistics of the GitLab instance. You have to be an administrator to perform this action. NOTE: These statistics show exact counts for values less than 10,000. For values of 10,000 and higher, these statistics show approximate data when [TablesampleCountStrategy](https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/database/count/tablesample_count_strategy.rb?ref_type=heads#L16) and [ReltuplesCountStrategy](https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/database/count/reltuples_count_strategy.rb?ref_type=heads) strategies are used for calculations. ', 'put /api/v4/application/appearance': 'Use an API call to modify GitLab instance appearance configuration. ', 'get /api/v4/application/appearance': 'List the current appearance configuration of the GitLab instance. ', 'put /api/v4/application/plan_limits': 'Modify the limits of a plan on the GitLab instance. ', 'get /api/v4/application/plan_limits': 'List the current limits of a plan on the GitLab instance. ', 'get /api/v4/deploy_keys': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated > `projects_with_readonly_access` [introduced](https://gitlab.com/gitlab-org/gitlab/-/merge_requests/119147) in GitLab 16.0. Get a list of all deploy keys across all projects of the GitLab instance. This endpoint requires administrator access and is not available on GitLab.com. ', 'get /api/v4/deploy_tokens': 'DETAILS: **Tier:** Free, Premium, Ultimate **Offering:** Self-managed, GitLab Dedicated Get a list of all deploy tokens across the GitLab instance. This endpoint requires administrator access. ', 'post /api/v4/import/github/gists': "You can use the GitLab API to import personal GitHub gists (with up to 10 files) into personal GitLab snippets. GitHub gists with more than 10 files are skipped. You should manually migrate these GitHub gists. If any gists couldn't be imported, an email is sent with a list of gists that were not imported. ", 'post /api/v4/import/github/cancel': 'Cancel an in-progress GitHub project import using the API. ', 'post /api/v4/import/github': 'Import your projects from GitHub to GitLab using the API. Prerequisites: - [Prerequisites for GitHub importer](../user/project/import/github.md#prerequisites). - The namespace set in `target_namespace` must exist. - The namespace can be your user namespace or an existing group that you have at least the Maintainer role for. ', 'post /api/v4/import/bitbucket_server': 'Import your projects from Bitbucket Server to GitLab using the API. The Bitbucket Project Key is only used for finding the repository in Bitbucket. You must specify a `target_namespace` if you want to import the repository to a GitLab group. If you do not specify `target_namespace`, the project imports to your personal user namespace. Prerequisites: - For more information, see [prerequisites for Bitbucket Server importer](../user/project/import/bitbucket_server.md). ', 'post /api/v4/slack/trigger': 'Trigger a global slack command', 'get /api/v4/metadata': '', 'get /api/v4/version': '', 'post /api/v4/topics/merge': 'You must be an administrator to merge a source topic into a target topic. When you merge topics, you delete the source topic and move all assigned projects to the target topic. ', 'delete /api/v4/topics/{id}': 'You must be an administrator to delete a project topic. When you delete a project topic, you also delete the topic assignment for projects. ', 'put /api/v4/topics/{id}': 'Update a project topic. Only available to administrators. ', 'get /api/v4/topics/{id}': 'Get a project topic by ID. ', 'post /api/v4/topics': 'Create a new project topic. Only available to administrators. ', 'get /api/v4/topics': 'Returns a list of project topics in the GitLab instance ordered by number of associated projects. '}
Before actually using a Gitlab API call, you can should the `get_api_documentation_gitlab` function in the `utils` module to get detailed API documentation of the API. For example, if you want to use the API GET /api/v4/projects/{id}/repository/commits, you should first do: 
<execute_ipython>
from utils import get_api_documentation_gitlab
get_api_documentation_gitlab('GET /api/v4/projects/{id}/repository/commits')
</execute_ipython>
This will provide you with detailed descriptions of the input parameters and example output jsons.IMPORTANT: You should ONLY interact with the environment provided to you AND NEVER ASK FOR HUMAN HELP.
When you think you have completed the request, please run the following command: <execute_bash> exit </execute_bash>.

obs - NullObservation(content='', observation='null')

Step 1:
act - **BrowseInteractiveAction**
BROWSER_ACTIONS: goto("http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/users/sign_in")
obs - **BrowserOutputObservation**
URL: http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/users/sign_in
Status code: 200
Error: False
Open pages: ['http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/users/sign_in']
Active page index: 0
Last browser action: goto("http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/users/sign_in")
Last browser action error: 
Focused element bid: 66
CONTENT: #  GitLab Community Edition 

Username or email 

This field is required. 

Password 

This field is required. 

<::before><::after> Remember me 

[ Forgot your password? ](/users/password/new)

Sign in 

Don't have an account yet? [ Register now ](/users/sign_up)

* * *

[ Explore ](/explore) [ Help ](/help) [ About GitLab ](https://about.gitlab.com) [ Community forum ](https://forum.gitlab.com)



Step 2:
act - **BrowseInteractiveAction**
BROWSER_ACTIONS: fill("66", "byteblaze")
fill("70", "hello1234")
click("83")
goto("http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023")
obs - **BrowserOutputObservation**
URL: http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/
Status code: 200
Error: True
Open pages: ['http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/']
Active page index: 0
Last browser action: fill("66", "byteblaze")
fill("70", "hello1234")
click("83")
goto("http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023")
Last browser action error: TimeoutError: Timeout 500ms exceeded.
=========================== logs ===========================
waiting for get_by_test_id("83")
  locator resolved to <button value="" bid="83" name="button" type="submit" br…>Sign in</button>
attempting click action
  waiting for element to be visible, enabled and stable
  element is visible, enabled and stable
  scrolling into view if needed
  done scrolling
  performing click action
  click action done
  waiting for scheduled navigations to finish
============================================================
Focused element bid: 49
CONTENT: Skip to content 

GitLab  [ ](/ "Dashboard")

  *     * **Switch to** Projects  Groups  **Explore** [ Milestones  ](/dashboard/milestones) [ Snippets  ](/dashboard/snippets) [ Activity  ](/dashboard/activity)

Frequently visited 

      * Projects you visit often will appear here 

[ View all projects  ](/dashboard/projects)




[ Projects ](/dashboard/projects) [ Groups ](/dashboard/groups) [ Milestones ](/dashboard/milestones) [ Snippets ](/dashboard/snippets) [ Activity ](/dashboard/activity)

  * ` / `

  * [ ](/search "Search")



  * [ ](/projects/new "Create new...")

    * [ New project/repository ](/projects/new)
    * [ New group ](/groups/new)
    * [ New snippet ](/-/snippets/new)

  * [ 12  ](/dashboard/issues?assignee_username=byteblaze "Issues")
  * [ 8  ](/dashboard/merge_requests?assignee_username=byteblaze "Merge requests")

    * Merge requests 
    * [ Assigned to you  3  ](/dashboard/merge_requests?assignee_username=byteblaze)
    * [ Review requests for you  5  ](/dashboard/merge_requests?reviewer_username=byteblaze)

  * [ 4  ](/dashboard/todos "To-Do List")
  * [ Help  ](/help)

    *     * What's new  10 
    * [ Help ](/help)
    * [ Support ](https://about.gitlab.com/getting-help/)
    * [ Community forum ](https://forum.gitlab.com)
    * Keyboard shortcuts ` ? `
    *     * [ Submit feedback ](https://about.gitlab.com/submit-feedback)
    * [ Contribute to GitLab ](https://about.gitlab.com/contributing)

  * [ ](/byteblaze)

    * [ Byte Blaze  @byteblaze ](/byteblaze)
    *     * Set status 
    * [ Edit profile ](/-/profile)
    * [ Preferences ](/-/profile/preferences)
    *     * [ Help ](/help)
    * [ Support ](https://about.gitlab.com/getting-help/)
    * [ Community forum ](https://forum.gitlab.com)
    * [ Submit feedback ](https://about.gitlab.com/submit-feedback)
    * [ Contribute to GitLab ](https://about.gitlab.com/contributing)
    *     * [ Sign out ](/users/sign_out)




Toggle navigation  Menu 

<::after>

#  Projects 

[ New project  ](/projects/new)

<::after>

<::after>

  * [ Yours  14  ](/dashboard/projects)
  * [ Starred  3  ](/dashboard/projects/starred)
  * [ Explore ](/explore)
  * [ Topics ](/explore/projects/topics)



Name 

  * Sort by 
  * [ Updated date ](/?sort=latest_activity_desc)
  * [ Last created ](/?sort=created_desc)
  * [ Name ](/?sort=name_asc)
  * [ Name, descending ](/?sort=name_desc)
  * [ Most stars ](/?sort=stars_desc)
  * [ Oldest updated ](/?sort=latest_activity_asc)
  * [ Oldest created ](/?sort=created_asc)
  *   * [ Hide archived projects ](/?sort=name_asc)
  * [ Show archived projects ](/?archived=true&sort=name_asc)
  * [ Show archived projects only ](/?archived=only&sort=name_asc)
  *   * [ Owned by anyone ](/?sort=name_asc)
  * [ Owned by me ](/?personal=true&sort=name_asc)



  * [ All ](/dashboard/projects)
  * [ Personal ](/?personal=true&sort=name_asc)



  * <::after>

[ A  ](/byteblaze/a11y-syntax-highlighting)

##  [ Byte Blaze /  a11y-syntax-highlighting  ](/byteblaze/a11y-syntax-highlighting)

Owner 

💄  Accessible light and dark syntax highlighting themes 

[ 1 ](/byteblaze/a11y-syntax-highlighting/-/starrers "Stars")

Updated  49 minutes ago 

[ 1 ](/byteblaze/a11y-syntax-highlighting/-/starrers "Stars") [ 0 ](/byteblaze/a11y-syntax-highlighting/-/forks "Forks") [ 0 ](/byteblaze/a11y-syntax-highlighting/-/merge_requests "Merge requests") [ 0 ](/byteblaze/a11y-syntax-highlighting/-/issues "Issues")

Updated  49 minutes ago 

  * <::after>

[ A  ](/byteblaze/a11y-webring.club)

##  [ Byte Blaze /  a11y-webring.club  ](/byteblaze/a11y-webring.club)

Owner 

🌐  A webring for digital accessibility practitioners. 

[ 2 ](/byteblaze/a11y-webring.club/-/starrers "Stars")

Updated  1 year ago 

[ 2 ](/byteblaze/a11y-webring.club/-/starrers "Stars") [ 0 ](/byteblaze/a11y-webring.club/-/forks "Forks") [ 1 ](/byteblaze/a11y-webring.club/-/merge_requests "Merge requests") [ 4 ](/byteblaze/a11y-webring.club/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ A  ](/a11yproject/a11yproject.com)

##  [ The A11Y Project /  a11yproject.com  ](/a11yproject/a11yproject.com)

Maintainer 

The A11Y Project is a community-driven effort to make digital accessibility easier. 

[ 21 ](/a11yproject/a11yproject.com/-/starrers "Stars")

Updated  1 year ago 

[ 21 ](/a11yproject/a11yproject.com/-/starrers "Stars") [ 0 ](/a11yproject/a11yproject.com/-/forks "Forks") [ 10 ](/a11yproject/a11yproject.com/-/merge_requests "Merge requests") [ 40 ](/a11yproject/a11yproject.com/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ A  ](/byteblaze/accessible-html-content-patterns)

##  [ Byte Blaze /  accessible-html-content-patterns  ](/byteblaze/accessible-html-content-patterns)

Owner 

♿  ️ The full HTML5 Doctor Element Index as well as common markup patterns for quick reference. 

[ 1 ](/byteblaze/accessible-html-content-patterns/-/starrers "Stars")

Updated  1 year ago 

[ 1 ](/byteblaze/accessible-html-content-patterns/-/starrers "Stars") [ 0 ](/byteblaze/accessible-html-content-patterns/-/forks "Forks") [ 0 ](/byteblaze/accessible-html-content-patterns/-/merge_requests "Merge requests") [ 0 ](/byteblaze/accessible-html-content-patterns/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ ](/byteblaze/cloud-to-butt)

##  [ Byte Blaze /  cloud-to-butt  ](/byteblaze/cloud-to-butt)

Owner 

Chrome extension that replaces occurrences of 'the cloud' with 'my butt' 

[ 0 ](/byteblaze/cloud-to-butt/-/starrers "Stars")

Updated  1 year ago 

[ 0 ](/byteblaze/cloud-to-butt/-/starrers "Stars") [ 0 ](/byteblaze/cloud-to-butt/-/forks "Forks") [ 0 ](/byteblaze/cloud-to-butt/-/merge_requests "Merge requests") [ 0 ](/byteblaze/cloud-to-butt/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ D  ](/primer/design)

##  [ Primer /  design  ](/primer/design)

Developer 

Primer Design Guidelines 

[ 21 ](/primer/design/-/starrers "Stars")

Updated  1 year ago 

[ 21 ](/primer/design/-/starrers "Stars") [ 0 ](/primer/design/-/forks "Forks") [ 16 ](/primer/design/-/merge_requests "Merge requests") [ 21 ](/primer/design/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ D  ](/byteblaze/dotfiles)

##  [ Byte Blaze /  dotfiles  ](/byteblaze/dotfiles)

Owner 

🤖  Computer setup 

[ 0 ](/byteblaze/dotfiles/-/starrers "Stars")

Updated  1 year ago 

[ 0 ](/byteblaze/dotfiles/-/starrers "Stars") [ 0 ](/byteblaze/dotfiles/-/forks "Forks") [ 0 ](/byteblaze/dotfiles/-/merge_requests "Merge requests") [ 0 ](/byteblaze/dotfiles/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ E  ](/byteblaze/empathy-prompts)

##  [ Byte Blaze /  empathy-prompts  ](/byteblaze/empathy-prompts)

Owner 

💡  Ideas to help consider Inclusive Design principles when making things for others to use. 

[ 6 ](/byteblaze/empathy-prompts/-/starrers "Stars")

Updated  1 year ago 

[ 6 ](/byteblaze/empathy-prompts/-/starrers "Stars") [ 1 ](/byteblaze/empathy-prompts/-/forks "Forks") [ 2 ](/byteblaze/empathy-prompts/-/merge_requests "Merge requests") [ 6 ](/byteblaze/empathy-prompts/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ E  ](/byteblaze/ericwbailey.website)

##  [ Byte Blaze /  ericwbailey.website  ](/byteblaze/ericwbailey.website)

Owner 

📐  Repo for my personal website. 

[ 2 ](/byteblaze/ericwbailey.website/-/starrers "Stars")

Updated  1 year ago 

[ 2 ](/byteblaze/ericwbailey.website/-/starrers "Stars") [ 0 ](/byteblaze/ericwbailey.website/-/forks "Forks") [ 0 ](/byteblaze/ericwbailey.website/-/merge_requests "Merge requests") [ 0 ](/byteblaze/ericwbailey.website/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ G  ](/byteblaze/gimmiethat.space)

##  [ Byte Blaze /  gimmiethat.space  ](/byteblaze/gimmiethat.space)

Owner 

I need some space. 

[ 0 ](/byteblaze/gimmiethat.space/-/starrers "Stars")

Updated  1 year ago 

[ 0 ](/byteblaze/gimmiethat.space/-/starrers "Stars") [ 0 ](/byteblaze/gimmiethat.space/-/forks "Forks") [ 0 ](/byteblaze/gimmiethat.space/-/merge_requests "Merge requests") [ 0 ](/byteblaze/gimmiethat.space/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ M  ](/byteblaze/millennials-to-snake-people)

##  [ Byte Blaze /  millennials-to-snake-people  ](/byteblaze/millennials-to-snake-people)

Owner 

🐍  Chrome extension that replaces occurrences of 'Millennials' with 'Snake People' 

[ 6 ](/byteblaze/millennials-to-snake-people/-/starrers "Stars")

Updated  1 year ago 

[ 6 ](/byteblaze/millennials-to-snake-people/-/starrers "Stars") [ 0 ](/byteblaze/millennials-to-snake-people/-/forks "Forks") [ 2 ](/byteblaze/millennials-to-snake-people/-/merge_requests "Merge requests") [ 4 ](/byteblaze/millennials-to-snake-people/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ R  ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline)

##  [ Byte Blaze /  remove-board-movement-events-from-the-github-issue-timeline  ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline)

Owner 

This extension can remove and restore the presence of timeline items generated by a project board event from GitHub's timeline. 

[ 0 ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/starrers "Stars")

Updated  1 year ago 

[ 0 ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/starrers "Stars") [ 1 ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/forks "Forks") [ 0 ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/merge_requests "Merge requests") [ 0 ](/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ S  ](/byteblaze/solarized-prism-theme)

##  [ Byte Blaze /  solarized-prism-theme  ](/byteblaze/solarized-prism-theme)

Owner 

solarized theme for prism.js 

[ 0 ](/byteblaze/solarized-prism-theme/-/starrers "Stars")

Updated  1 year ago 

[ 0 ](/byteblaze/solarized-prism-theme/-/starrers "Stars") [ 0 ](/byteblaze/solarized-prism-theme/-/forks "Forks") [ 0 ](/byteblaze/solarized-prism-theme/-/merge_requests "Merge requests") [ 0 ](/byteblaze/solarized-prism-theme/-/issues "Issues")

Updated  1 year ago 

  * <::after>

[ T  ](/byteblaze/timeit)

##  [ Byte Blaze /  timeit  ](/byteblaze/timeit)

Owner 

Rails implementation of time tracking tool timeit 

[ 0 ](/byteblaze/timeit/-/starrers "Stars")

Updated  1 year ago 

[ 0 ](/byteblaze/timeit/-/starrers "Stars") [ 0 ](/byteblaze/timeit/-/forks "Forks") [ 0 ](/byteblaze/timeit/-/merge_requests "Merge requests") [ 0 ](/byteblaze/timeit/-/issues "Issues")

Updated  1 year ago 




#  Menu 

[ ](/search)

Create new... 

  * [ New project/repository  ](/projects/new)
  * [ New group  ](/groups/new)
  * [ New snippet  ](/-/snippets/new)




**Switch to** Projects  Groups  **Explore** [ Milestones  ](/dashboard/milestones) [ Snippets  ](/dashboard/snippets) [ Activity  ](/dashboard/activity)



Step 3:
act - **IPythonRunCellAction**
THOUGHT: To find the best GAN (Generative Adversarial Network) implementation on GitLab and get the SSH clone command, we can follow these steps:

1. **Search for GAN Projects**: Use the GitLab API to search for projects related to GAN.
2. **Identify the Best Implementation**: Based on criteria such as stars, forks, or recent activity, identify the best GAN implementation.
3. **Get the SSH Clone URL**: Retrieve the SSH clone URL for the identified project.

### Step 1: Search for GAN Projects

We will use the `GET /api/v4/projects` API to search for projects with the keyword "GAN".
CODE:
import requests

# Define the API endpoint and headers
api_url = "http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023/api/v4/projects"
headers = {
    "PRIVATE-TOKEN": "glpat-KygcYjwtD2JfA6wU4wBd"
}

# Define the search parameters
params = {
    "search": "GAN",
    "order_by": "stars",
    "sort": "desc",
    "per_page": 5
}

# Make the API request
response = requests.get(api_url, headers=headers, params=params)
response.json()
obs - **IPythonRunCellObservation**
{'error': 'order_by does not have a valid value'}

Step 4:
act - **IPythonRunCellAction**
THOUGHT: It seems that the `order_by` parameter does not accept "stars" as a valid value. Let's try searching for GAN projects without the `order_by` parameter and then manually inspect the results to identify the best implementation.

### Step 1: Search for GAN Projects

We will use the `GET /api/v4/projects` API to search for projects with the keyword "GAN" without the `order_by` parameter.
CODE:
# Define the search parameters without the order_by parameter
params = {
    "search": "GAN",
    "per_page": 5
}

# Make the API request
response = requests.get(api_url, headers=headers, params=params)
response.json()
obs - **IPythonRunCellObservation**
[{'id': 86,
  'description': 'PyTorch implementations of Generative Adversarial Networks.',
  'name': 'PyTorch-GAN',
  'name_with_namespace': 'Erik Linder-Norén / PyTorch-GAN',
  'path': 'PyTorch-GAN',
  'path_with_namespace': 'eriklindernoren/PyTorch-GAN',
  'created_at': '2023-03-19T20:39:07.692Z',
  'default_branch': 'master',
  'tag_list': [],
  'topics': [],
  'ssh_url_to_repo': 'ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git',
  'http_url_to_repo': 'http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git',
  'web_url': 'http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN',
  'readme_url': 'http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md',
  'avatar_url': None,
  'forks_count': 0,
  'star_count': 45,
  'last_activity_at': '2022-11-08T15:50:58.000Z',
  'namespace': {'id': 365,
   'name': 'Erik Linder-Norén',
   'path': 'eriklindernoren',
   'kind': 'user',
   'full_path': 'eriklindernoren',
   'parent_id': None,
   'avatar_url': 'https://www.gravatar.com/avatar/7d8751467ddaccbc715df5ca1c02b6a0?s=80&d=identicon',
   'web_url': 'http://metis.lti.cs.cmu.edu:8023/eriklindernoren'},
  '_links': {'self': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86',
   'issues': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/issues',
   'merge_requests': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/merge_requests',
   'repo_branches': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/repository/branches',
   'labels': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/labels',
   'events': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/events',
   'members': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/members',
   'cluster_agents': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/86/cluster_agents'},
  'packages_enabled': True,
  'empty_repo': False,
  'archived': False,
  'visibility': 'public',
  'owner': {'id': 311,
   'username': 'eriklindernoren',
   'name': 'Erik Linder-Norén',
   'state': 'active',
   'avatar_url': 'https://www.gravatar.com/avatar/7d8751467ddaccbc715df5ca1c02b6a0?s=80&d=identicon',
   'web_url': 'http://metis.lti.cs.cmu.edu:8023/eriklindernoren'},
  'resolve_outdated_diff_discussions': False,
  'container_expiration_policy': {'cadence': '1d',
   'enabled': False,
   'keep_n': 10,
   'older_than': '90d',
   'name_regex': '.*',
   'name_regex_keep': None,
   'next_run_at': '2023-03-20T20:39:09.411Z'},
  'issues_enabled': True,
  'merge_requests_enabled': True,
  'wiki_enabled': True,
  'jobs_enabled': True,
  'snippets_enabled': True,
  'container_registry_enabled': True,
  'service_desk_enabled': False,
  'can_create_merge_request_in': True,
  'issues_access_level': 'enabled',
  'repository_access_level': 'enabled',
  'merge_requests_access_level': 'enabled',
  'forking_access_level': 'enabled',
  'wiki_access_level': 'enabled',
  'builds_access_level': 'enabled',
  'snippets_access_level': 'enabled',
  'pages_access_level': 'enabled',
  'operations_access_level': 'enabled',
  'analytics_access_level': 'enabled',
  'container_registry_access_level': 'enabled',
  'security_and_compliance_access_level': 'private',
  'releases_access_level': 'enabled',
  'environments_access_level': 'enabled',
  'feature_flags_access_level': 'enabled',
  'infrastructure_access_level': 'enabled',
  'monitor_access_level': 'enabled',
  'emails_disabled': None,
  'shared_runners_enabled': True,
  'lfs_enabled': True,
  'creator_id': 1,
  'import_status': 'finished',
  'open_issues_count': 102,
  'ci_default_git_depth': 20,
  'ci_forward_deployment_enabled': True,
  'ci_job_token_scope_enabled': False,
  'ci_separated_caches': True,
  'ci_opt_in_jwt': False,
  'ci_allow_fork_pipelines_to_run_in_parent_project': True,
  'public_jobs': True,
  'build_timeout': 3600,
  'auto_cancel_pending_pipelines': 'enabled',
  'ci_config_path': None,
  'shared_with_groups': [],
  'only_allow_merge_if_pipeline_succeeds': False,
  'allow_merge_on_skipped_pipeline': None,
  'restrict_user_defined_variables': False,
  'request_access_enabled': True,
  'only_allow_merge_if_all_discussions_are_resolved': False,
  'remove_source_branch_after_merge': True,
  'printing_merge_request_link_enabled': True,
  'merge_method': 'merge',
  'squash_option': 'default_off',
  'enforce_auth_checks_on_uploads': True,
  'suggestion_commit_message': None,
  'merge_commit_template': None,
  'squash_commit_template': None,
  'issue_branch_template': None,
  'auto_devops_enabled': False,
  'auto_devops_deploy_strategy': 'continuous',
  'autoclose_referenced_issues': True,
  'keep_latest_artifact': True,
  'runner_token_expiration_interval': None,
  'permissions': {'project_access': None, 'group_access': None}},
 {'id': 64,
  'description': "Organize world's knowledge, explore connections and curate learning paths",
  'name': 'learn-anything',
  'name_with_namespace': 'Learn Anything / learn-anything',
  'path': 'learn-anything',
  'path_with_namespace': 'learn-anything/learn-anything',
  'created_at': '2023-03-19T18:37:12.211Z',
  'default_branch': 'main',
  'tag_list': [],
  'topics': [],
  'ssh_url_to_repo': 'ssh://git@metis.lti.cs.cmu.edu:2222/learn-anything/learn-anything.git',
  'http_url_to_repo': 'http://metis.lti.cs.cmu.edu:8023/learn-anything/learn-anything.git',
  'web_url': 'http://metis.lti.cs.cmu.edu:8023/learn-anything/learn-anything',
  'readme_url': 'http://metis.lti.cs.cmu.edu:8023/learn-anything/learn-anything/-/blob/main/readme.md',
  'avatar_url': None,
  'forks_count': 0,
  'star_count': 0,
  'last_activity_at': '2023-03-19T18:37:12.211Z',
  'namespace': {'id': 575,
   'name': 'Learn Anything',
   'path': 'learn-anything',
   'kind': 'user',
   'full_path': 'learn-anything',
   'parent_id': None,
   'avatar_url': 'https://www.gravatar.com/avatar/f6d380d2043617eeb92d4d5a15f8cf19?s=80&d=identicon',
   'web_url': 'http://metis.lti.cs.cmu.edu:8023/learn-anything'},
  '_links': {'self': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64',
   'issues': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/issues',
   'merge_requests': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/merge_requests',
   'repo_branches': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/repository/branches',
   'labels': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/labels',
   'events': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/events',
   'members': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/members',
   'cluster_agents': 'http://metis.lti.cs.cmu.edu:8023/api/v4/projects/64/cluster_agents'},
  'packages_enabled': True,
  'empty_repo': False,
  'archived': False,
  'visibility': 'public',
  'owner': {'id': 510,
   'username': 'learn-anything',
   'name': 'Learn Anything',
   'state': 'active',
   'avatar_url': 'https://www.gravatar.com/avatar/f6d380d2043617eeb92d4d5a15f8cf19?s=80&d=identicon',
   'web_url': 'http://metis.lti.cs.cmu.edu:8023/learn-anything'},
  'resolve_outdated_diff_discussions': False,
  'container_expiration_policy': {'cadence': '1d',
   'enabled': False,
   'keep_n': 10,
   'older_than': '90d',
   'name_regex': '.*',
   'name_regex_keep': None,
   'next_run_at': '2023-03-20T18:37:12.257Z'},
  'issues_enabled': True,
  'merge_requests_enabled': True,
  'wiki_enabled': True,
  'jobs_enabled': True,
  'snippets_enabled': True,
  'container_registry_enabled': True,
  'service_desk_enabled': False,
  'can_create_merge_request_in': True,
  'issues_access_level': 'enabled',
  'repository_access_level': 'enabled',
  'merge_requests_access_level': 'enabled',
  'forking_access_level': 'enabled',
  'wiki_access_level': 'enabled',
  'builds_access_level': 'enabled',
  'snippets_access_level': 'enabled',
  'pages_access_level': 'enabled',
  'operations_access_level': 'enabled',
  'analytics_access_level': 'enabled',
  'container_registry_access_level': 'enabled',
  'security_and_compliance_access_level': 'private',
  'releases_access_level': 'enabled',
  'environments_access_level': 'enabled',
  'feature_flags_access_level': 'enabled',
  'infrastructure_access_level': 'enabled',
  'monitor_access_level': 'enabled',
  'emails_disabled': None,
  'shared_runners_enabled': True,
  'lfs_enabled': True,
  'creator_id': 1,
  'import_status': 'finished',
  'open_issues_count': 0,
  'ci_default_git_depth': 20,
  'ci_forward_deployment_enabled': True,
  'ci_job_token_scope_enabled': False,
  'ci_separated_caches': True,
  'ci_opt_in_jwt': False,
  'ci_allow_fork_pipelines_to_run_in_parent_project': True,
  'public_jobs': True,
  'build_timeout': 3600,
  'auto_cancel_pending_pipelines': 'enabled',
  'ci_config_path': None,
  'shared_with_groups': [],
  'only_allow_merge_if_pipeline_succeeds': False,
  'allow_merge_on_skipped_pipeline': None,
  'restrict_user_defined_variables': False,
  'request_access_enabled': True,
  'only_allow_merge_if_all_discussions_are_resolved': False,
  'remove_source_branch_after_merge': True,
  'printing_merge_request_link_enabled': True,
  'merge_method': 'merge',
  'squash_option': 'default_off',
  'enforce_auth_checks_on_uploads': True,
  'suggestion_commit_message': None,
  'merge_commit_template': None,
  'squash_commit_template': None,
  'issue_branch_template': None,
  'auto_devops_enabled': True,
  'auto_devops_deploy_strategy': 'continuous',
  'autoclose_referenced_issues': True,
  'keep_latest_artifact': True,
  'runner_token_expiration_interval': None,
  'permissions': {'project_access': None, 'group_access': None}}]

Step 5:
act - **BrowseInteractiveAction**
BROWSER_ACTIONS: goto("http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN")
obs - **BrowserOutputObservation**
URL: http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN
Status code: 200
Error: False
Open pages: ['http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN']
Active page index: 0
Last browser action: goto("http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN")
Last browser action error: 
Focused element bid: 64
CONTENT: Skip to content 

GitLab  [ ](/ "Dashboard")

  *     * **Explore** [ Projects  ](/explore) [ Groups  ](/explore/groups) [ Snippets  ](/explore/snippets)




[ Projects ](/explore) [ Groups ](/explore/groups) [ Snippets ](/explore/snippets)

  * ` / `

  * [ ](/search?project_id=86 "Search")



  * [ Help  ](/help)

    *     * [ Help ](/help)
    * [ Support ](https://about.gitlab.com/getting-help/)
    * [ Community forum ](https://forum.gitlab.com)
    * Keyboard shortcuts ` ? `
    *     * [ Submit feedback ](https://about.gitlab.com/submit-feedback)
    * [ Contribute to GitLab ](https://about.gitlab.com/contributing)

  * [ Sign in / Register  ](/users/sign_in?redirect_to_referer=yes)




Toggle navigation  Menu 

  * [ P  PyTorch-GAN  ](/eriklindernoren/PyTorch-GAN)
  * [ Project information  ](/eriklindernoren/PyTorch-GAN/activity)
    * **Project information**
    *     * [ Activity  ](/eriklindernoren/PyTorch-GAN/activity)
    * [ Labels  ](/eriklindernoren/PyTorch-GAN/-/labels)
    * [ Members  ](/eriklindernoren/PyTorch-GAN/-/project_members)
  * [ Repository  ](/eriklindernoren/PyTorch-GAN/-/tree/master)
    * **Repository**
    *     * [ Files  ](/eriklindernoren/PyTorch-GAN/-/tree/master)
    * [ Commits  ](/eriklindernoren/PyTorch-GAN/-/commits/master)
    * [ Branches  ](/eriklindernoren/PyTorch-GAN/-/branches)
    * [ Tags  ](/eriklindernoren/PyTorch-GAN/-/tags)
    * [ Contributors  ](/eriklindernoren/PyTorch-GAN/-/graphs/master)
    * [ Graph  ](/eriklindernoren/PyTorch-GAN/-/network/master)
    * [ Compare  ](/eriklindernoren/PyTorch-GAN/-/compare?from=master&to=master)
  * [ Issues  102  ](/eriklindernoren/PyTorch-GAN/-/issues)
    * **Issues** 102 
    *     * [ List  ](/eriklindernoren/PyTorch-GAN/-/issues)
    * [ Boards  ](/eriklindernoren/PyTorch-GAN/-/boards)
    * [ Service Desk  ](/eriklindernoren/PyTorch-GAN/-/issues/service_desk)
    * [ Milestones  ](/eriklindernoren/PyTorch-GAN/-/milestones)
  * [ Merge requests  24  ](/eriklindernoren/PyTorch-GAN/-/merge_requests)
    * **Merge requests** 24 
  * [ CI/CD  ](/eriklindernoren/PyTorch-GAN/-/pipelines)
    * **CI/CD**
    *     * [ Pipelines  ](/eriklindernoren/PyTorch-GAN/-/pipelines)
    * [ Jobs  ](/eriklindernoren/PyTorch-GAN/-/jobs)
    * [ Schedules  ](/eriklindernoren/PyTorch-GAN/-/pipeline_schedules)
  * [ Deployments  ](/eriklindernoren/PyTorch-GAN/-/environments)
    * **Deployments**
    *     * [ Environments  ](/eriklindernoren/PyTorch-GAN/-/environments)
    * [ Releases  ](/eriklindernoren/PyTorch-GAN/-/releases)
  * [ Packages and registries  ](/eriklindernoren/PyTorch-GAN/-/packages)
    * **Packages and registries**
    *     * [ Package Registry  ](/eriklindernoren/PyTorch-GAN/-/packages)
    * [ Infrastructure Registry  ](/eriklindernoren/PyTorch-GAN/-/infrastructure_registry)
  * [ Monitor  ](/eriklindernoren/PyTorch-GAN/-/incidents)
    * **Monitor**
    *     * [ Incidents  ](/eriklindernoren/PyTorch-GAN/-/incidents)
  * [ Analytics  ](/eriklindernoren/PyTorch-GAN/-/value_stream_analytics)
    * **Analytics**
    *     * [ Value stream  ](/eriklindernoren/PyTorch-GAN/-/value_stream_analytics)
    * [ CI/CD  ](/eriklindernoren/PyTorch-GAN/-/pipelines/charts)
    * [ Repository  ](/eriklindernoren/PyTorch-GAN/-/graphs/master/charts)
  * [ Wiki  ](/eriklindernoren/PyTorch-GAN/-/wikis/home)
    * **Wiki**
  * [ Snippets  ](/eriklindernoren/PyTorch-GAN/-/snippets)
    * **Snippets**
  * [ Activity ](/eriklindernoren/PyTorch-GAN/activity)
  * [ Graph ](/eriklindernoren/PyTorch-GAN/-/network/master)
  * [ Create a new issue ](/eriklindernoren/PyTorch-GAN/-/issues/new)
  * [ Jobs ](/eriklindernoren/PyTorch-GAN/-/jobs)
  * [ Commits ](/eriklindernoren/PyTorch-GAN/-/commits/master)
  * [ Issue Boards ](/eriklindernoren/PyTorch-GAN/-/boards)

Collapse sidebar  Close sidebar 

<::after>

Open sidebar 

  * [ Erik Linder-Norén ](/eriklindernoren)
  * [ PyTorch-GAN  ](/eriklindernoren/PyTorch-GAN)



P 

#  PyTorch-GAN 

Project ID: 86 

[ Star  ](/users/sign_in "You must sign in to star a project") [ 45 ](/eriklindernoren/PyTorch-GAN/-/starrers "Starrers")

  * [ **193** Commits ](/eriklindernoren/PyTorch-GAN/-/commits/master)
  * [ **25** Branches ](/eriklindernoren/PyTorch-GAN/-/branches)
  * [ **0** Tags ](/eriklindernoren/PyTorch-GAN/-/tags)
  * **184.7 MB** Project Storage 




PyTorch implementations of Generative Adversarial Networks. 

Read more 

Python  99.6%  ">

Shell  0.4%  ">

<::after>

[ Update README.md ](/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e)

Erik Linder-Norén authored  3 years ago 

4AEE18F83AFDEB23  [ Learn more about signing commits ](/help/user/project/repository/gpg_signed_commits/index.md) " data-html="true" data-placement="top" data-title=" 

This commit was signed with an **unverified** signature. 

" data-toggle="popover" role="button" tabindex="0"> Unverified 

36d3c77e 

master 

Select Git revision 

  * Branches  25 

  * github/fork/Aniloid2/patch-1 

  * github/fork/Boyden/master 

  * github/fork/CaoE/master 

  * github/fork/HCMY/master 

  * github/fork/HanbumKo/patch-1 

  * github/fork/Hazarre/master 

  * github/fork/Hosein47/patch-1 

  * github/fork/IvanFei/master 

  * github/fork/Misaliet/Fix-variable-name-typo 

  * github/fork/San-ctuary/modify_acgan 

  * github/fork/Sean16SYSU/dev 

  * github/fork/WalterDUT/master 

  * github/fork/aqbewtra/patch-1 

  * github/fork/chenyang1999/patch-4 

  * github/fork/foersterrobert/patch-1 

  * github/fork/hou-yz/master 

  * github/fork/lukas-blecher/master 

  * github/fork/masud99r/patch-1 

  * github/fork/mexxik/bgan_fix 

  * github/fork/nicolas-gervais/patch-1 




  1. [ PyTorch-GAN ](/eriklindernoren/PyTorch-GAN/-/tree/master/)



[ Find file ](/eriklindernoren/PyTorch-GAN/-/find_file/master)

Select Archive Format 

#####  Download source code 

[ zip ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.zip) [ tar.gz ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar.gz) [ tar.bz2 ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar.bz2) [ tar ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar)

Clone 

  * Clone with SSH 

  * Clone with HTTP 

  *   * Open in your IDE  [ Visual Studio Code (SSH)  ](vscode://vscode.git/clone?url=ssh%3A%2F%2Fgit%40metis.lti.cs.cmu.edu%3A2222%2Feriklindernoren%2FPyTorch-GAN.git) [ Visual Studio Code (HTTPS)  ](vscode://vscode.git/clone?url=http%3A%2F%2Fmetis.lti.cs.cmu.edu%3A8023%2Feriklindernoren%2FPyTorch-GAN.git) [ IntelliJ IDEA (SSH)  ](jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=ssh%3A%2F%2Fgit%40metis.lti.cs.cmu.edu%3A2222%2Feriklindernoren%2FPyTorch-GAN.git) [ IntelliJ IDEA (HTTPS)  ](jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=http%3A%2F%2Fmetis.lti.cs.cmu.edu%3A8023%2Feriklindernoren%2FPyTorch-GAN.git)



Copy HTTP clone URL 

  * [ **Copy SSH clone URL** ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git  ](ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git)
  * [ **Copy HTTP clone URL** http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git  ](http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git)



  * [ README ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md)
  * [ MIT License  ](/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE)



Name  |  Last commit  |  Last update   
---|---|---  
[ <::before> assets  ](/eriklindernoren/PyTorch-GAN/-/tree/master/assets "assets") |  [ adds clustergan gif ](/eriklindernoren/PyTorch-GAN/-/commit/23a2b9f4514cc997a8689e5e19fbddf7adc539f6 "adds clustergan gif
") |  5 years ago   
[ <::before> data  ](/eriklindernoren/PyTorch-GAN/-/tree/master/data "data") |  [ Figures ](/eriklindernoren/PyTorch-GAN/-/commit/df342dd3ecd5270a8810bdaae30c1c6571ac31bc "Figures
") |  6 years ago   
[ <::before> implementations  ](/eriklindernoren/PyTorch-GAN/-/tree/master/implementations "implementations") |  [ Adds single clustergan script ](/eriklindernoren/PyTorch-GAN/-/commit/5f84be03dec16e032d170dafd1689ca948218e88 "Adds single clustergan script
") |  5 years ago   
[ <::before> .gitignore  ](/eriklindernoren/PyTorch-GAN/-/blob/master/.gitignore ".gitignore") |  [ MNIST normalization. Black refactoring. ](/eriklindernoren/PyTorch-GAN/-/commit/c5d6be170013db8975d96806084df573d87e5d26 "MNIST normalization. Black refactoring.
") |  5 years ago   
[ <::before> LICENSE  ](/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE "LICENSE") |  [ Initial commit ](/eriklindernoren/PyTorch-GAN/-/commit/a18bcc2695e95e10420570913816317b1f233438 "Initial commit") |  6 years ago   
[ <::before> README.md  ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md "README.md") |  [ Update README.md ](/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e "Update README.md") |  3 years ago   
[ <::before> requirements.txt  ](/eriklindernoren/PyTorch-GAN/-/blob/master/requirements.txt "requirements.txt") |  [ Added PyTorch 0.4.0 to requirements ](/eriklindernoren/PyTorch-GAN/-/commit/8400a6e4ab0eb1a69f641bc568ce56049a2112eb "Added PyTorch 0.4.0 to requirements
") |  6 years ago   
  
[ **README.md** ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md)

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png)

**This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at[ eriklindernoren@gmail.com ](mailto:eriklindernoren@gmail.com) . **

##  <::after> PyTorch-GAN 

Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed. 

**See also:** [ Keras-GAN ](https://github.com/eriklindernoren/Keras-GAN)

##  <::after> Table of Contents 

  * <::marker> Installation 
  * <::marker> Implementations 
    * <::marker> Auxiliary Classifier GAN 
    * <::marker> Adversarial Autoencoder 
    * <::marker> BEGAN 
    * <::marker> BicycleGAN 
    * <::marker> Boundary-Seeking GAN 
    * <::marker> Cluster GAN 
    * <::marker> Conditional GAN 
    * <::marker> Context-Conditional GAN 
    * <::marker> Context Encoder 
    * <::marker> Coupled GAN 
    * <::marker> CycleGAN 
    * <::marker> Deep Convolutional GAN 
    * <::marker> DiscoGAN 
    * <::marker> DRAGAN 
    * <::marker> DualGAN 
    * <::marker> Energy-Based GAN 
    * <::marker> Enhanced Super-Resolution GAN 
    * <::marker> GAN 
    * <::marker> InfoGAN 
    * <::marker> Least Squares GAN 
    * <::marker> MUNIT 
    * <::marker> Pix2Pix 
    * <::marker> PixelDA 
    * <::marker> Relativistic GAN 
    * <::marker> Semi-Supervised GAN 
    * <::marker> Softmax GAN 
    * <::marker> StarGAN 
    * <::marker> Super-Resolution GAN 
    * <::marker> UNIT 
    * <::marker> Wasserstein GAN 
    * <::marker> Wasserstein GAN GP 
    * <::marker> Wasserstein GAN DIV 



##  <::after> Installation 
    
    
    $ git clone https://github.com/eriklindernoren/PyTorch-GAN
    $ cd PyTorch-GAN/
    $ sudo pip3 install -r requirements.txt

##  <::after> Implementations 

###  <::after> Auxiliary Classifier GAN 

_Auxiliary Classifier Generative Adversarial Network_

####  <::after> Authors 

Augustus Odena, Christopher Olah, Jonathon Shlens 

####  <::after> Abstract 

Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data. 

[ [Paper] ](https://arxiv.org/abs/1610.09585) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/acgan/acgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/acgan/
    $ python3 acgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif)

###  <::after> Adversarial Autoencoder 

_Adversarial Autoencoder_

####  <::after> Authors 

Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey 

####  <::after> Abstract 

n this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks. 

[ [Paper] ](https://arxiv.org/abs/1511.05644) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/aae/aae.py)

####  <::after> Run Example 
    
    
    $ cd implementations/aae/
    $ python3 aae.py

###  <::after> BEGAN 

_BEGAN: Boundary Equilibrium Generative Adversarial Networks_

####  <::after> Authors 

David Berthelot, Thomas Schumm, Luke Metz 

####  <::after> Abstract 

We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure. 

[ [Paper] ](https://arxiv.org/abs/1703.10717) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/began/began.py)

####  <::after> Run Example 
    
    
    $ cd implementations/began/
    $ python3 began.py

###  <::after> BicycleGAN 

_Toward Multimodal Image-to-Image Translation_

####  <::after> Authors 

Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman 

####  <::after> Abstract 

Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a \emph{distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity. 

[ [Paper] ](https://arxiv.org/abs/1711.11586) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bicyclegan/bicyclegan.py)

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/bicyclegan/
    $ python3 bicyclegan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png)

Various style translations by varying the latent code. 

###  <::after> Boundary-Seeking GAN 

_Boundary-Seeking Generative Adversarial Networks_

####  <::after> Authors 

R Devon Hjelm, Athul Paul Jacob, Tong Che, Adam Trischler, Kyunghyun Cho, Yoshua Bengio 

####  <::after> Abstract 

Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning. 

[ [Paper] ](https://arxiv.org/abs/1702.08431) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bgan/bgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/bgan/
    $ python3 bgan.py

###  <::after> Cluster GAN 

_ClusterGAN: Latent Space Clustering in Generative Adversarial Networks_

####  <::after> Authors 

Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan 

####  <::after> Abstract 

Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets. 

[ [Paper] ](https://arxiv.org/abs/1809.03627) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cluster_gan/clustergan.py)

Code based on a full PyTorch [ [implementation] ](https://github.com/zhampel/clusterGAN) . 

####  <::after> Run Example 
    
    
    $ cd implementations/cluster_gan/
    $ python3 clustergan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif)

###  <::after> Conditional GAN 

_Conditional Generative Adversarial Nets_

####  <::after> Authors 

Mehdi Mirza, Simon Osindero 

####  <::after> Abstract 

Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels. 

[ [Paper] ](https://arxiv.org/abs/1411.1784) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cgan/cgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/cgan/
    $ python3 cgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif)

###  <::after> Context-Conditional GAN 

_Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks_

####  <::after> Authors 

Emily Denton, Sam Gross, Rob Fergus 

####  <::after> Abstract 

We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods. 

[ [Paper] ](https://arxiv.org/abs/1611.06430) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ccgan/ccgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/ccgan/
    $ python3 ccgan.py

###  <::after> Context Encoder 

_Context Encoders: Feature Learning by Inpainting_

####  <::after> Authors 

Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros 

####  <::after> Abstract 

We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods. 

[ [Paper] ](https://arxiv.org/abs/1604.07379) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/context_encoder/context_encoder.py)

####  <::after> Run Example 
    
    
    $ cd implementations/context_encoder/
    
    $ python3 context_encoder.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png)

Rows: Masked | Inpainted | Original | Masked | Inpainted | Original 

###  <::after> Coupled GAN 

_Coupled Generative Adversarial Networks_

####  <::after> Authors 

Ming-Yu Liu, Oncel Tuzel 

####  <::after> Abstract 

We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation. 

[ [Paper] ](https://arxiv.org/abs/1606.07536) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cogan/cogan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/cogan/
    $ python3 cogan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif)

Generated MNIST and MNIST-M images 

###  <::after> CycleGAN 

_Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_

####  <::after> Authors 

Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros 

####  <::after> Abstract 

Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X→Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F:Y→X and introduce a cycle consistency loss to push F(G(X))≈X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach. 

[ [Paper] ](https://arxiv.org/abs/1703.10593) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cyclegan/cyclegan.py)

[ ](http://eriklindernoren.se/images/cyclegan.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_cyclegan_dataset.sh monet2photo
    $ cd ../implementations/cyclegan/
    $ python3 cyclegan.py --dataset_name monet2photo

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png)

Monet to photo translations. 

###  <::after> Deep Convolutional GAN 

_Deep Convolutional Generative Adversarial Network_

####  <::after> Authors 

Alec Radford, Luke Metz, Soumith Chintala 

####  <::after> Abstract 

In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations. 

[ [Paper] ](https://arxiv.org/abs/1511.06434) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dcgan/dcgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/dcgan/
    $ python3 dcgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif)

###  <::after> DiscoGAN 

_Learning to Discover Cross-Domain Relations with Generative Adversarial Networks_

####  <::after> Authors 

Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim 

####  <::after> Abstract 

While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity. 

[ [Paper] ](https://arxiv.org/abs/1703.05192) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/discogan/discogan.py)

[ ](http://eriklindernoren.se/images/discogan_architecture.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/discogan/
    $ python3 discogan.py --dataset_name edges2shoes

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png)

Rows from top to bottom: (1) Real image from domain A (2) Translated image from   
domain A (3) Reconstructed image from domain A (4) Real image from domain B (5)   
Translated image from domain B (6) Reconstructed image from domain B 

###  <::after> DRAGAN 

_On Convergence and Stability of GANs_

####  <::after> Authors 

Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira 

####  <::after> Abstract 

We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions. 

[ [Paper] ](https://arxiv.org/abs/1705.07215) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dragan/dragan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/dragan/
    $ python3 dragan.py

###  <::after> DualGAN 

_DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_

####  <::after> Authors 

Zili Yi, Hao Zhang, Ping Tan, Minglun Gong 

####  <::after> Abstract 

Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V, while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data. 

[ [Paper] ](https://arxiv.org/abs/1704.02510) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dualgan/dualgan.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh facades
    $ cd ../implementations/dualgan/
    $ python3 dualgan.py --dataset_name facades

###  <::after> Energy-Based GAN 

_Energy-based Generative Adversarial Network_

####  <::after> Authors 

Junbo Zhao, Michael Mathieu, Yann LeCun 

####  <::after> Abstract 

We introduce the "Energy-based Generative Adversarial Network" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images. 

[ [Paper] ](https://arxiv.org/abs/1609.03126) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ebgan/ebgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/ebgan/
    $ python3 ebgan.py

###  <::after> Enhanced Super-Resolution GAN 

_ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks_

####  <::after> Authors 

Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, Xiaoou Tang 

####  <::after> Abstract 

The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at [ this https URL ](https://github.com/xinntao/ESRGAN) . 

[ [Paper] ](https://arxiv.org/abs/1809.00219) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/esrgan/esrgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/esrgan/
    
    $ python3 esrgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png)

Nearest Neighbor Upsampling | ESRGAN 

###  <::after> GAN 

_Generative Adversarial Network_

####  <::after> Authors 

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio 

####  <::after> Abstract 

We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 

[ [Paper] ](https://arxiv.org/abs/1406.2661) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/gan/gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/gan/
    $ python3 gan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif)

###  <::after> InfoGAN 

_InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets_

####  <::after> Authors 

Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel 

####  <::after> Abstract 

This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods. 

[ [Paper] ](https://arxiv.org/abs/1606.03657) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/infogan/infogan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/infogan/
    $ python3 infogan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif)

Result of varying categorical latent variable by column. 

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png)

Result of varying continuous latent variable by row. 

###  <::after> Least Squares GAN 

_Least Squares Generative Adversarial Networks_

####  <::after> Authors 

Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley 

####  <::after> Abstract 

Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson χ2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs. 

[ [Paper] ](https://arxiv.org/abs/1611.04076) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/lsgan/lsgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/lsgan/
    $ python3 lsgan.py

###  <::after> MUNIT 

_Multimodal Unsupervised Image-to-Image Translation_

####  <::after> Authors 

Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz 

####  <::after> Abstract 

Unsupervised image-to-image translation is an important and challenging problem in computer vision. Given an image in the source domain, the goal is to learn the conditional distribution of corresponding images in the target domain, without seeing any pairs of corresponding images. While this conditional distribution is inherently multimodal, existing approaches make an overly simplified assumption, modeling it as a deterministic one-to-one mapping. As a result, they fail to generate diverse outputs from a given source domain image. To address this limitation, we propose a Multimodal Unsupervised Image-to-image Translation (MUNIT) framework. We assume that the image representation can be decomposed into a content code that is domain-invariant, and a style code that captures domain-specific properties. To translate an image to another domain, we recombine its content code with a random style code sampled from the style space of the target domain. We analyze the proposed framework and establish several theoretical results. Extensive experiments with comparisons to the state-of-the-art approaches further demonstrates the advantage of the proposed framework. Moreover, our framework allows users to control the style of translation outputs by providing an example style image. Code and pretrained models are available at [ this https URL ](https://github.com/nvlabs/MUNIT)

[ [Paper] ](https://arxiv.org/abs/1804.04732) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/munit/munit.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/munit/
    $ python3 munit.py --dataset_name edges2shoes

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png)

Results by varying the style code. 

###  <::after> Pix2Pix 

_Unpaired Image-to-Image Translation with Conditional Adversarial Networks_

####  <::after> Authors 

Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros 

####  <::after> Abstract 

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either. 

[ [Paper] ](https://arxiv.org/abs/1611.07004) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pix2pix/pix2pix.py)

[ ](http://eriklindernoren.se/images/pix2pix_architecture.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh facades
    $ cd ../implementations/pix2pix/
    $ python3 pix2pix.py --dataset_name facades

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png)

Rows from top to bottom: (1) The condition for the generator (2) Generated image   
based of condition (3) The true corresponding image to the condition 

###  <::after> PixelDA 

_Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks_

####  <::after> Authors 

Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan 

####  <::after> Abstract 

Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training. 

[ [Paper] ](https://arxiv.org/abs/1612.05424) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pixelda/pixelda.py)

####  <::after> MNIST to MNIST-M Classification 

Trains a classifier on images that have been translated from the source domain (MNIST) to the target domain (MNIST-M) using the annotations of the source domain images. The classification network is trained jointly with the generator network to optimize the generator for both providing a proper domain translation and also for preserving the semantics of the source domain image. The classification network trained on translated images is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation achieves a 95% classification accuracy. 
    
    
    $ cd implementations/pixelda/
    $ python3 pixelda.py

Method  |  Accuracy   
---|---  
Naive  |  55%   
PixelDA  |  95%   
  
[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png)

Rows from top to bottom: (1) Real images from MNIST (2) Translated images from   
MNIST to MNIST-M (3) Examples of images from MNIST-M 

###  <::after> Relativistic GAN 

_The relativistic discriminator: a key element missing from standard GAN_

####  <::after> Authors 

Alexia Jolicoeur-Martineau 

####  <::after> Abstract 

In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization. 

[ [Paper] ](https://arxiv.org/abs/1807.00734) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/relativistic_gan/relativistic_gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/relativistic_gan/
    $ python3 relativistic_gan.py                 # Relativistic Standard GAN
    $ python3 relativistic_gan.py --rel_avg_gan   # Relativistic Average GAN

###  <::after> Semi-Supervised GAN 

_Semi-Supervised Generative Adversarial Network_

####  <::after> Authors 

Augustus Odena 

####  <::after> Abstract 

We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN. 

[ [Paper] ](https://arxiv.org/abs/1606.01583) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/sgan/sgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/sgan/
    $ python3 sgan.py

###  <::after> Softmax GAN 

_Softmax GAN_

####  <::after> Authors 

Min Lin 

####  <::after> Abstract 

Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The key idea of Softmax GAN is to replace the classification loss in the original GAN with a softmax cross-entropy loss in the sample space of one single batch. In the adversarial learning of N real training samples and M generated samples, the target of discriminator training is to distribute all the probability mass to the real samples, each with probability 1M, and distribute zero probability to generated data. In the generator training phase, the target is to assign equal probability to all data points in the batch, each with probability 1M+N. While the original GAN is closely related to Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance Sampling version of GAN. We futher demonstrate with experiments that this simple change stabilizes GAN training. 

[ [Paper] ](https://arxiv.org/abs/1704.06191) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/softmax_gan/softmax_gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/softmax_gan/
    $ python3 softmax_gan.py

###  <::after> StarGAN 

_StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation_

####  <::after> Authors 

Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo 

####  <::after> Abstract 

Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks. 

[ [Paper] ](https://arxiv.org/abs/1711.09020) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/stargan/stargan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/stargan/
    
    $ python3 stargan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png)

Original | Black Hair | Blonde Hair | Brown Hair | Gender Flip | Aged 

###  <::after> Super-Resolution GAN 

_Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network_

####  <::after> Authors 

Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi 

####  <::after> Abstract 

Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method. 

[ [Paper] ](https://arxiv.org/abs/1609.04802) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/srgan/srgan.py)

[ ](http://eriklindernoren.se/images/superresgan.png)

####  <::after> Run Example 
    
    
    $ cd implementations/srgan/
    
    $ python3 srgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png)

Nearest Neighbor Upsampling | SRGAN 

###  <::after> UNIT 

_Unsupervised Image-to-Image Translation Networks_

####  <::after> Authors 

Ming-Yu Liu, Thomas Breuel, Jan Kautz 

####  <::after> Abstract 

Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in this [ https URL ](https://github.com/mingyuliutw/unit) . 

[ [Paper] ](https://arxiv.org/abs/1703.00848) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/unit/unit.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_cyclegan_dataset.sh apple2orange
    $ cd implementations/unit/
    $ python3 unit.py --dataset_name apple2orange

###  <::after> Wasserstein GAN 

_Wasserstein GAN_

####  <::after> Authors 

Martin Arjovsky, Soumith Chintala, Léon Bottou 

####  <::after> Abstract 

We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions. 

[ [Paper] ](https://arxiv.org/abs/1701.07875) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan/wgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan/
    $ python3 wgan.py

###  <::after> Wasserstein GAN GP 

_Improved Training of Wasserstein GANs_

####  <::after> Authors 

Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville 

####  <::after> Abstract 

Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms. 

[ [Paper] ](https://arxiv.org/abs/1704.00028) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_gp/wgan_gp.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan_gp/
    $ python3 wgan_gp.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif)

###  <::after> Wasserstein GAN DIV 

_Wasserstein Divergence for GANs_

####  <::after> Authors 

Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya, Luc Van Gool 

####  <::after> Abstract 

In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods. 

[ [Paper] ](https://arxiv.org/abs/1712.01026) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_div/wgan_div.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan_div/
    $ python3 wgan_div.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png)

#  Menu 

[ ](/search?project_id=86)

**Explore** [ Projects  ](/explore) [ Groups  ](/explore/groups) [ Snippets  ](/explore/snippets)



Step 6:
act - **MessageAction** (source=EventSource.AGENT)
CONTENT: Based on the information obtained, the best GAN implementation project is "PyTorch-GAN" by Erik Linder-Norén. The SSH clone URL for this project is:

```
ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git
```

To clone this repository using SSH, you can use the following command:

```
git clone ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git
```

Finish[git clone ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git]
obs - NullObservation(content='', observation='null')

Step 7:
act - **MessageAction** (source=EventSource.USER)
CONTENT: Please continue working on the task on whatever approach you think is suitable.

obs - NullObservation(content='', observation='null')

Step 8:
act - **BrowseInteractiveAction**
BROWSER_ACTIONS: click("687")
obs - **BrowserOutputObservation**
URL: http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN
Status code: 200
Error: False
Open pages: ['http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN']
Active page index: 0
Last browser action: click("687")
Last browser action error: 
Focused element bid: 687
CONTENT: Skip to content 

GitLab  [ ](/ "Dashboard")

  *     * **Explore** [ Projects  ](/explore) [ Groups  ](/explore/groups) [ Snippets  ](/explore/snippets)




[ Projects ](/explore) [ Groups ](/explore/groups) [ Snippets ](/explore/snippets)

  * ` / `

  * [ ](/search?project_id=86 "Search")



  * [ Help  ](/help)

    *     * [ Help ](/help)
    * [ Support ](https://about.gitlab.com/getting-help/)
    * [ Community forum ](https://forum.gitlab.com)
    * Keyboard shortcuts ` ? `
    *     * [ Submit feedback ](https://about.gitlab.com/submit-feedback)
    * [ Contribute to GitLab ](https://about.gitlab.com/contributing)

  * [ Sign in / Register  ](/users/sign_in?redirect_to_referer=yes)




Toggle navigation  Menu 

  * [ P  PyTorch-GAN  ](/eriklindernoren/PyTorch-GAN)
  * [ Project information  ](/eriklindernoren/PyTorch-GAN/activity)
    * **Project information**
    *     * [ Activity  ](/eriklindernoren/PyTorch-GAN/activity)
    * [ Labels  ](/eriklindernoren/PyTorch-GAN/-/labels)
    * [ Members  ](/eriklindernoren/PyTorch-GAN/-/project_members)
  * [ Repository  ](/eriklindernoren/PyTorch-GAN/-/tree/master)
    * **Repository**
    *     * [ Files  ](/eriklindernoren/PyTorch-GAN/-/tree/master)
    * [ Commits  ](/eriklindernoren/PyTorch-GAN/-/commits/master)
    * [ Branches  ](/eriklindernoren/PyTorch-GAN/-/branches)
    * [ Tags  ](/eriklindernoren/PyTorch-GAN/-/tags)
    * [ Contributors  ](/eriklindernoren/PyTorch-GAN/-/graphs/master)
    * [ Graph  ](/eriklindernoren/PyTorch-GAN/-/network/master)
    * [ Compare  ](/eriklindernoren/PyTorch-GAN/-/compare?from=master&to=master)
  * [ Issues  102  ](/eriklindernoren/PyTorch-GAN/-/issues)
    * **Issues** 102 
    *     * [ List  ](/eriklindernoren/PyTorch-GAN/-/issues)
    * [ Boards  ](/eriklindernoren/PyTorch-GAN/-/boards)
    * [ Service Desk  ](/eriklindernoren/PyTorch-GAN/-/issues/service_desk)
    * [ Milestones  ](/eriklindernoren/PyTorch-GAN/-/milestones)
  * [ Merge requests  24  ](/eriklindernoren/PyTorch-GAN/-/merge_requests)
    * **Merge requests** 24 
  * [ CI/CD  ](/eriklindernoren/PyTorch-GAN/-/pipelines)
    * **CI/CD**
    *     * [ Pipelines  ](/eriklindernoren/PyTorch-GAN/-/pipelines)
    * [ Jobs  ](/eriklindernoren/PyTorch-GAN/-/jobs)
    * [ Schedules  ](/eriklindernoren/PyTorch-GAN/-/pipeline_schedules)
  * [ Deployments  ](/eriklindernoren/PyTorch-GAN/-/environments)
    * **Deployments**
    *     * [ Environments  ](/eriklindernoren/PyTorch-GAN/-/environments)
    * [ Releases  ](/eriklindernoren/PyTorch-GAN/-/releases)
  * [ Packages and registries  ](/eriklindernoren/PyTorch-GAN/-/packages)
    * **Packages and registries**
    *     * [ Package Registry  ](/eriklindernoren/PyTorch-GAN/-/packages)
    * [ Infrastructure Registry  ](/eriklindernoren/PyTorch-GAN/-/infrastructure_registry)
  * [ Monitor  ](/eriklindernoren/PyTorch-GAN/-/incidents)
    * **Monitor**
    *     * [ Incidents  ](/eriklindernoren/PyTorch-GAN/-/incidents)
  * [ Analytics  ](/eriklindernoren/PyTorch-GAN/-/value_stream_analytics)
    * **Analytics**
    *     * [ Value stream  ](/eriklindernoren/PyTorch-GAN/-/value_stream_analytics)
    * [ CI/CD  ](/eriklindernoren/PyTorch-GAN/-/pipelines/charts)
    * [ Repository  ](/eriklindernoren/PyTorch-GAN/-/graphs/master/charts)
  * [ Wiki  ](/eriklindernoren/PyTorch-GAN/-/wikis/home)
    * **Wiki**
  * [ Snippets  ](/eriklindernoren/PyTorch-GAN/-/snippets)
    * **Snippets**
  * [ Activity ](/eriklindernoren/PyTorch-GAN/activity)
  * [ Graph ](/eriklindernoren/PyTorch-GAN/-/network/master)
  * [ Create a new issue ](/eriklindernoren/PyTorch-GAN/-/issues/new)
  * [ Jobs ](/eriklindernoren/PyTorch-GAN/-/jobs)
  * [ Commits ](/eriklindernoren/PyTorch-GAN/-/commits/master)
  * [ Issue Boards ](/eriklindernoren/PyTorch-GAN/-/boards)

Collapse sidebar  Close sidebar 

<::after>

Open sidebar 

  * [ Erik Linder-Norén ](/eriklindernoren)
  * [ PyTorch-GAN  ](/eriklindernoren/PyTorch-GAN)



P 

#  PyTorch-GAN 

Project ID: 86 

[ Star  ](/users/sign_in "You must sign in to star a project") [ 45 ](/eriklindernoren/PyTorch-GAN/-/starrers "Starrers")

  * [ **193** Commits ](/eriklindernoren/PyTorch-GAN/-/commits/master)
  * [ **25** Branches ](/eriklindernoren/PyTorch-GAN/-/branches)
  * [ **0** Tags ](/eriklindernoren/PyTorch-GAN/-/tags)
  * **184.7 MB** Project Storage 




PyTorch implementations of Generative Adversarial Networks. 

Read more 

Python  99.6%  ">

Shell  0.4%  ">

<::after>

[ Update README.md ](/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e)

Erik Linder-Norén authored  3 years ago 

4AEE18F83AFDEB23  [ Learn more about signing commits ](/help/user/project/repository/gpg_signed_commits/index.md) " data-html="true" data-placement="top" data-title=" 

This commit was signed with an **unverified** signature. 

" data-toggle="popover" role="button" tabindex="0"> Unverified 

36d3c77e 

master 

Select Git revision 

  * Branches  25 

  * github/fork/Aniloid2/patch-1 

  * github/fork/Boyden/master 

  * github/fork/CaoE/master 

  * github/fork/HCMY/master 

  * github/fork/HanbumKo/patch-1 

  * github/fork/Hazarre/master 

  * github/fork/Hosein47/patch-1 

  * github/fork/IvanFei/master 

  * github/fork/Misaliet/Fix-variable-name-typo 

  * github/fork/San-ctuary/modify_acgan 

  * github/fork/Sean16SYSU/dev 

  * github/fork/WalterDUT/master 

  * github/fork/aqbewtra/patch-1 

  * github/fork/chenyang1999/patch-4 

  * github/fork/foersterrobert/patch-1 

  * github/fork/hou-yz/master 

  * github/fork/lukas-blecher/master 

  * github/fork/masud99r/patch-1 

  * github/fork/mexxik/bgan_fix 

  * github/fork/nicolas-gervais/patch-1 




  1. [ PyTorch-GAN ](/eriklindernoren/PyTorch-GAN/-/tree/master/)



[ Find file ](/eriklindernoren/PyTorch-GAN/-/find_file/master)

Select Archive Format 

#####  Download source code 

[ zip ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.zip) [ tar.gz ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar.gz) [ tar.bz2 ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar.bz2) [ tar ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar)

Clone 

  * Clone with SSH 

  * Clone with HTTP 

  *   * Open in your IDE  [ Visual Studio Code (SSH)  ](vscode://vscode.git/clone?url=ssh%3A%2F%2Fgit%40metis.lti.cs.cmu.edu%3A2222%2Feriklindernoren%2FPyTorch-GAN.git) [ Visual Studio Code (HTTPS)  ](vscode://vscode.git/clone?url=http%3A%2F%2Fmetis.lti.cs.cmu.edu%3A8023%2Feriklindernoren%2FPyTorch-GAN.git) [ IntelliJ IDEA (SSH)  ](jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=ssh%3A%2F%2Fgit%40metis.lti.cs.cmu.edu%3A2222%2Feriklindernoren%2FPyTorch-GAN.git) [ IntelliJ IDEA (HTTPS)  ](jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=http%3A%2F%2Fmetis.lti.cs.cmu.edu%3A8023%2Feriklindernoren%2FPyTorch-GAN.git)



Copy HTTP clone URL 

  * [ **Copy SSH clone URL** ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git  ](ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git)
  * [ **Copy HTTP clone URL** http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git  ](http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git)



  * [ README ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md)
  * [ MIT License  ](/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE)



Name  |  Last commit  |  Last update   
---|---|---  
[ <::before> assets  ](/eriklindernoren/PyTorch-GAN/-/tree/master/assets "assets") |  [ adds clustergan gif ](/eriklindernoren/PyTorch-GAN/-/commit/23a2b9f4514cc997a8689e5e19fbddf7adc539f6 "adds clustergan gif
") |  5 years ago   
[ <::before> data  ](/eriklindernoren/PyTorch-GAN/-/tree/master/data "data") |  [ Figures ](/eriklindernoren/PyTorch-GAN/-/commit/df342dd3ecd5270a8810bdaae30c1c6571ac31bc "Figures
") |  6 years ago   
[ <::before> implementations  ](/eriklindernoren/PyTorch-GAN/-/tree/master/implementations "implementations") |  [ Adds single clustergan script ](/eriklindernoren/PyTorch-GAN/-/commit/5f84be03dec16e032d170dafd1689ca948218e88 "Adds single clustergan script
") |  5 years ago   
[ <::before> .gitignore  ](/eriklindernoren/PyTorch-GAN/-/blob/master/.gitignore ".gitignore") |  [ MNIST normalization. Black refactoring. ](/eriklindernoren/PyTorch-GAN/-/commit/c5d6be170013db8975d96806084df573d87e5d26 "MNIST normalization. Black refactoring.
") |  5 years ago   
[ <::before> LICENSE  ](/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE "LICENSE") |  [ Initial commit ](/eriklindernoren/PyTorch-GAN/-/commit/a18bcc2695e95e10420570913816317b1f233438 "Initial commit") |  6 years ago   
[ <::before> README.md  ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md "README.md") |  [ Update README.md ](/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e "Update README.md") |  3 years ago   
[ <::before> requirements.txt  ](/eriklindernoren/PyTorch-GAN/-/blob/master/requirements.txt "requirements.txt") |  [ Added PyTorch 0.4.0 to requirements ](/eriklindernoren/PyTorch-GAN/-/commit/8400a6e4ab0eb1a69f641bc568ce56049a2112eb "Added PyTorch 0.4.0 to requirements
") |  6 years ago   
  
[ **README.md** ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md)

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png)

**This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at[ eriklindernoren@gmail.com ](mailto:eriklindernoren@gmail.com) . **

##  <::after> PyTorch-GAN 

Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed. 

**See also:** [ Keras-GAN ](https://github.com/eriklindernoren/Keras-GAN)

##  <::after> Table of Contents 

  * <::marker> Installation 
  * <::marker> Implementations 
    * <::marker> Auxiliary Classifier GAN 
    * <::marker> Adversarial Autoencoder 
    * <::marker> BEGAN 
    * <::marker> BicycleGAN 
    * <::marker> Boundary-Seeking GAN 
    * <::marker> Cluster GAN 
    * <::marker> Conditional GAN 
    * <::marker> Context-Conditional GAN 
    * <::marker> Context Encoder 
    * <::marker> Coupled GAN 
    * <::marker> CycleGAN 
    * <::marker> Deep Convolutional GAN 
    * <::marker> DiscoGAN 
    * <::marker> DRAGAN 
    * <::marker> DualGAN 
    * <::marker> Energy-Based GAN 
    * <::marker> Enhanced Super-Resolution GAN 
    * <::marker> GAN 
    * <::marker> InfoGAN 
    * <::marker> Least Squares GAN 
    * <::marker> MUNIT 
    * <::marker> Pix2Pix 
    * <::marker> PixelDA 
    * <::marker> Relativistic GAN 
    * <::marker> Semi-Supervised GAN 
    * <::marker> Softmax GAN 
    * <::marker> StarGAN 
    * <::marker> Super-Resolution GAN 
    * <::marker> UNIT 
    * <::marker> Wasserstein GAN 
    * <::marker> Wasserstein GAN GP 
    * <::marker> Wasserstein GAN DIV 



##  <::after> Installation 
    
    
    $ git clone https://github.com/eriklindernoren/PyTorch-GAN
    $ cd PyTorch-GAN/
    $ sudo pip3 install -r requirements.txt

##  <::after> Implementations 

###  <::after> Auxiliary Classifier GAN 

_Auxiliary Classifier Generative Adversarial Network_

####  <::after> Authors 

Augustus Odena, Christopher Olah, Jonathon Shlens 

####  <::after> Abstract 

Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data. 

[ [Paper] ](https://arxiv.org/abs/1610.09585) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/acgan/acgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/acgan/
    $ python3 acgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif)

###  <::after> Adversarial Autoencoder 

_Adversarial Autoencoder_

####  <::after> Authors 

Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey 

####  <::after> Abstract 

n this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks. 

[ [Paper] ](https://arxiv.org/abs/1511.05644) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/aae/aae.py)

####  <::after> Run Example 
    
    
    $ cd implementations/aae/
    $ python3 aae.py

###  <::after> BEGAN 

_BEGAN: Boundary Equilibrium Generative Adversarial Networks_

####  <::after> Authors 

David Berthelot, Thomas Schumm, Luke Metz 

####  <::after> Abstract 

We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure. 

[ [Paper] ](https://arxiv.org/abs/1703.10717) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/began/began.py)

####  <::after> Run Example 
    
    
    $ cd implementations/began/
    $ python3 began.py

###  <::after> BicycleGAN 

_Toward Multimodal Image-to-Image Translation_

####  <::after> Authors 

Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman 

####  <::after> Abstract 

Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a \emph{distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity. 

[ [Paper] ](https://arxiv.org/abs/1711.11586) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bicyclegan/bicyclegan.py)

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/bicyclegan/
    $ python3 bicyclegan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png)

Various style translations by varying the latent code. 

###  <::after> Boundary-Seeking GAN 

_Boundary-Seeking Generative Adversarial Networks_

####  <::after> Authors 

R Devon Hjelm, Athul Paul Jacob, Tong Che, Adam Trischler, Kyunghyun Cho, Yoshua Bengio 

####  <::after> Abstract 

Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning. 

[ [Paper] ](https://arxiv.org/abs/1702.08431) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bgan/bgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/bgan/
    $ python3 bgan.py

###  <::after> Cluster GAN 

_ClusterGAN: Latent Space Clustering in Generative Adversarial Networks_

####  <::after> Authors 

Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan 

####  <::after> Abstract 

Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets. 

[ [Paper] ](https://arxiv.org/abs/1809.03627) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cluster_gan/clustergan.py)

Code based on a full PyTorch [ [implementation] ](https://github.com/zhampel/clusterGAN) . 

####  <::after> Run Example 
    
    
    $ cd implementations/cluster_gan/
    $ python3 clustergan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif)

###  <::after> Conditional GAN 

_Conditional Generative Adversarial Nets_

####  <::after> Authors 

Mehdi Mirza, Simon Osindero 

####  <::after> Abstract 

Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels. 

[ [Paper] ](https://arxiv.org/abs/1411.1784) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cgan/cgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/cgan/
    $ python3 cgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif)

###  <::after> Context-Conditional GAN 

_Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks_

####  <::after> Authors 

Emily Denton, Sam Gross, Rob Fergus 

####  <::after> Abstract 

We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods. 

[ [Paper] ](https://arxiv.org/abs/1611.06430) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ccgan/ccgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/ccgan/
    $ python3 ccgan.py

###  <::after> Context Encoder 

_Context Encoders: Feature Learning by Inpainting_

####  <::after> Authors 

Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros 

####  <::after> Abstract 

We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods. 

[ [Paper] ](https://arxiv.org/abs/1604.07379) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/context_encoder/context_encoder.py)

####  <::after> Run Example 
    
    
    $ cd implementations/context_encoder/
    
    $ python3 context_encoder.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png)

Rows: Masked | Inpainted | Original | Masked | Inpainted | Original 

###  <::after> Coupled GAN 

_Coupled Generative Adversarial Networks_

####  <::after> Authors 

Ming-Yu Liu, Oncel Tuzel 

####  <::after> Abstract 

We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation. 

[ [Paper] ](https://arxiv.org/abs/1606.07536) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cogan/cogan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/cogan/
    $ python3 cogan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif)

Generated MNIST and MNIST-M images 

###  <::after> CycleGAN 

_Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_

####  <::after> Authors 

Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros 

####  <::after> Abstract 

Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X→Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F:Y→X and introduce a cycle consistency loss to push F(G(X))≈X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach. 

[ [Paper] ](https://arxiv.org/abs/1703.10593) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cyclegan/cyclegan.py)

[ ](http://eriklindernoren.se/images/cyclegan.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_cyclegan_dataset.sh monet2photo
    $ cd ../implementations/cyclegan/
    $ python3 cyclegan.py --dataset_name monet2photo

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png)

Monet to photo translations. 

###  <::after> Deep Convolutional GAN 

_Deep Convolutional Generative Adversarial Network_

####  <::after> Authors 

Alec Radford, Luke Metz, Soumith Chintala 

####  <::after> Abstract 

In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations. 

[ [Paper] ](https://arxiv.org/abs/1511.06434) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dcgan/dcgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/dcgan/
    $ python3 dcgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif)

###  <::after> DiscoGAN 

_Learning to Discover Cross-Domain Relations with Generative Adversarial Networks_

####  <::after> Authors 

Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim 

####  <::after> Abstract 

While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity. 

[ [Paper] ](https://arxiv.org/abs/1703.05192) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/discogan/discogan.py)

[ ](http://eriklindernoren.se/images/discogan_architecture.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/discogan/
    $ python3 discogan.py --dataset_name edges2shoes

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png)

Rows from top to bottom: (1) Real image from domain A (2) Translated image from   
domain A (3) Reconstructed image from domain A (4) Real image from domain B (5)   
Translated image from domain B (6) Reconstructed image from domain B 

###  <::after> DRAGAN 

_On Convergence and Stability of GANs_

####  <::after> Authors 

Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira 

####  <::after> Abstract 

We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions. 

[ [Paper] ](https://arxiv.org/abs/1705.07215) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dragan/dragan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/dragan/
    $ python3 dragan.py

###  <::after> DualGAN 

_DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_

####  <::after> Authors 

Zili Yi, Hao Zhang, Ping Tan, Minglun Gong 

####  <::after> Abstract 

Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V, while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data. 

[ [Paper] ](https://arxiv.org/abs/1704.02510) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dualgan/dualgan.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh facades
    $ cd ../implementations/dualgan/
    $ python3 dualgan.py --dataset_name facades

###  <::after> Energy-Based GAN 

_Energy-based Generative Adversarial Network_

####  <::after> Authors 

Junbo Zhao, Michael Mathieu, Yann LeCun 

####  <::after> Abstract 

We introduce the "Energy-based Generative Adversarial Network" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images. 

[ [Paper] ](https://arxiv.org/abs/1609.03126) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ebgan/ebgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/ebgan/
    $ python3 ebgan.py

###  <::after> Enhanced Super-Resolution GAN 

_ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks_

####  <::after> Authors 

Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, Xiaoou Tang 

####  <::after> Abstract 

The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at [ this https URL ](https://github.com/xinntao/ESRGAN) . 

[ [Paper] ](https://arxiv.org/abs/1809.00219) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/esrgan/esrgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/esrgan/
    
    $ python3 esrgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png)

Nearest Neighbor Upsampling | ESRGAN 

###  <::after> GAN 

_Generative Adversarial Network_

####  <::after> Authors 

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio 

####  <::after> Abstract 

We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 

[ [Paper] ](https://arxiv.org/abs/1406.2661) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/gan/gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/gan/
    $ python3 gan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif)

###  <::after> InfoGAN 

_InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets_

####  <::after> Authors 

Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel 

####  <::after> Abstract 

This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods. 

[ [Paper] ](https://arxiv.org/abs/1606.03657) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/infogan/infogan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/infogan/
    $ python3 infogan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif)

Result of varying categorical latent variable by column. 

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png)

Result of varying continuous latent variable by row. 

###  <::after> Least Squares GAN 

_Least Squares Generative Adversarial Networks_

####  <::after> Authors 

Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley 

####  <::after> Abstract 

Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson χ2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs. 

[ [Paper] ](https://arxiv.org/abs/1611.04076) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/lsgan/lsgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/lsgan/
    $ python3 lsgan.py

###  <::after> MUNIT 

_Multimodal Unsupervised Image-to-Image Translation_

####  <::after> Authors 

Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz 

####  <::after> Abstract 

Unsupervised image-to-image translation is an important and challenging problem in computer vision. Given an image in the source domain, the goal is to learn the conditional distribution of corresponding images in the target domain, without seeing any pairs of corresponding images. While this conditional distribution is inherently multimodal, existing approaches make an overly simplified assumption, modeling it as a deterministic one-to-one mapping. As a result, they fail to generate diverse outputs from a given source domain image. To address this limitation, we propose a Multimodal Unsupervised Image-to-image Translation (MUNIT) framework. We assume that the image representation can be decomposed into a content code that is domain-invariant, and a style code that captures domain-specific properties. To translate an image to another domain, we recombine its content code with a random style code sampled from the style space of the target domain. We analyze the proposed framework and establish several theoretical results. Extensive experiments with comparisons to the state-of-the-art approaches further demonstrates the advantage of the proposed framework. Moreover, our framework allows users to control the style of translation outputs by providing an example style image. Code and pretrained models are available at [ this https URL ](https://github.com/nvlabs/MUNIT)

[ [Paper] ](https://arxiv.org/abs/1804.04732) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/munit/munit.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/munit/
    $ python3 munit.py --dataset_name edges2shoes

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png)

Results by varying the style code. 

###  <::after> Pix2Pix 

_Unpaired Image-to-Image Translation with Conditional Adversarial Networks_

####  <::after> Authors 

Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros 

####  <::after> Abstract 

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either. 

[ [Paper] ](https://arxiv.org/abs/1611.07004) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pix2pix/pix2pix.py)

[ ](http://eriklindernoren.se/images/pix2pix_architecture.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh facades
    $ cd ../implementations/pix2pix/
    $ python3 pix2pix.py --dataset_name facades

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png)

Rows from top to bottom: (1) The condition for the generator (2) Generated image   
based of condition (3) The true corresponding image to the condition 

###  <::after> PixelDA 

_Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks_

####  <::after> Authors 

Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan 

####  <::after> Abstract 

Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training. 

[ [Paper] ](https://arxiv.org/abs/1612.05424) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pixelda/pixelda.py)

####  <::after> MNIST to MNIST-M Classification 

Trains a classifier on images that have been translated from the source domain (MNIST) to the target domain (MNIST-M) using the annotations of the source domain images. The classification network is trained jointly with the generator network to optimize the generator for both providing a proper domain translation and also for preserving the semantics of the source domain image. The classification network trained on translated images is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation achieves a 95% classification accuracy. 
    
    
    $ cd implementations/pixelda/
    $ python3 pixelda.py

Method  |  Accuracy   
---|---  
Naive  |  55%   
PixelDA  |  95%   
  
[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png)

Rows from top to bottom: (1) Real images from MNIST (2) Translated images from   
MNIST to MNIST-M (3) Examples of images from MNIST-M 

###  <::after> Relativistic GAN 

_The relativistic discriminator: a key element missing from standard GAN_

####  <::after> Authors 

Alexia Jolicoeur-Martineau 

####  <::after> Abstract 

In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization. 

[ [Paper] ](https://arxiv.org/abs/1807.00734) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/relativistic_gan/relativistic_gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/relativistic_gan/
    $ python3 relativistic_gan.py                 # Relativistic Standard GAN
    $ python3 relativistic_gan.py --rel_avg_gan   # Relativistic Average GAN

###  <::after> Semi-Supervised GAN 

_Semi-Supervised Generative Adversarial Network_

####  <::after> Authors 

Augustus Odena 

####  <::after> Abstract 

We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN. 

[ [Paper] ](https://arxiv.org/abs/1606.01583) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/sgan/sgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/sgan/
    $ python3 sgan.py

###  <::after> Softmax GAN 

_Softmax GAN_

####  <::after> Authors 

Min Lin 

####  <::after> Abstract 

Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The key idea of Softmax GAN is to replace the classification loss in the original GAN with a softmax cross-entropy loss in the sample space of one single batch. In the adversarial learning of N real training samples and M generated samples, the target of discriminator training is to distribute all the probability mass to the real samples, each with probability 1M, and distribute zero probability to generated data. In the generator training phase, the target is to assign equal probability to all data points in the batch, each with probability 1M+N. While the original GAN is closely related to Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance Sampling version of GAN. We futher demonstrate with experiments that this simple change stabilizes GAN training. 

[ [Paper] ](https://arxiv.org/abs/1704.06191) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/softmax_gan/softmax_gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/softmax_gan/
    $ python3 softmax_gan.py

###  <::after> StarGAN 

_StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation_

####  <::after> Authors 

Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo 

####  <::after> Abstract 

Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks. 

[ [Paper] ](https://arxiv.org/abs/1711.09020) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/stargan/stargan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/stargan/
    
    $ python3 stargan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png)

Original | Black Hair | Blonde Hair | Brown Hair | Gender Flip | Aged 

###  <::after> Super-Resolution GAN 

_Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network_

####  <::after> Authors 

Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi 

####  <::after> Abstract 

Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method. 

[ [Paper] ](https://arxiv.org/abs/1609.04802) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/srgan/srgan.py)

[ ](http://eriklindernoren.se/images/superresgan.png)

####  <::after> Run Example 
    
    
    $ cd implementations/srgan/
    
    $ python3 srgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png)

Nearest Neighbor Upsampling | SRGAN 

###  <::after> UNIT 

_Unsupervised Image-to-Image Translation Networks_

####  <::after> Authors 

Ming-Yu Liu, Thomas Breuel, Jan Kautz 

####  <::after> Abstract 

Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in this [ https URL ](https://github.com/mingyuliutw/unit) . 

[ [Paper] ](https://arxiv.org/abs/1703.00848) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/unit/unit.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_cyclegan_dataset.sh apple2orange
    $ cd implementations/unit/
    $ python3 unit.py --dataset_name apple2orange

###  <::after> Wasserstein GAN 

_Wasserstein GAN_

####  <::after> Authors 

Martin Arjovsky, Soumith Chintala, Léon Bottou 

####  <::after> Abstract 

We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions. 

[ [Paper] ](https://arxiv.org/abs/1701.07875) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan/wgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan/
    $ python3 wgan.py

###  <::after> Wasserstein GAN GP 

_Improved Training of Wasserstein GANs_

####  <::after> Authors 

Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville 

####  <::after> Abstract 

Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms. 

[ [Paper] ](https://arxiv.org/abs/1704.00028) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_gp/wgan_gp.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan_gp/
    $ python3 wgan_gp.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif)

###  <::after> Wasserstein GAN DIV 

_Wasserstein Divergence for GANs_

####  <::after> Authors 

Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya, Luc Van Gool 

####  <::after> Abstract 

In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods. 

[ [Paper] ](https://arxiv.org/abs/1712.01026) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_div/wgan_div.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan_div/
    $ python3 wgan_div.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png)

#  Menu 

[ ](/search?project_id=86)

**Explore** [ Projects  ](/explore) [ Groups  ](/explore/groups) [ Snippets  ](/explore/snippets)



Step 9:
act - **MessageAction** (source=EventSource.AGENT)
CONTENT: The SSH clone URL for the "PyTorch-GAN" project is:

```
ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git
```

To clone this repository using SSH, you can use the following command:

```
git clone ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git
```

Finish[git clone ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git]
obs - NullObservation(content='', observation='null')

Step 10:
act - **MessageAction** (source=EventSource.USER)
CONTENT: Please continue working on the task on whatever approach you think is suitable.

When you think you successfully finished the task, first respond with `Finish[answer]` where you include *only* your answer to the questionin `[]` if the user asks for an answer, make sure you should only include the answer to the question but not any additional explanation, details, or commentary unless specifically requested.
After that, when you responded with your answer, you should respond with <finish></finish>.
Then finally, to exit, you can run <execute_bash>
exit()
</execute_bash>
obs - NullObservation(content='', observation='null')

Step 11:
act - **BrowseInteractiveAction**
BROWSER_ACTIONS: click("696")
obs - **BrowserOutputObservation**
URL: http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN
Status code: 200
Error: False
Open pages: ['http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN']
Active page index: 0
Last browser action: click("696")
Last browser action error: 
Focused element bid: 64
CONTENT: Skip to content 

GitLab  [ ](/ "Dashboard")

  *     * **Explore** [ Projects  ](/explore) [ Groups  ](/explore/groups) [ Snippets  ](/explore/snippets)




[ Projects ](/explore) [ Groups ](/explore/groups) [ Snippets ](/explore/snippets)

  * ` / `

  * [ ](/search?project_id=86 "Search")



  * [ Help  ](/help)

    *     * [ Help ](/help)
    * [ Support ](https://about.gitlab.com/getting-help/)
    * [ Community forum ](https://forum.gitlab.com)
    * Keyboard shortcuts ` ? `
    *     * [ Submit feedback ](https://about.gitlab.com/submit-feedback)
    * [ Contribute to GitLab ](https://about.gitlab.com/contributing)

  * [ Sign in / Register  ](/users/sign_in?redirect_to_referer=yes)




Toggle navigation  Menu 

  * [ P  PyTorch-GAN  ](/eriklindernoren/PyTorch-GAN)
  * [ Project information  ](/eriklindernoren/PyTorch-GAN/activity)
    * **Project information**
    *     * [ Activity  ](/eriklindernoren/PyTorch-GAN/activity)
    * [ Labels  ](/eriklindernoren/PyTorch-GAN/-/labels)
    * [ Members  ](/eriklindernoren/PyTorch-GAN/-/project_members)
  * [ Repository  ](/eriklindernoren/PyTorch-GAN/-/tree/master)
    * **Repository**
    *     * [ Files  ](/eriklindernoren/PyTorch-GAN/-/tree/master)
    * [ Commits  ](/eriklindernoren/PyTorch-GAN/-/commits/master)
    * [ Branches  ](/eriklindernoren/PyTorch-GAN/-/branches)
    * [ Tags  ](/eriklindernoren/PyTorch-GAN/-/tags)
    * [ Contributors  ](/eriklindernoren/PyTorch-GAN/-/graphs/master)
    * [ Graph  ](/eriklindernoren/PyTorch-GAN/-/network/master)
    * [ Compare  ](/eriklindernoren/PyTorch-GAN/-/compare?from=master&to=master)
  * [ Issues  102  ](/eriklindernoren/PyTorch-GAN/-/issues)
    * **Issues** 102 
    *     * [ List  ](/eriklindernoren/PyTorch-GAN/-/issues)
    * [ Boards  ](/eriklindernoren/PyTorch-GAN/-/boards)
    * [ Service Desk  ](/eriklindernoren/PyTorch-GAN/-/issues/service_desk)
    * [ Milestones  ](/eriklindernoren/PyTorch-GAN/-/milestones)
  * [ Merge requests  24  ](/eriklindernoren/PyTorch-GAN/-/merge_requests)
    * **Merge requests** 24 
  * [ CI/CD  ](/eriklindernoren/PyTorch-GAN/-/pipelines)
    * **CI/CD**
    *     * [ Pipelines  ](/eriklindernoren/PyTorch-GAN/-/pipelines)
    * [ Jobs  ](/eriklindernoren/PyTorch-GAN/-/jobs)
    * [ Schedules  ](/eriklindernoren/PyTorch-GAN/-/pipeline_schedules)
  * [ Deployments  ](/eriklindernoren/PyTorch-GAN/-/environments)
    * **Deployments**
    *     * [ Environments  ](/eriklindernoren/PyTorch-GAN/-/environments)
    * [ Releases  ](/eriklindernoren/PyTorch-GAN/-/releases)
  * [ Packages and registries  ](/eriklindernoren/PyTorch-GAN/-/packages)
    * **Packages and registries**
    *     * [ Package Registry  ](/eriklindernoren/PyTorch-GAN/-/packages)
    * [ Infrastructure Registry  ](/eriklindernoren/PyTorch-GAN/-/infrastructure_registry)
  * [ Monitor  ](/eriklindernoren/PyTorch-GAN/-/incidents)
    * **Monitor**
    *     * [ Incidents  ](/eriklindernoren/PyTorch-GAN/-/incidents)
  * [ Analytics  ](/eriklindernoren/PyTorch-GAN/-/value_stream_analytics)
    * **Analytics**
    *     * [ Value stream  ](/eriklindernoren/PyTorch-GAN/-/value_stream_analytics)
    * [ CI/CD  ](/eriklindernoren/PyTorch-GAN/-/pipelines/charts)
    * [ Repository  ](/eriklindernoren/PyTorch-GAN/-/graphs/master/charts)
  * [ Wiki  ](/eriklindernoren/PyTorch-GAN/-/wikis/home)
    * **Wiki**
  * [ Snippets  ](/eriklindernoren/PyTorch-GAN/-/snippets)
    * **Snippets**
  * [ Activity ](/eriklindernoren/PyTorch-GAN/activity)
  * [ Graph ](/eriklindernoren/PyTorch-GAN/-/network/master)
  * [ Create a new issue ](/eriklindernoren/PyTorch-GAN/-/issues/new)
  * [ Jobs ](/eriklindernoren/PyTorch-GAN/-/jobs)
  * [ Commits ](/eriklindernoren/PyTorch-GAN/-/commits/master)
  * [ Issue Boards ](/eriklindernoren/PyTorch-GAN/-/boards)

Collapse sidebar  Close sidebar 

<::after>

Open sidebar 

  * [ Erik Linder-Norén ](/eriklindernoren)
  * [ PyTorch-GAN  ](/eriklindernoren/PyTorch-GAN)



P 

#  PyTorch-GAN 

Project ID: 86 

[ Star  ](/users/sign_in "You must sign in to star a project") [ 45 ](/eriklindernoren/PyTorch-GAN/-/starrers "Starrers")

  * [ **193** Commits ](/eriklindernoren/PyTorch-GAN/-/commits/master)
  * [ **25** Branches ](/eriklindernoren/PyTorch-GAN/-/branches)
  * [ **0** Tags ](/eriklindernoren/PyTorch-GAN/-/tags)
  * **184.7 MB** Project Storage 




PyTorch implementations of Generative Adversarial Networks. 

Read more 

Python  99.6%  ">

Shell  0.4%  ">

<::after>

[ Update README.md ](/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e)

Erik Linder-Norén authored  3 years ago 

4AEE18F83AFDEB23  [ Learn more about signing commits ](/help/user/project/repository/gpg_signed_commits/index.md) " data-html="true" data-placement="top" data-title=" 

This commit was signed with an **unverified** signature. 

" data-toggle="popover" role="button" tabindex="0"> Unverified 

36d3c77e 

master 

Select Git revision 

  * Branches  25 

  * github/fork/Aniloid2/patch-1 

  * github/fork/Boyden/master 

  * github/fork/CaoE/master 

  * github/fork/HCMY/master 

  * github/fork/HanbumKo/patch-1 

  * github/fork/Hazarre/master 

  * github/fork/Hosein47/patch-1 

  * github/fork/IvanFei/master 

  * github/fork/Misaliet/Fix-variable-name-typo 

  * github/fork/San-ctuary/modify_acgan 

  * github/fork/Sean16SYSU/dev 

  * github/fork/WalterDUT/master 

  * github/fork/aqbewtra/patch-1 

  * github/fork/chenyang1999/patch-4 

  * github/fork/foersterrobert/patch-1 

  * github/fork/hou-yz/master 

  * github/fork/lukas-blecher/master 

  * github/fork/masud99r/patch-1 

  * github/fork/mexxik/bgan_fix 

  * github/fork/nicolas-gervais/patch-1 




  1. [ PyTorch-GAN ](/eriklindernoren/PyTorch-GAN/-/tree/master/)



[ Find file ](/eriklindernoren/PyTorch-GAN/-/find_file/master)

Select Archive Format 

#####  Download source code 

[ zip ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.zip) [ tar.gz ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar.gz) [ tar.bz2 ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar.bz2) [ tar ](/eriklindernoren/PyTorch-GAN/-/archive/master/PyTorch-GAN-master.tar)

Clone 

  * Clone with SSH 

  * Clone with HTTP 

  *   * Open in your IDE  [ Visual Studio Code (SSH)  ](vscode://vscode.git/clone?url=ssh%3A%2F%2Fgit%40metis.lti.cs.cmu.edu%3A2222%2Feriklindernoren%2FPyTorch-GAN.git) [ Visual Studio Code (HTTPS)  ](vscode://vscode.git/clone?url=http%3A%2F%2Fmetis.lti.cs.cmu.edu%3A8023%2Feriklindernoren%2FPyTorch-GAN.git) [ IntelliJ IDEA (SSH)  ](jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=ssh%3A%2F%2Fgit%40metis.lti.cs.cmu.edu%3A2222%2Feriklindernoren%2FPyTorch-GAN.git) [ IntelliJ IDEA (HTTPS)  ](jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=http%3A%2F%2Fmetis.lti.cs.cmu.edu%3A8023%2Feriklindernoren%2FPyTorch-GAN.git)



Copy HTTP clone URL 

  * [ **Copy SSH clone URL** ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git  ](ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git)
  * [ **Copy HTTP clone URL** http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git  ](http://metis.lti.cs.cmu.edu:8023/eriklindernoren/PyTorch-GAN.git)



  * [ README ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md)
  * [ MIT License  ](/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE)



Name  |  Last commit  |  Last update   
---|---|---  
[ <::before> assets  ](/eriklindernoren/PyTorch-GAN/-/tree/master/assets "assets") |  [ adds clustergan gif ](/eriklindernoren/PyTorch-GAN/-/commit/23a2b9f4514cc997a8689e5e19fbddf7adc539f6 "adds clustergan gif
") |  5 years ago   
[ <::before> data  ](/eriklindernoren/PyTorch-GAN/-/tree/master/data "data") |  [ Figures ](/eriklindernoren/PyTorch-GAN/-/commit/df342dd3ecd5270a8810bdaae30c1c6571ac31bc "Figures
") |  6 years ago   
[ <::before> implementations  ](/eriklindernoren/PyTorch-GAN/-/tree/master/implementations "implementations") |  [ Adds single clustergan script ](/eriklindernoren/PyTorch-GAN/-/commit/5f84be03dec16e032d170dafd1689ca948218e88 "Adds single clustergan script
") |  5 years ago   
[ <::before> .gitignore  ](/eriklindernoren/PyTorch-GAN/-/blob/master/.gitignore ".gitignore") |  [ MNIST normalization. Black refactoring. ](/eriklindernoren/PyTorch-GAN/-/commit/c5d6be170013db8975d96806084df573d87e5d26 "MNIST normalization. Black refactoring.
") |  5 years ago   
[ <::before> LICENSE  ](/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE "LICENSE") |  [ Initial commit ](/eriklindernoren/PyTorch-GAN/-/commit/a18bcc2695e95e10420570913816317b1f233438 "Initial commit") |  6 years ago   
[ <::before> README.md  ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md "README.md") |  [ Update README.md ](/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e "Update README.md") |  3 years ago   
[ <::before> requirements.txt  ](/eriklindernoren/PyTorch-GAN/-/blob/master/requirements.txt "requirements.txt") |  [ Added PyTorch 0.4.0 to requirements ](/eriklindernoren/PyTorch-GAN/-/commit/8400a6e4ab0eb1a69f641bc568ce56049a2112eb "Added PyTorch 0.4.0 to requirements
") |  6 years ago   
  
[ **README.md** ](/eriklindernoren/PyTorch-GAN/-/blob/master/README.md)

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png)

**This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at[ eriklindernoren@gmail.com ](mailto:eriklindernoren@gmail.com) . **

##  <::after> PyTorch-GAN 

Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed. 

**See also:** [ Keras-GAN ](https://github.com/eriklindernoren/Keras-GAN)

##  <::after> Table of Contents 

  * <::marker> Installation 
  * <::marker> Implementations 
    * <::marker> Auxiliary Classifier GAN 
    * <::marker> Adversarial Autoencoder 
    * <::marker> BEGAN 
    * <::marker> BicycleGAN 
    * <::marker> Boundary-Seeking GAN 
    * <::marker> Cluster GAN 
    * <::marker> Conditional GAN 
    * <::marker> Context-Conditional GAN 
    * <::marker> Context Encoder 
    * <::marker> Coupled GAN 
    * <::marker> CycleGAN 
    * <::marker> Deep Convolutional GAN 
    * <::marker> DiscoGAN 
    * <::marker> DRAGAN 
    * <::marker> DualGAN 
    * <::marker> Energy-Based GAN 
    * <::marker> Enhanced Super-Resolution GAN 
    * <::marker> GAN 
    * <::marker> InfoGAN 
    * <::marker> Least Squares GAN 
    * <::marker> MUNIT 
    * <::marker> Pix2Pix 
    * <::marker> PixelDA 
    * <::marker> Relativistic GAN 
    * <::marker> Semi-Supervised GAN 
    * <::marker> Softmax GAN 
    * <::marker> StarGAN 
    * <::marker> Super-Resolution GAN 
    * <::marker> UNIT 
    * <::marker> Wasserstein GAN 
    * <::marker> Wasserstein GAN GP 
    * <::marker> Wasserstein GAN DIV 



##  <::after> Installation 
    
    
    $ git clone https://github.com/eriklindernoren/PyTorch-GAN
    $ cd PyTorch-GAN/
    $ sudo pip3 install -r requirements.txt

##  <::after> Implementations 

###  <::after> Auxiliary Classifier GAN 

_Auxiliary Classifier Generative Adversarial Network_

####  <::after> Authors 

Augustus Odena, Christopher Olah, Jonathon Shlens 

####  <::after> Abstract 

Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data. 

[ [Paper] ](https://arxiv.org/abs/1610.09585) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/acgan/acgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/acgan/
    $ python3 acgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif)

###  <::after> Adversarial Autoencoder 

_Adversarial Autoencoder_

####  <::after> Authors 

Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey 

####  <::after> Abstract 

n this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks. 

[ [Paper] ](https://arxiv.org/abs/1511.05644) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/aae/aae.py)

####  <::after> Run Example 
    
    
    $ cd implementations/aae/
    $ python3 aae.py

###  <::after> BEGAN 

_BEGAN: Boundary Equilibrium Generative Adversarial Networks_

####  <::after> Authors 

David Berthelot, Thomas Schumm, Luke Metz 

####  <::after> Abstract 

We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure. 

[ [Paper] ](https://arxiv.org/abs/1703.10717) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/began/began.py)

####  <::after> Run Example 
    
    
    $ cd implementations/began/
    $ python3 began.py

###  <::after> BicycleGAN 

_Toward Multimodal Image-to-Image Translation_

####  <::after> Authors 

Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman 

####  <::after> Abstract 

Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a \emph{distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity. 

[ [Paper] ](https://arxiv.org/abs/1711.11586) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bicyclegan/bicyclegan.py)

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/bicyclegan/
    $ python3 bicyclegan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png)

Various style translations by varying the latent code. 

###  <::after> Boundary-Seeking GAN 

_Boundary-Seeking Generative Adversarial Networks_

####  <::after> Authors 

R Devon Hjelm, Athul Paul Jacob, Tong Che, Adam Trischler, Kyunghyun Cho, Yoshua Bengio 

####  <::after> Abstract 

Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning. 

[ [Paper] ](https://arxiv.org/abs/1702.08431) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bgan/bgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/bgan/
    $ python3 bgan.py

###  <::after> Cluster GAN 

_ClusterGAN: Latent Space Clustering in Generative Adversarial Networks_

####  <::after> Authors 

Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan 

####  <::after> Abstract 

Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets. 

[ [Paper] ](https://arxiv.org/abs/1809.03627) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cluster_gan/clustergan.py)

Code based on a full PyTorch [ [implementation] ](https://github.com/zhampel/clusterGAN) . 

####  <::after> Run Example 
    
    
    $ cd implementations/cluster_gan/
    $ python3 clustergan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif)

###  <::after> Conditional GAN 

_Conditional Generative Adversarial Nets_

####  <::after> Authors 

Mehdi Mirza, Simon Osindero 

####  <::after> Abstract 

Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels. 

[ [Paper] ](https://arxiv.org/abs/1411.1784) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cgan/cgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/cgan/
    $ python3 cgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif)

###  <::after> Context-Conditional GAN 

_Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks_

####  <::after> Authors 

Emily Denton, Sam Gross, Rob Fergus 

####  <::after> Abstract 

We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods. 

[ [Paper] ](https://arxiv.org/abs/1611.06430) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ccgan/ccgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/ccgan/
    $ python3 ccgan.py

###  <::after> Context Encoder 

_Context Encoders: Feature Learning by Inpainting_

####  <::after> Authors 

Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros 

####  <::after> Abstract 

We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods. 

[ [Paper] ](https://arxiv.org/abs/1604.07379) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/context_encoder/context_encoder.py)

####  <::after> Run Example 
    
    
    $ cd implementations/context_encoder/
    
    $ python3 context_encoder.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png)

Rows: Masked | Inpainted | Original | Masked | Inpainted | Original 

###  <::after> Coupled GAN 

_Coupled Generative Adversarial Networks_

####  <::after> Authors 

Ming-Yu Liu, Oncel Tuzel 

####  <::after> Abstract 

We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation. 

[ [Paper] ](https://arxiv.org/abs/1606.07536) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cogan/cogan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/cogan/
    $ python3 cogan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif)

Generated MNIST and MNIST-M images 

###  <::after> CycleGAN 

_Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_

####  <::after> Authors 

Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros 

####  <::after> Abstract 

Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X→Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F:Y→X and introduce a cycle consistency loss to push F(G(X))≈X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach. 

[ [Paper] ](https://arxiv.org/abs/1703.10593) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cyclegan/cyclegan.py)

[ ](http://eriklindernoren.se/images/cyclegan.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_cyclegan_dataset.sh monet2photo
    $ cd ../implementations/cyclegan/
    $ python3 cyclegan.py --dataset_name monet2photo

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png)

Monet to photo translations. 

###  <::after> Deep Convolutional GAN 

_Deep Convolutional Generative Adversarial Network_

####  <::after> Authors 

Alec Radford, Luke Metz, Soumith Chintala 

####  <::after> Abstract 

In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations. 

[ [Paper] ](https://arxiv.org/abs/1511.06434) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dcgan/dcgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/dcgan/
    $ python3 dcgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif)

###  <::after> DiscoGAN 

_Learning to Discover Cross-Domain Relations with Generative Adversarial Networks_

####  <::after> Authors 

Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim 

####  <::after> Abstract 

While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity. 

[ [Paper] ](https://arxiv.org/abs/1703.05192) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/discogan/discogan.py)

[ ](http://eriklindernoren.se/images/discogan_architecture.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/discogan/
    $ python3 discogan.py --dataset_name edges2shoes

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png)

Rows from top to bottom: (1) Real image from domain A (2) Translated image from   
domain A (3) Reconstructed image from domain A (4) Real image from domain B (5)   
Translated image from domain B (6) Reconstructed image from domain B 

###  <::after> DRAGAN 

_On Convergence and Stability of GANs_

####  <::after> Authors 

Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira 

####  <::after> Abstract 

We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions. 

[ [Paper] ](https://arxiv.org/abs/1705.07215) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dragan/dragan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/dragan/
    $ python3 dragan.py

###  <::after> DualGAN 

_DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_

####  <::after> Authors 

Zili Yi, Hao Zhang, Ping Tan, Minglun Gong 

####  <::after> Abstract 

Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V, while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data. 

[ [Paper] ](https://arxiv.org/abs/1704.02510) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dualgan/dualgan.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh facades
    $ cd ../implementations/dualgan/
    $ python3 dualgan.py --dataset_name facades

###  <::after> Energy-Based GAN 

_Energy-based Generative Adversarial Network_

####  <::after> Authors 

Junbo Zhao, Michael Mathieu, Yann LeCun 

####  <::after> Abstract 

We introduce the "Energy-based Generative Adversarial Network" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images. 

[ [Paper] ](https://arxiv.org/abs/1609.03126) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ebgan/ebgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/ebgan/
    $ python3 ebgan.py

###  <::after> Enhanced Super-Resolution GAN 

_ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks_

####  <::after> Authors 

Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, Xiaoou Tang 

####  <::after> Abstract 

The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at [ this https URL ](https://github.com/xinntao/ESRGAN) . 

[ [Paper] ](https://arxiv.org/abs/1809.00219) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/esrgan/esrgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/esrgan/
    
    $ python3 esrgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png)

Nearest Neighbor Upsampling | ESRGAN 

###  <::after> GAN 

_Generative Adversarial Network_

####  <::after> Authors 

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio 

####  <::after> Abstract 

We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 

[ [Paper] ](https://arxiv.org/abs/1406.2661) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/gan/gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/gan/
    $ python3 gan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif)

###  <::after> InfoGAN 

_InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets_

####  <::after> Authors 

Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel 

####  <::after> Abstract 

This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods. 

[ [Paper] ](https://arxiv.org/abs/1606.03657) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/infogan/infogan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/infogan/
    $ python3 infogan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif)

Result of varying categorical latent variable by column. 

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png)

Result of varying continuous latent variable by row. 

###  <::after> Least Squares GAN 

_Least Squares Generative Adversarial Networks_

####  <::after> Authors 

Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley 

####  <::after> Abstract 

Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson χ2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs. 

[ [Paper] ](https://arxiv.org/abs/1611.04076) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/lsgan/lsgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/lsgan/
    $ python3 lsgan.py

###  <::after> MUNIT 

_Multimodal Unsupervised Image-to-Image Translation_

####  <::after> Authors 

Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz 

####  <::after> Abstract 

Unsupervised image-to-image translation is an important and challenging problem in computer vision. Given an image in the source domain, the goal is to learn the conditional distribution of corresponding images in the target domain, without seeing any pairs of corresponding images. While this conditional distribution is inherently multimodal, existing approaches make an overly simplified assumption, modeling it as a deterministic one-to-one mapping. As a result, they fail to generate diverse outputs from a given source domain image. To address this limitation, we propose a Multimodal Unsupervised Image-to-image Translation (MUNIT) framework. We assume that the image representation can be decomposed into a content code that is domain-invariant, and a style code that captures domain-specific properties. To translate an image to another domain, we recombine its content code with a random style code sampled from the style space of the target domain. We analyze the proposed framework and establish several theoretical results. Extensive experiments with comparisons to the state-of-the-art approaches further demonstrates the advantage of the proposed framework. Moreover, our framework allows users to control the style of translation outputs by providing an example style image. Code and pretrained models are available at [ this https URL ](https://github.com/nvlabs/MUNIT)

[ [Paper] ](https://arxiv.org/abs/1804.04732) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/munit/munit.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh edges2shoes
    $ cd ../implementations/munit/
    $ python3 munit.py --dataset_name edges2shoes

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png)

Results by varying the style code. 

###  <::after> Pix2Pix 

_Unpaired Image-to-Image Translation with Conditional Adversarial Networks_

####  <::after> Authors 

Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros 

####  <::after> Abstract 

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either. 

[ [Paper] ](https://arxiv.org/abs/1611.07004) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pix2pix/pix2pix.py)

[ ](http://eriklindernoren.se/images/pix2pix_architecture.png)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_pix2pix_dataset.sh facades
    $ cd ../implementations/pix2pix/
    $ python3 pix2pix.py --dataset_name facades

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png)

Rows from top to bottom: (1) The condition for the generator (2) Generated image   
based of condition (3) The true corresponding image to the condition 

###  <::after> PixelDA 

_Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks_

####  <::after> Authors 

Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan 

####  <::after> Abstract 

Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training. 

[ [Paper] ](https://arxiv.org/abs/1612.05424) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pixelda/pixelda.py)

####  <::after> MNIST to MNIST-M Classification 

Trains a classifier on images that have been translated from the source domain (MNIST) to the target domain (MNIST-M) using the annotations of the source domain images. The classification network is trained jointly with the generator network to optimize the generator for both providing a proper domain translation and also for preserving the semantics of the source domain image. The classification network trained on translated images is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation achieves a 95% classification accuracy. 
    
    
    $ cd implementations/pixelda/
    $ python3 pixelda.py

Method  |  Accuracy   
---|---  
Naive  |  55%   
PixelDA  |  95%   
  
[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png)

Rows from top to bottom: (1) Real images from MNIST (2) Translated images from   
MNIST to MNIST-M (3) Examples of images from MNIST-M 

###  <::after> Relativistic GAN 

_The relativistic discriminator: a key element missing from standard GAN_

####  <::after> Authors 

Alexia Jolicoeur-Martineau 

####  <::after> Abstract 

In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization. 

[ [Paper] ](https://arxiv.org/abs/1807.00734) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/relativistic_gan/relativistic_gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/relativistic_gan/
    $ python3 relativistic_gan.py                 # Relativistic Standard GAN
    $ python3 relativistic_gan.py --rel_avg_gan   # Relativistic Average GAN

###  <::after> Semi-Supervised GAN 

_Semi-Supervised Generative Adversarial Network_

####  <::after> Authors 

Augustus Odena 

####  <::after> Abstract 

We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN. 

[ [Paper] ](https://arxiv.org/abs/1606.01583) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/sgan/sgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/sgan/
    $ python3 sgan.py

###  <::after> Softmax GAN 

_Softmax GAN_

####  <::after> Authors 

Min Lin 

####  <::after> Abstract 

Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The key idea of Softmax GAN is to replace the classification loss in the original GAN with a softmax cross-entropy loss in the sample space of one single batch. In the adversarial learning of N real training samples and M generated samples, the target of discriminator training is to distribute all the probability mass to the real samples, each with probability 1M, and distribute zero probability to generated data. In the generator training phase, the target is to assign equal probability to all data points in the batch, each with probability 1M+N. While the original GAN is closely related to Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance Sampling version of GAN. We futher demonstrate with experiments that this simple change stabilizes GAN training. 

[ [Paper] ](https://arxiv.org/abs/1704.06191) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/softmax_gan/softmax_gan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/softmax_gan/
    $ python3 softmax_gan.py

###  <::after> StarGAN 

_StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation_

####  <::after> Authors 

Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo 

####  <::after> Abstract 

Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks. 

[ [Paper] ](https://arxiv.org/abs/1711.09020) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/stargan/stargan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/stargan/
    
    $ python3 stargan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png)

Original | Black Hair | Blonde Hair | Brown Hair | Gender Flip | Aged 

###  <::after> Super-Resolution GAN 

_Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network_

####  <::after> Authors 

Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi 

####  <::after> Abstract 

Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method. 

[ [Paper] ](https://arxiv.org/abs/1609.04802) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/srgan/srgan.py)

[ ](http://eriklindernoren.se/images/superresgan.png)

####  <::after> Run Example 
    
    
    $ cd implementations/srgan/
    
    $ python3 srgan.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png)

Nearest Neighbor Upsampling | SRGAN 

###  <::after> UNIT 

_Unsupervised Image-to-Image Translation Networks_

####  <::after> Authors 

Ming-Yu Liu, Thomas Breuel, Jan Kautz 

####  <::after> Abstract 

Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in this [ https URL ](https://github.com/mingyuliutw/unit) . 

[ [Paper] ](https://arxiv.org/abs/1703.00848) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/unit/unit.py)

####  <::after> Run Example 
    
    
    $ cd data/
    $ bash download_cyclegan_dataset.sh apple2orange
    $ cd implementations/unit/
    $ python3 unit.py --dataset_name apple2orange

###  <::after> Wasserstein GAN 

_Wasserstein GAN_

####  <::after> Authors 

Martin Arjovsky, Soumith Chintala, Léon Bottou 

####  <::after> Abstract 

We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions. 

[ [Paper] ](https://arxiv.org/abs/1701.07875) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan/wgan.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan/
    $ python3 wgan.py

###  <::after> Wasserstein GAN GP 

_Improved Training of Wasserstein GANs_

####  <::after> Authors 

Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville 

####  <::after> Abstract 

Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms. 

[ [Paper] ](https://arxiv.org/abs/1704.00028) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_gp/wgan_gp.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan_gp/
    $ python3 wgan_gp.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif)

###  <::after> Wasserstein GAN DIV 

_Wasserstein Divergence for GANs_

####  <::after> Authors 

Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya, Luc Van Gool 

####  <::after> Abstract 

In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods. 

[ [Paper] ](https://arxiv.org/abs/1712.01026) [ [Code] ](/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_div/wgan_div.py)

####  <::after> Run Example 
    
    
    $ cd implementations/wgan_div/
    $ python3 wgan_div.py

[ ](/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png)

#  Menu 

[ ](/search?project_id=86)

**Explore** [ Projects  ](/explore) [ Groups  ](/explore/groups) [ Snippets  ](/explore/snippets)



Step 12:
act - AgentFinishAction(outputs={}, thought='Finish[git clone ssh://git@metis.lti.cs.cmu.edu:2222/eriklindernoren/PyTorch-GAN.git]', action='finish')
obs - NullObservation(content='', observation='null')

